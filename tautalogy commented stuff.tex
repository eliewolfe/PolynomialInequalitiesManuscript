


%One can also come up with a \emph{satisfiability} version of a marginal problem at the possibilistic level. Possibilistic satisfiability is the following: for every joint marginal outcome with positive probability, one needs to find an assignment of values to all variables which extends the given marginal outcomes and such that the restriction to every context also has positive probability. This is very easy to do: one can simply enumerate all deterministic assignments of values to all observables, discard all those that have a marginal with zero probability, and then check whether the remaining assignments are enough to generate all the joint marginal outcomes with positive probability.

% We note that the connection between classical propositional logic and linear inequalities has been used previously in the task of causal inference. Noteworthy examples of works deriving causal infeasibility criteria via classical logic are \citet{Pitowsky1989} and \citet{Ghirardi08}, see also Refs. \cite{pitowsky_boole_1994,kellerer_marginal_1964,leggett_garg_1985,araujo_cycle_2013}. Novel to this work, however, is the use of the hypergraph transversals problem to formally enumerate relevant logical implications. 

\begin{comment}
\section{Inequalities for the marginal problem via Hardy-type paradoxes and minimal transversals}

\purp{T: this may replace the tautologies section}

In the literature on Bell inequalities, it has been noticed that the infeasibility with the Bell scenario DAG can sometimes be witnessed by only looking at which joint probabilities are zero and which ones are nonzero. In other words, instead of considering the probability of a joint outcome, some distributions can be witnesses as infeasible by only considering the \emph{possibility} or \emph{impossibility} of each joint outcome. This has been originally noticed by~\citet{L.Hardy:PRL:1665}, and hence such possibilistic constraints are also known as \tblue{Hardy-type paradoxes}. The ``paradox'' occurs whenever the possibilistic constraint is violated. For a systematic account of Hardy-type paradoxes in Bell scenarios, see~\cite{Mansfield2012}. It has been noted previously that such possibilistic constraints also exist for other types of marginal problems~\cite[Section~III.C]{LSW}. In the following, we explain how to determine \emph{all} such constraints for \emph{any} marginal problem.

To start with a simple example, suppose that we are in a marginal scenario where the pairwise joint distributions of three variables $A$, $B$ and $C$ are given, and these two variables are binary with values in $\{0,1\}$. Then we have the implication
\[
	[A\eql 1,C\eql 1] \Longrightarrow [A\eql 0,B=\eql 0] \lor [B\eql 1,C \eql 1].
\]
Assuming the existence of a solution to the marginal problem, we can apply the union bound to the probability of the right-hand side. This translates the implication into the inequality
\[
	P_{AC}(01) \leq P_{AB}(00) + P_{BC}(11),
\]
which is therefore a necessary condition for the marginal problem to have a solution. Applying this together with the inflation technique to the Triangle scenario results in an inequality equivalent to~\cref{eq:polymonogamy}.

We outline the general procedure using a slightly more sophisticated example. Consider the marginal scenario of~\cref{fig:simplicialcomplex222}, where the contexts are
\begin{align*}
	\{A_1 B_1 C_1\},\\
	\{A_1 B_2 C_2\},\\
	\{A_2 B_1 C_2\},\\
	\{A_2 B_2 C_1\},\\
	\{A_2 B_2 C_2\}.
\end{align*}
Now a possibilistic constraint on this marginal problem consists of a logical implication with one joint outcome as the implicant and a disjunction of joint outcomes as the conclusion (implicate?). In the following, we explain how to generate \emph{all} such implications which are tight in the sense that their right-hand sides are minimal. So let us fix some joint outcome for the left-hand side for the sake of concreteness, taking
\begin{equation}
	\label{eq:lhshardy}
	[A_2 \eql 1, B_2 \eql 1, C_2 \eql 1].
\end{equation}
To generate all possibilistic constraints, one will have to perform the following procedure for every choice of joint outcome in every context as the left-hand side. Assuming these concrete outcomes, the right-hand side of the implication needs to be a conjunction of joint outcomes which is such that for any deterministic assignment of outcomes to the variables which extends~\cref{eq:lhshardy}, also at least one of the joint outcomes on the right-hand side occurs. To determine what the possibilities for choosing this right-hand side are, it helps to draw the following hypergraph: take the set of nodes to be the disjoint union over all the contexts of all the joint outcomes which are compatible with~\eqref{eq:lhshardy}\footnote{In the left-hand side context there will thus be only one node, and one can also omit this one node without changing the result.}. Furthermore, let the hyperedges correspond to complete deterministic assignments of values to all variables extending~\cref{eq:lhshardy}, such that such a hyperedge contains precisely those nodes that are the marginal outcomes to which it restricts. In our example, the resulting hypergraph has $2^3 + 3\cdot 2^1 = 14$ nodes and $2^3 = 8$ hyperedges. Then the possible right-hand sides of the implications are precisely the \tblue{transversals} of this hypergraph, i.e.~the sets of nodes which have the property that they intersect every hyperedge in at least one node. In order to get implications which are as tight as possible, it is sufficient to enumerate only the \tblue{minimal transversals}. Doing so is a well-studied problem in computer science with various natural reformulations and for which manifold algorithms have been developed~\cite{eiter_dualization_2008}. We expect that this enumeration of minimal transversals will be computationally much more tractable than the linear quantifier elimination, even if one does it for every possible left-hand side of the implication.

In our example, it is not hard to check that the right-hand side of
\begin{align*}
	[A_2 \eql 1, B_2 \eql 1, C_2 \eql 1] \Longrightarrow [A_1 \eql 0, B_1 & \eql 0, A_1 \eql 0] \lor [A_1 \eql 1, B_2 \eql 1, C_2 \eql 1] \\
		& \lor [A_2 \eql 1, B_1 \eql 1, C_2 \eql 1] \lor [A_2 \eql 1, B_2 \eql 1, C_1 \eql 1]
\end{align*}
is such a minimal transversal: every assignment of values to all variables which extends the assignment on the left-hand side satisfies at least one of the terms on the right, but this ceases to hold as soon as one removes any one term on the right.

Finally, we convert the implication into an inequality by replacing the implication itself by an inequality and the disjunctions by sums,
\[
	P_{A_2 B_2 C_2}(111) \leq P_{A_1 B_1 C_1}(000) + P_{A_1 B_2 C_2}(111) + P_{A_2 B_1 C_2}(111) + P_{A_2 B_2 C_1}(111).
\]
Applying this to our inflation DAG of~\cref{fig:Tri222} results again in one of our previous inequalities.

Since also many Bell inequalities are of this form---such as the CHSH inequality which follows in this way from Hardy's original implication---we conclude that this still sufficiently powerful to generate plenty of interesting inequalities, and at the same time significantly easier to perform in practice than the full-fledged linear (let alone nonlinear) quantifier elimination.
\end{comment}


\begin{comment}
\color{purple} 
[Version that uses modal logic]

In the literature on Bell inequalities, it has been noticed that incompatibility with the Bell DAG can sometimes be witnessed by merely looking at which events have zero probability and which events have nonzero probability. In other words, instead of considering the \emph{probability} of a composite outcome, the inconsistency of some marginal distributions can be evident from considering only the \emph{possibility} or \emph{impossibility} of each composite outcome. This insight is originally due to~\citet{L.Hardy:PRL:1665}, and versions of Bell's theorem that are based on the violation of such \tblue{possibilistic constraints} are known as \tblue{Hardy-type paradoxes}. For more background on Hardy-type paradoxes, see Refs.~\cite{Garuccio95,CabelloHardyInequality,Braun08,Mancinska14,LSW}; a partial classification of these can be found in Ref.~\cite{Mansfield2012}.


We have already provided a simple example of this sort of argument in \cref{Sec:DerivingInequalities}, in the logic used to demonstrate that the marginal distributions of Eqs.~\eqref{W4}-\eqref{W7} are incompatible with the DAG depicted in Fig.~\ref{fig:Tri222v2}.   For our present purposes, it is useful to recast the argument of \cref{Sec:DerivingInequalities} into a new but manifestly equivalent form.    For the distribution in question, we have
\begin{align} 
\text{Necessarily}\quad &A_2 \eql 1 \implies C_1\eql 0\label{WWs1}\\
\text{Necessarily}\quad &B_2\eql 1 \implies A_1\eql 0\label{WWs2}\\
\text{Necessarily}\quad &C_2 \eql 1 \implies B_1 \eql 0\label{WWs3}\\
\text{Necessarily not}  \quad &A_1 \eql 0\,\text{ and }\, B_1 \eql 0\,\text{ and }\, C_1 \eql 0.\label{WWs4}
\end{align}
From the last constraint one infers that necessarily at least one of $A_1$, $B_1$ and $C_1$ must be 1, which from the three other constraints implies that necessarily at least one of $A_2$, $B_2$ and $C_2$ must be 0, so that it is necessarily not the case that all of $A_2$, $B_2$ and $C_2$ are 1.  Thus Eqs.~\eqref{WWs1}-\eqref{WWs4} imply
\begin{align} \label{consequent2}
\text{Necessarily not}  \quad &A_2 \eql 1\,\text{ and }\, B_2 \eql 1\,\text{ and }\, C_2 \eql 1.
\end{align}
However, the DAG of Fig.~\ref{fig:Tri222v2} is such that $A_2$,$B_2$, and $C_2$ have no common ancestor and consequently these variables are marginally independent in any distribution consistent with this DAG.  Combining this with the fact that the marginal distribution for each of these three variables has full support implies that $A_2$,$B_2$, and $C_2$ sometimes all take the value 1, that is,
\begin{align} 
\text{Possibly}  \quad &A_1 \eql 0\,\text{ and }\, B_1 \eql 0\,\text{ and }\, C_1 \eql 0.\label{WWs4}
\end{align}
and this contradicts \cref{consequent2}.

What is nice about this form of the reasoning is that the appeal to the causal structure occurs only in the very last step.  In fact, one can even recast the argument in such a way that the appeal to the form of the marginal distributions also occurs only in the very last step.  In the first step, one notes only that the following proposition is a logical tautology in modal logic (here, $\land$, $\lor$ and $\lnot$ denote conjunction, disjunction and negation respectively, while $\square$ and $\diamond$ denote the modal unary operations {\em necessarily} and {\em possibly}):
\begin{align}\begin{split}\label{tautology1}
&(\square \lnot [A_2 \eql 1 \land C_1 \eql 1]) \bigwedge (\square \lnot [B_2 \eql 1 \land A_1 \eql 1]) \bigwedge (\square \lnot [C_2 \eql 1 \land B_1 \eql 1]) \bigwedge (\square \lnot [A_1 \eql 0 \land B_1 \eql 0 \land C_1 \eql 0])\\
 &\qquad\implies
\square \lnot [A_2 \eql 1 \land B_2 \eql 1 \land C_2 \eql 1].
\end{split}\end{align}
In the second and final step, one notes that the given distribution and the given causal structure imply that the antecedent is true while the consequent is false (because of Eq.~\eqref{WWs4}, which in logical form is
$\diamond [A_2 \eql 1 \land B_2 \eql 1 \land C_2 \eql 1]$,
and the fact that in modal logic $\diamond X = \lnot \square \lnot X$).  Thus the distribution and causal structure together imply a contradiction.

Such Hardy-type arguments for incompatibility actually only require one to be given an assignment of {\em possible} or {\em impossible} to certain valuations of variables rather an assignment of probabilities thereto. We call such assignments {\em possibilistic}.  In our final recasting of the Hardy-type argument for our example, the first step---identifying the logical tautology---can be understood as a constraint on marginal possibilistic assignments that follows from logic alone.  It can be understood as the possibilistic analogue of identifying a constraint on marginals distributions that holds for {\em any} joint distribution.  Thus it is useful to think of the problem in the first step of such proofs as the possibilistic counterpart of solving the marginal problem.
%Identifying such tautologies can be understood as a constraint on marginal {\em possibilistic assignments} rather than marginal distributions.  

Imagine that one has specified the full set of variables, denoted $\bm{X}$, together with a family of subsets of $\bm{X}$, termed contexts and denoted $(\bm{U}_1,\ldots,\bm{U}_n)$.  A \emph{joint possibilistic assignment} to $\bm{X}$, denoted $S_{\bm{X}}$, specifies for each joint valuation of the variables in $\bm{X}$ whether it is possible or not.  A \emph{marginal possibilistic assignment} for the context $\bm{U}_i$, denoted $S_{\bm{U}_i}$,  specifies for each joint valuation of the variables in $\bm{U_i}$ whether it is possible or not. Clearly, every joint possibilistic assignment $S_{\bm{X}}$ defines a family of marginal possibilistic assignments, $(S_{\bm{U}_1}, \ldots,S_{\bm{U}_n})$ through restriction.   In a \emph{possibilistic marginal problem}, one is given a family of marginal possibilistic assignments and one seeks to find the conditions under which one can find a joint possibilistic assignment that yields these under restriction. 


To assert that the valuation $\bm{U}_i = \bm{u}_i$ is {\em impossible} is to assert that it is necessarily not the case that  $\bm{U}_i = \bm{u}_i$, denoted logically as $\square \lnot  [\bm{U}_i = \bm{u}_i]$. A logical tautology involving such assertions can therefore be understood as a constraint on marginal possibilistic assignments.
%Because asserting the {\em impossibility} of some valuation $\bm{U}_i = \bm{u}_i$ is equivalent to asserting the falsity of the proposition $[\bm{U}_i = \bm{u}_i]$, it follows that any logical tautology involving only logical negations of particular valuations for the contexts can be understood as a constraint on marginal possibilistic assignments. 


As such, \cref{tautology1} can indeed be understood as a constraint on marginal possibilistic assignments.  Thinking of it this way makes it clear that witnessing incompatibility by starting with a Hardy-type logical tautology is the possibilistic analogue of deriving causal compatibility inequalities starting with a solution of the marginal problem.  More importantly, such constraints on marginal possibilistic assignments are interesting because they can be used to derive constraints on marginal distributions, as was shown by \citet{Mansfield2012}.

We illustrate this last claim with the example just discussed.  It can be cast as a marginal scenario where the contexts are $\{A_2 B_2 C_2\}$, $\{A_2 C_1\}$, $\{B_2 A_1\}$, $\{C_2 B_1\}$, and  $\{A_1 B_1 C_1\}$.  The logical tautology \eqref{tautology1} is then a constraint on marginal possibilistic assignments for this marginal scenario.   To see how to obtain a constraint on marginal distributions, we start by rewriting \cref{tautology1} in its contrapositive form (recall that $\lnot \square \lnot X = \diamond X$),
\begin{align}\begin{split}\label{tautology2}
&\diamond [A_2 \eql 1 \land B_2 \eql 1 \land C_2 \eql 1] \\
&\qquad \implies \diamond [A_2 \eql 1 \land C_1 \eql 1] \lor \diamond [B_2 \eql 1 \land A_1 \eql 1] \lor \diamond [C_2 \eql 1 \land B_1 \eql 1] \lor \diamond [A_1 \eql 0 \land B_1 \eql 0 \land C_1 \eql 0].
\end{split}\end{align}
Next, we note that if a logical tautology can be expressed as
\begin{align}\label{eq:inference}
   \diamond \SmallNamedFunction{}{E_0} \implies \diamond \SmallNamedFunction{}{E_1} \lor \ldots \lor \diamond \SmallNamedFunction{}{E_n},
\end{align}
then by applying
%because  a possibilistic assertion, such as $diamond E_i$, can be cashed out as ``the set of possible worlds in which $E_i$ is the case is not empty'', it follows that we can apply
 the union bound (which asserts that the probability of at least one of a set of events occuring is no greater than the sum of the probabilities of each event occuring), one obtains
\begin{align}\label{eq:possinference}
\p{E_0}\leq \sum\limits_{j=1}^n{\p{E_j}}.
\end{align}
Applying the union bound to \cref{tautology2} in particular yields
\begin{align}\label{eq:F3rawweak}
P_{A_2 B_2 C_2}\parens{\mgreen{1} \mgreen{1} \mgreen{1}} \leq P_{A_1 B_1 C_1}\parens{0 0 0}+P_{A_1 B_2}\parens{1 \mgreen{1 }}+P_{ B_1 C_2}\parens{ 1 \mgreen{1}}+P_{A_2 C_1}\parens{\mgreen{1 } 1},
\end{align}
which is a constraint on the marginal {\em distributions}.
 
Note that this inequality allows one to demonstrate the incompatibility of the marginal distributions of Eqs.~\eqref{W4}-\eqref{W7} with the inflated DAG just as easily as one can with the tautology of \cref{tautology1}.  It suffices to note that the given distribution and causal structure imply that the left-hand side has nonzero probability (which corresponds to the consequent of \cref{tautology1} being false) while every term on the right-hand side has zero probability (which corresponds to the antecedent of  \cref{tautology1} begin true).
%This is a causal compatibility inequality for the inflated DAG.  It can be used to demonstrate the incompatibility of the marginal distributions of Eqs.~\eqref{W4}-\eqref{W7} with the inflated DAG because these marginal distributions assing probability 0 to all terms on the right-hand side, while these together with the causal structure imply a nonzero probability for the term on the left-hand side.  
But, of course, the inequality can witness many other incompatibilities in addition to this one.

%The truth of the proposition $[U_i = u_i]$ implies that the marginal possibilistic assignment $S_{\bm{U}_1}$ must judge the joint valuation $u_i$ to be possible.  Consequently, any logical tautology in terms of such propositions can be understood as a constraint on the marginal possibilistic assignments. 

As another example, consider the marginal problem where the variables are $\{ A,B,C\}$, with each being binary, and the contexts are the pairs $\{AB\}$, $\{AC\}$, and $\{BC\}$.  
%where the pairwise joint distributions of three variables $A$, $B$ and $C$ are given. %, and these two variables are binary with values in $\{0,1\}$. 
The following tautology provides a constraint on marginal possibilistic assignments:
%A possibilistic constraint that follows from logic alone, and therefore is true regardless of the joint distribution over $A, B, C$, is this one:
%One Hardy-type possibilistic constraint which we would want to enumerate is
\begin{align}
%    \bracks{\mgreen{A \eql a}, \mgreen{C \eql c}} \implies \bracks{\mgreen{A \eql a}, B \eql b} \bigvee \bracks{B \eql \n{b}, \mgreen{C \eql c}}
\diamond \bracks{\mgreen{A \eql 1}, \mgreen{C \eql 1}} \implies \diamond \bracks{\mgreen{A \eql 1}, B \eql 1} \lor  \diamond \bracks{B \eql 0, \mgreen{C \eql 1}}.
\end{align}
(To see that this is a tautology, simply note that $E \land F  \implies  E \land F \land (G \lor \lnot G) = (E \land F \land G) \lor (E\land F \land \lnot G) \implies (E \land G) \lor (F \land \lnot G)$ and that if $X \implies Y$ then $\diamond X \implies \diamond Y$ and that $\diamond (W \lor Z) = \diamond W \lor \diamond Z$. \color{red} Check that I've got my modal logic right.\color{black}) 
Applying the union bound, one obtains the following constraint on marginal distributions\footnote{This inequality is in fact equivalent to \cref{eq:polymonogamyraw}.}
\begin{align}\label{eq:trivmarginalconstraintV2}
	P_{AC}(\mgreen{1 1}) \leq P_{AB}(\mgreen{1} 1) + P_{BC}(0 \mgreen{1}).
\end{align}
\color{purple}
[New modal version]
\begin{align}\label{eq:trivmarginalconstraintV3}
	S_{AC}(\mgreen{1 1}) \leq \text{max}\{ S_{AB}(\mgreen{1} 1) ,S_{BC}(0 \mgreen{1})\}.
\end{align}
\color{black}

In this section, we seek to determine, for any marginal scenario, the set of \emph{all} inequalities that can be derived in this manner.  We do so by \tblue{enumerating} the full set of constraints on marginal possibilistic assignments for the given marginal scenario.
% that arise in a given marginal problem.



We outline the general procedure using 
%a slightly more sophisticated example than the one provided above. Consider 
the marginal scenario of~\cref{fig:simplicialcomplex222}, where the full set of variables is $\{ A_1, A_2, B_1, B_2, C_1, C_2\}$ and the contexts are $\{A_1 B_1 C_1\}$, $\{A_1 B_2 C_2\}$, $\{A_2 B_1 C_2\}$, $\{A_2 B_2 C_1\}$ and $\{A_2 B_2 C_2\}$, pursuant to \cref{eq:basicsetup222}.
%\begin{align*}
%	\{A_1 B_1 C_1\},\\
%	\{A_1 B_2 C_2\},\\
%	\{A_2 B_1 C_2\},\\
%	\{A_2 B_2 C_1\},\\
%	\{A_2 B_2 C_2\}.
%\end{align*}
As before, we will express the constraints on marginal possibilistic assignments as logical implications with
%Now a possibilistic constraint on this marginal problem consists of a logical implication with 
a joint valuation of one of the contexts as the \tblue{antecedent} and a disjunction over contexts of joint valuations thereon as the \tblue{consequent}. In the following, we explain how to generate \emph{all} such implications which are tight in the sense that the consequent is minimal, i.e., involves as few terms as possible in the disjunction. 
%ir right-hand sides are minimal.

First, we fix the antecedant by choosing some context and a joint valuation of its variables. In order to generate all contraints on marginal possibilistic assignments, one will have to perform this procedure for \emph{every} context as the antecedent and every choice of joint valuation thereof. For the sake of concreteness, we take the example of $\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$ as the antecedent.  
Each logical implication we consider is required to have the property 
%The consequent will be a disjunction over contexts of joint valuations for each context, with the additional property
 that any variable that appears in both the antecendent and the consequent must be given the same value in both. 
%all outcomes of variables that also occur in the antecedent carry the same outcome. 
%For the implication to be valid, the consequent must further be such that \tred{for any \emph{joint} composite outcome which extends the antecedent's marginal composite outcome, also at least one of the marginal composite outcomes in the consequent must occur.}

To formally determine all valid consequents, we first consider two hypergraphs. %Take the set of nodes to be the disjoint union over all the contexts of all the joint outcomes which are compatible with~\eqref{eq:lhshardy}\footnote{In the left-hand side context there will thus be only one node, and one can also omit this one node without changing the result.}. 
The nodes in the first hypegraph correspond to every possible joint valuation of the variables in a context for every possible context.
The hyperedges correspond to every possible joint valuation of all the variables. A hyperedge (joint valuation) contains a node (marginal joint valuation) iff the hyperedge is an extension of the node; for example the hyperedge $\bracks{A_1 \eql 0, \mgreen{A_2 \eql 1}, B_1 \eql 0, \mgreen{B_2 \eql 1}, C_1 \eql 1, \mgreen{C_2 \eql 1}}$ is an extension of the node $\bracks{A_1 \eql 0,  \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$. In our example following \cref{fig:simplicialcomplex222}, this initial hypergraph has $5\cdot 2^3 = 40$ nodes and $2^6 = 64$ hyperedges.

The second hypergraph is a sub-hypergraph of the first one. We delete from the first graph all nodes and hyperedges which contradict the outcomes supposed by the antecedent. For example, the node $\bracks{\mgreen{A_2 \eql 1}, \mred{B_2 \eql 0}, C_1 \eql 1}$ contradicts the antecedent $\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$. We also delete the node corresponding to the antecedent itself. In our example, this final resulting hypergraph has $2^3 + 3\cdot 2^1 = 14$ nodes and $2^3 = 8$ hyperedges.

All valid (minimal) consequents are (minimal) \tblue{transversals} of this latter hypergraph. A transversal is a set of nodes which has the property that it intersects every hyperedge in at least one node. In order to get implications which are as tight as possible, it is sufficient to enumerate only the minimal transversals. Doing so is a well-studied problem in computer science with various natural reformulations and for which manifold algorithms have been developed~\cite{eiter_dualization_2008}.

%It is then possible right-hand sides of the implications are precisely the \tblue{transversals} of this hypergraph, i.e.~the sets of nodes which have the property that they intersect every hyperedge in at least one node. In order to get implications which are as tight as possible, it is sufficient to enumerate only the \tblue{minimal transversals}. Doing so is a well-studied problem in computer science with various natural reformulations and for which manifold algorithms have been developed~\cite{eiter_dualization_2008}. We expect that this enumeration of minimal transversals will be computationally much more tractable than the linear quantifier elimination, even if one does it for every possible left-hand side of the implication.

In our example, it is not hard to check that the consequent of
\begin{align}\begin{split}\label{eq:F3implicationform}
	\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}} \quad\Longrightarrow\quad &\bracks{A_1 \eql 0, B_1 \eql 0, C_1 \eql 0} \lor \bracks{A_1 \eql 1, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}} \\
	\lor\: & \bracks{\mgreen{A_2 \eql 1}, B_1 \eql 1, \mgreen{C_2 \eql 1}} \lor \bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, C_1 \eql 1}
\end{split}\end{align}
is such a minimal transversal: every assignment of values to all variables which extends the assignment on the left-hand side satisfies at least one of the terms on the right, but this ceases to hold as soon as one removes any one term on the right. 

We convert these implications into inequalities in the usual way via the union bound (i.e., replacing ``$\Rightarrow$'' by ``$\leq$'' at the level of probabilities and the disjunctions by sums). For example the constraint on marginal possibilistic assignments \cref{eq:F3implicationform} translates to the constraint on marginal distributions
\begin{align}\label{eq:F3rawprobform}
%    P_{A_2 B_2 C_2}\parens{\mgreen{a_2} \mgreen{b_2} \mgreen{c_2}} \leq \p{\n{a_1} \n{b_1} \n{c_1}}+\p{a_1 \mgreen{b_2 c_2}}+\p{\mgreen{a_2} b_1 \mgreen{c_2}}+\p{\mgreen{a_2 b_2} c_1}
    P_{A_2 B_2 C_2}\parens{\mgreen{1} \mgreen{1} \mgreen{1}} \leq P_{A_1 B_1 C_1}\parens{0 0 0}+P_{A_1 B_2 C_2}\parens{1 \mgreen{1 1}}+P_{A_2 B_1 C_2}\parens{\mgreen{1} 1 \mgreen{1}}+P_{A_2 B_2 C_1}\parens{\mgreen{1 1} 1}.
\end{align}
%\[
%	P_{A_2 B_2 C_2}(111) \leq P_{A_1 B_1 C_1}(000) + P_{A_1 B_2 C_2}(111) + P_{A_2 B_1 C_2}(111) + P_{A_2 B_2 C_1}(111).
%\]
Note that \cref{eq:F3rawprobform} is a strengthening of \cref{eq:F3rawweak}.  \cref{eq:F3rawprobform} was used earlier in this article as the starting point of our third example of how to derive a causal compatibility inequality for the Triangle scenario, in Sec.~\ref{Sec:DerivingInequalities} (see \cref{eq:FritzF3raw}). Because \cref{eq:F3implicationform} is the progenitor of this inequality, it can be thought of as the progenitor of the causal compatibility inequality that one derives from it, namely, \cref{eq:FritzF3}.  


Inequalities on marginal distributions that one derives from hypergraph transversals are generally weaker than those that result from a complete solution of the marginal problem. Nevertheless, many Bell inequalities are of this form---such as the CHSH inequality which follows in this way from the possibilistic constraints used in Hardy's version of Bell's theorem \cite{Ghirardi08}.  So it seems that this method is still sufficiently powerful to generate plenty of interesting inequalities. At the same time, it should be significantly easier to perform in practice than the full-fledged linear (let alone nonlinear) quantifier elimination, even if one does it for every possible antecedent.

In conclusion, linear quantifier elimination is the preferable tool for deriving inequalities for the marginal problem whenever it is computationally tractable; but whenever it is not, then enumerating hypergraph transversals presents a good alternative. %: \cref{eq:trisimplestunmapped} here corresponds to Eq. (2-4) in~\cite{Pitowsky1989}%, and \cref{eq:bellcondeq} here corresponds to Eq. (30) in Ref. \cite{Ghirardi08}

\end{comment}