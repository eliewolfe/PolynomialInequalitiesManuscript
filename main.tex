\documentclass[aps,english,superscriptaddress,onecolumn,twoside,longbibliography,pra,floatfix,fleqn,nofootinbib]{revtex4-1}%

% packages
\usepackage[OT1]{fontenc}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[intlimits,fleqn]{amsmath}
\usepackage{bm}
\usepackage{graphicx}
\usepackage[normalem]{ulem} %for sout
\usepackage{paralist}
\usepackage{microtype}
\usepackage{float}% (not with floatrow)
\usepackage{wrapfig}
\usepackage{verbatim} %for comment command
\usepackage{array}
\usepackage{ragged2e}%for justifying text in tables
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{showkeys}
\usepackage[intlimits,fleqn]{mathtools} %for mathclap and prescript and more. Learning to love this package. And DeclarePairDelimeter!

% tables stuff
\newcolumntype{R}{>{\raggedleft\arraybackslash}X}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\newcolumntype{J}{>{\justifying\arraybackslash}X}
\usepackage{adjustbox}
\usepackage{multirow}
\newcolumntype{T}[2]{%
    >{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
    l%
    <{\egroup}%
}
\setcounter{MaxMatrixCols}{30}

% colours and hyperlink stuff
\usepackage[usenames,dvipsnames]{xcolor}
\definecolor{purple}{RGB}{128,0,128}
\definecolor{ultramarine}{RGB}{63, 0, 255}
\definecolor{medblue}{RGB}{0, 0, 100}
\definecolor{panblue}{RGB}{0,24,150}
\definecolor{carmine}{RGB}{150, 0, 24}
\definecolor{gray}{RGB}{150, 150, 150}
\usepackage[breaklinks=true]{hyperref}
\hypersetup{colorlinks,
linkcolor=carmine,
citecolor=medblue,
urlcolor=panblue,
anchorcolor=OliveGreen}

% coloured text
\newcommand*{\mred}[1]{{\color{RawSienna}{\mathbf{#1}}}}
\newcommand*{\mgreen}[1]{{\color{OliveGreen}{\mathbf{#1}}}}
\newcommand*{\tred}[1]{{\color{carmine}{\textbf{#1}}}}
\newcommand*{\tblue}[1]{{\color{MidnightBlue}{\textbf{#1}}}}
\newcommand*{\tpurp}[1]{{\color{Plum}{\textbf{#1}}}}

% cleveref stuff
\usepackage[capitalise]{cleveref}
\Crefname{eqs}{Eqs.}{Eqs.}
\creflabelformat{eqs}{(#2#1#3)}
\crefrangelabelformat{equation}{(#3#1#4-#5#2#6)}
\Crefmultiformat{equation}{Eqs.~(#2#1#3}{,#2#1#3)}{,#2#1#3}{,#2#1#3)}
\crefrangelabelformat{eqs}{(#3#1#4-#5#2#6)}
\Crefmultiformat{eqs}{Eqs.~(#2#1#3}{,#2#1#3)}{,#2#1#3}{,#2#1#3)}
\Crefname{example}{Example}{Examples}
\Crefname{section}{Sec.}{Secs.}

% theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{remark}[theorem]{Remark}

% macros for our notation
\newcommand{\p}[2][]{{P_{#1}}\parenths{#2}}
\newcommand{\pfunc}[1]{P_{#1}}
\newcommand{\An}[2][]{{\mathsf{An}_{#1}}\parenths{#2}}
\newcommand{\Pa}[2][]{{\mathsf{Pa}_{#1}}\parenths{#2}}
\newcommand{\Ch}[2][]{{\mathsf{Ch}_{#1}}\parenths{#2}}
\newcommand{\SmallNamedFunction}[3][]{\operatorname{\mathsf{#2}}_{#1}\parenths{#3}}
\newcommand{\subgraph}[2][]{\SmallNamedFunction[#1]{SubDAG}{#2}}
\newcommand{\ansubgraph}[2][]{\SmallNamedFunction[#1]{AnSubDAG}{#2}}
\newcommand{\nodes}[1]{\SmallNamedFunction{Nodes}{#1}}
\newcommand{\obsnodes}[1]{\SmallNamedFunction{ObservedNodes}{#1}}
\newcommand{\latnodes}[1]{\SmallNamedFunction{LatentNodes}{#1}}
\newcommand{\edges}[1]{\SmallNamedFunction{Edges}{#1}}
\newcommand{\aindep}{\perp} % for d-separation
\newcommand{\indep}{\perp\!\!\!\!\perp} % (conditional) independence
\newcommand{\cramp}[1]{\ensuremath{\mathord{#1}}}
\newcommand{\eql}{\cramp{=}}
\newcommand{\neql}{\cramp{\neq}}
\DeclarePairedDelimiter{\parens}{\lparen}{\rparen}
\DeclarePairedDelimiter{\parenths}{\lparen}{\rparen}
\DeclarePairedDelimiter{\braces}{\lbrace}{\rbrace}
\DeclarePairedDelimiter{\bracks}{\lbrack}{\rbrack}
\DeclarePairedDelimiter{\expec}{\langle}{\rangle}
\newcommand{\brackets}[1]{\braces*{#1}}

% more vertical spacing in multiline equations
\setlength{\jot}{6pt}





\begin{document}

\title{The Inflation Technique for Causal Inference with Latent Variables}

\author{Elie Wolfe}
\email{ewolfe@perimeterinstitute.ca}
\affiliation{Perimeter Institute for Theoretical Physics, Waterloo, Ontario, Canada, N2L 2Y5}

\author{Robert W. Spekkens}
\email{rspekkens@perimeterinstitute.ca}
\affiliation{Perimeter Institute for Theoretical Physics, Waterloo, Ontario, Canada, N2L 2Y5}

\author{Tobias Fritz}
\email{fritz@mis.mpg.de}
\affiliation{Perimeter Institute for Theoretical Physics, Waterloo, Ontario, Canada, N2L 2Y5}
\affiliation{Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany}

\date{\today}


\begin{abstract}

The fundamental problem of causal inference is to determine whether or not a given probability distribution over observed variables is compatible with some causal structure. In the presence of latent variables, this is a challenging problem for which checking conditional independences is not enough. We here introduce a technique for witnessing the incompatibility of a given distribution with a given causal structure containing latent variables. It consists of  {\em inflating} the causal structure to a new one that can contain multiple copies of each of the original variables.

It is also desirable to derive inequalities whose violation by a distribution witnesses the incompatibility of that distribution with the causal structure. Prominent examples of such ``causal compatibility inequalities'' are Bell inequalities and Pearl's instrumental inequality.
Our inflation technique is also of relevance here: by construction, any causal compatibility inequality on the inflated structure can be translated into one for the original structure. By introducing additional $d$-separation relations, inflation often generates easy opportunities for such translations, and already the mere \emph{existence} of a joint distribution on the inflated structure usually results in nontrivial causal compatibility inequalities.
We demonstrate the technique's power by numerically classifying the causal compatibility inequalities that it entails for a particular concrete example---an inflation of the Triangle scenario with binary variables---obtaining a set of causal compatibility inequalities that are at least partly stronger than existing ones.
Finally, we discuss how to identify, among the causal compatibility inequalities that the technique yields, those that remain valid even for quantum (and post-quantum) generalizations of the notion of a causal model.
\end{abstract}

\maketitle
\tableofcontents

\section{Introduction}

Given a joint probability distribution of some observed variables, the problem of \tblue{causal inference} is to determine which hypotheses about the causal mechanism can explain the given distribution. Here, a causal mechanism may comprise both causal relations among the observed variables, as well as among these and a number of unobserved variables.
%what causal relations could hold among the set of variables that includes these as well as a putative set of unobserved variables that act upon them. 
%, among the observed variables themselves or among these and a putative set of unobserved variables, could  this distribution.
%among these variables and possibly also some unobserved variables could have generated this distribution.
 Causal inference problems arise in a wide variety of scientific disciplines, from sussing out biological pathways to enabling machine learning \cite{pearl2009causality,spirtes2011causation,studeny2005probabilistic,koller2009probabilistic}. A closely related type of problem is to determine, for a given set of causal relations, the set of all distributions of observed variables that can be generated from them.   
A special case of both problems is the following decision problem: given a probability distribution and a hypothesis about the causal relations, determine whether the two are compatible---could the given distribution have been generated by the hypothesized causal relations? This is the problem that we focus on.
%solving the decision problem and for 
We develop necessary conditions for a given distribution to be compatible with a given hypothesis about the causal relations.

%\tblue{infeasibility criteria}, i.e., observable constraints such that the their violation implies the invalidity of the hypothesis as an explanation for observational data. 

In the simplest setting, the causal hypothesis consists of a directed acyclic graph (DAG) {\em all} of whose nodes correspond to observed variables. In this case, obtaining a verdict on the compatibility of a given distribution with the causal hypothesis is simple: the compatibility holds if and only if the distribution is Markov with respect to the DAG, which is to say that the distribution features all of the conditional independence relations asserted by $d$-separation with respect to the DAG. 
The compatible DAGs can be determined algorithmically solely from the distribution~\cite{pearl2009causality}.
%. \sout{ i.e.~without having an \emph{a priori} hypothesis}

A significantly more difficult case is when one considers a causal hypothesis which consists of a DAG whose nodes include \tblue{latent} (i.e., unobserved) variables, so that the set of observed variables is a strict subset of the nodes of the DAG. This case occurs, e.g.,~in situations where one needs to deal with the possible presence of unobserved confounders, and thus is particularly relevant for experimental design in statistics. It is useful to distinguish two varieties of this problem: (i) the causal hypothesis specifies that the latent variables are discrete and of a particular cardinality\footnote{The cardinality of a variable is the number of possible values it can take.}, and (ii) the nature of the latent variables is arbitrary.  

Consider the first variety of causal inference problem, where the cardinalities of all the latent variables are finite. Then the mathematical problem which one must solve to infer the distributions that are compatible with the hypothesis is a quantifier elimination problem for some finite number of quantifiers, as follows. The probabilities making up the distribution of the observed variables can all be expressed as functions of the parameters specifying the conditional probabilities of each node given its parents, many of which involve latent variables. If one can eliminate these 
%unobservable 
parameters, then one obtains constraints that refer exclusively to the probability distribution of the observed variables.  This is a {\em nonlinear} quantifier elimination problem. The Tarski-Seidenberg theorem provides an \emph{in principle} algorithm for an exact solution, but unfortunately the computational complexity of such quantifier elimination techniques is too large to be practical, except in particularly simple scenarios~\cite{LeeSpekkens}.\footnote{Techniques for finding approximate solutions to nonlinear quantifier elimination may help~\cite{ChavesPolynomial}.}

The second variety of causal inference problem, where the latent variables are arbitrary, is even more difficult, but it is the one that has been the focus of most research and that motivates the present work. It is conceivable that inference problems of this variety can be expressed as quantifier elimination problems as well. This would be the case, for instance, if one could show that latent variables of a certain finite cardinality (as opposed to arbitrary latent variables) are sufficient to generate all the distributions compatible with a given DAG\footnote{\citet{rosset2016finite} have an unpublished proof purporting to upper bound the cardinality of the latent variables for the Triangle scenario (\cref{fig:TriMainDAG}) using an observation that may apply to all DAGs. We do not pursue the question here.}. At present, however, the problem of finding an algorithm for deciding compatibility in this second case---let alone an efficient algorithm---remains wide open.  Nonetheless, even if it {\em is} possible to achieve a reduction to the case of latent variables with finite cardinality, one would still be faced with a computationally impractical nonlinear quantifier elimination problem, as described above. As such, a heuristic technique for obtaining nontrivial constraints, such as the one presented in this work, is arguably more useful.  
%more important in practice. 

If one allows for latent variables, then the condition that all of the conditional independence relations among the observed variables should be explained by the structure of the DAG is still a necessary condition for compatibility of a DAG with a given distribution, but in general it is no longer a sufficient condition for compatibility, and this is what makes the problem difficult. Historically, the insufficiency of the conditional independence relations in the presence of latent variables was first noted by Bell in the context of the hidden variable problem in quantum physics~\cite{bell1964einstein}. Bell considered a thought experiment for which considerations from relativity theory implied a very particular causal based on the causal structure only. The CHSH inequality was the first example of a compatibility condition that appealed to the strength of the correlations rather than simply the conditional independence relations inherent therein.  Since then, many generalizations of the CHSH inequality have been derived for the same sort of causal structure~\cite{Brunner2013Bell}. The idea that such work is best understood as a contribution to the field of causal inference has only recently been put forward~\cite{WoodSpekkens,fritz2012bell,pusey2014gdag,BeyondBellII}, as has the idea that techniques developed by researchers in the foundations of quantum theory may be usefully adapted to causal inference\footnote{The current article being another example of the phenomenon \cite{BeyondBellII,ChavesNoSignalling,chaves2014informationinference,weilenmann2016entropic,kela2016covariance,ChavesPolynomial,TavakoliStarNetworks,RossetNetworks,TavakoliNoncyclicNetworks}.}.

Subsequent to Bell's work, Pearl derived the \tblue{instrumental inequality}~\cite{pearl1995instrumental}, which provides a necessary condition for the compatibility of a distribution with a causal structure 
known as the \emph{instrumental scenario}.  This causal structure is applicable, for instance, to certain kinds of noncompliance in drug trials. Later, \citet{steudel2010ancestors} derived an inequality which must hold whenever a distribution on $n$
variables is compatible with a causal structure where no set of more
than $c$ variables has a common ancestor, for arbitrary $n,c \in \mathbb{N}$. More recent work has focused specifically on the case of $n=3$ and $c=2$, a causal structure that has been called the Triangle scenario~\cite{fritz2012bell,chaves2014novel} (\cref{fig:TriMainDAG}).

Recently, Henson, Lal and Pusey~\cite{pusey2014gdag} have investigated those DAGs for which displaying the expected conditional independence relations does not guarantee the compatibility of a distribution on observed variables with the DAG, for which they coined the term \emph{interesting}. They presented a catalogue of all potentially interesting DAGs having six or fewer nodes in~\cite[App.~E]{pusey2014gdag}, of which all but three were shown to be indeed interesting. The Bell scenario, the Instrumental scenario, and the Triangle scenario all appear in the catalogue together with many others.   Furthermore, the fraction of DAGs that are interesting increases as the total number of nodes increases.  This highlights the need for moving beyond a case-by-case consideration of individual DAGs and for developing techniques for deriving constraints beyond conditional independence relations that can be applied to any interesting DAG. 
Shannon-type entropic inequalities are an example of such constraints~\cite{steudel2010ancestors,fritz2012bell,fritz2013marginal,chaves2014novel,chaves2014informationinference}. They can be derived for a given DAG with relative ease, via exclusively linear quantifier elimination, since conditional independence relations are linear equations at the level of entropies. They also have the advantage that they apply regardless of the cardinality of the observable variables. Recent work has also looked at non-Shannon type inequalities, potentially further strengthening the entropic constraints~\cite{weilenmann2016entropic,pianaar2016interesting}. However, entropic techniques are still wanting, since the resulting inequalities are often rather weak. For example, they are not sensitive enough to distinguish witness nonclassical quantum correlations as nonclassical~\cite{fritz2012bell,weilenmann2016entropic}\footnote{It should be noted that non-standard entropic inequalities can be obtained through a fine-graining of the causal scenario, namely by \emph{conditioning} on the distinct finite possible outcomes of root variables (``settings''), and these types of inequalities \emph{have} proven somewhat quantum-sensitive \cite{braunstein1988entropic,SchumacherInequality,chaves2014novel}. Such inequalities are still limited, however, in that they are only applicable to those DAGs which feature observable root nodes. The potential utility of entropic analysis where fine-graining is generalized to \emph{non}-root observable nodes is currently being explored by E.W. and Rafael Chaves. Jacques Pienaar has also alluded to similar considerations as a possible avenue for further research~\cite{pianaar2016interesting}.}.

%In contexts other than quantum theory, the latent nodes in causal structures are generally taken to represent hidden variables. This is not fully general, however, so we apply the retronym\footnote{Retronym (noun): a modification of an original term to distinguish it from a later development \cite{retronym}.} ``classical", as in classical causal structure and classical causal inference. The classical distributions of a given causal structure are defined as those which arise from it while restricting the latent nodes to be arbitrary (classical) random variables. Quantum distributions, by contrast, are those which are realizable if the latent nodes in the causal structure are allowed to be quantum systems. We hereafter take all causal structures and probability distributions to be classical, except where explicitly stated otherwise.

%From a physics perspective, therefore, tightly characterizing the set of observable probability distributions realizable from a causal structure is critical, in order to recognize and exploit the existence of distributions that can be realized quantumly but not classically. Few techniques are known for bounding this set of distributions which are simultaneously practical and applicable to general causal structures. Celebrated examples include the use of conditional independence relations (easy) \cite{pearl2009causality,spirtes2011causation,studeny2005probabilistic,koller2009probabilistic} and entropic inequalities (more advanced) \cite{fritz2013marginal,chaves2014novel,chaves2014informationinference}. In the presence of hidden variables, these criteria only rarely provide a tight characterization, and frequently fail to witness the non-classicality of quantum distributions.% Indeed, all the causal scenarios we shall consider here are instances where conventional causal compatibility criteria are found to be insufficient 

%Distinguishing quantum from classical correlations has historically been achieved through the use of Bell inequalities \cite{bell1966lhvm,GisinFramework2012,scarani2012device,Brunner2013Bell,BancalDIApproach}. Bell inequalities, however, are limited to very special causal scenarios involving \emph{only one} latent common cause variable, i.e.~Bell scenarios. A Bell scenario is also very special in that its realizable distributions admit characterization by a finite set of linear inequalities (after conditioning on the setting variables), i.e.~its realizable distributions comprise a convex polytope \cite{GisinFramework2012,FritzDuality}. %The nonconvexity of distributions realizable from a general structure is explicitly evidenced here. 
%Entirely new techniques, therefore, are required to derive quantum-sensitive incompatibility witnesses for more general causal scenarios \cite{fritz2012bell,pusey2014gdag,BeyondBellII}. 

In order to improve this state of affairs, we here introduce a new technique for deriving necessary conditions for the compatibility of a distribution over observed variables with a given causal structure, which we term the {\em inflation technique}. Our technique is frequently capable of witnessing incompatibility when many other causal inference techniques fail. For example, in \cref{example:noWdist} of \cref{subsec:witnessingincompat} we prove that the tripartite ``W-type'' distribution is incompatible with the Triangle scenario, despite the incompatibility being invisible to other causal inference tools such as conditional independence relations, Shannon-type~\cite{fritz2013marginal,chaves2014novel,chaves2014informationinference} or non-Shanon-type entropic inequalities~\cite{weilenmann2016entropic}, or covariance matrices~\cite{kela2016covariance}.


The inflation technique works roughly as follows. For a given DAG under consideration, one can construct many new DAGs, termed {\em inflations} of this DAG. These duplicate one or more of the nodes of the original DAG, while preserving the subgraph describing each node's ancestry.
%their ancestral subgraph.  
Furthermore, the causal parameters that one adds to the inflated DAG are constrained to mirror those of the original DAG.  We show that if the distributions over certain subsets of the observed variables are compatible with the original DAG, then the same distributions over certain copies of those subsets in the inflated DAG are compatible with the inflated DAG (\cref{mainlemma}).  Similarly, we show that any necessary condition for compatibility of a distribution with the inflated DAG translates into a necessary condition for compatibility with the original DAG (\cref{maincorollary}).  Thus standard techniques for deriving inequalities, applied to the inflated DAG,  can be supplemented with the inflation technique to derive new inequalities for the original DAG.  Concretely, we consider inequalities on the inflated DAG that are obtained from the \emph{mere existence of a joint distribution} on the inflated DAG, supplemented with independence constraints arising from the inflated causal structure.   We show how to derive a complete set of such inequalities by enumerating all facets of the associated \tblue{marginal polytope} (\cref{sec:CCineqs}). We also show how to compute a partial solution more efficiently by enumerating transversals of a certain hypergraph (\cref{sec:TSEM}). Translating either of these inequalities back to the original DAG results in causal compatibility conditions in the form of nonlinear \emph{polynomial inequalities}.
% An inflated DAG naturally carries inflated models, and the existence of an inflated model implies inequalities which constrain the set of distributions on observable nodes compatible with the original causal structure. Polynomial inequalities can be obtained through \emph{linear} inequalities which are necessary conditions for a collection of given marginal distributions to arise from a joint distribution (marginal problem). For deriving such inequalities in turn, we have considered the methods of computing all facets of the marginal polytope via facet enumeration, and deriving looser constraints more efficiently by enumerating hypergraph transversals.

%, in which case we say that the inequalities are \emph{polynomial}. 
%Together with 
Besides the entropic techniques discussed above, our method is the first systematic tool for causal inference with latent variables that goes beyond observable conditional independence relations while not assuming any bounds on the cardinality of each latent variable. While our method can be used to systematically generate necessary conditions for compatibility with a given causal structure, we do not know whether the set of inequalities thus generated are also sufficient.  
%, and we currently have conflicting evidence on this question. On the one hand, our method rederives all Bell-type inequalities (\cref{sec:Bellscenarios}), but on the other hand 

% We show how the no-broadcasting theorem governing quantum theory \cite{NoCloningQuantum1996,NoCloningGeneral2006} can be exploited in order to derive specifically quantum-sensitive infeasibility criteria.
While we present our technique primarily as a tool for standard causal inference, we also briefly discuss applications to {\em quantum} causal models and causal models within generalized probabilistic theories (\cref{sec:classicallity}).  In particular, we discuss when our inequalities are also necessary conditions for a distribution over observed variables to be compatible with a given DAG within any generalized probabilistic theory. 

%\color{purple} [R: provide summary of paper] \color{black}

%While we present our technique primarily as a tool for standard causal inference, we also  comment on the extent to which the inequalities we derive are also necessary conditions on the compatibility of a distribution with a DAG for nonclassical generalizations of the notion of a causal model \cite{fritz2012bell,pusey2014gdag,chaves2014informationinference,BeyondBellII}.Some of the inequalities we derive require us to imagine that the value of a hidden variable can be distributed or \emph{broadcast} to many different observed variables.  The no-broadcasting theorem from quantum theory shows that this is not valid in the non-classical case, and from our perspective this is the reason for the existence of quantum violations of Bell inequalities. Moreover, our technique can also be applied in order to derive criteria that must be satisfied by all distributions that can be generated with latent nodes that are states in quantum theory or any other general probabilistic theory, simply by not assuming the possibility of broadcasting. 


%\section{Notation}
\section{Basic definitions of causal models and compatibility}\label{sec:definitions}

A \tblue{causal model} consists of a pair of objects: a \tblue{causal structure} and a family of \tblue{causal parameters}.  We define each in turn. 
%The causal structure specifies a directed acyclic graph (DAG).  Recall that a DAG $G$ 
First, recall that a directed acyclic graph (DAG) $G$ consists of a finite set of nodes $\nodes{G}$ and a set of directed edges $\edges{G}$, where a directed edge is an ordered pair of nodes, so that $\edges{G}\subseteq\nodes{G}\times\nodes{G}$. This directed graph is assumed to be \emph{acylic}, which means that there is no way to start and end at the same node by traversing edges forward.
%Later, each node will carry 
 In the context of a causal model, each node $X\in\nodes{G}$ carries a random variable that we denote by the same letter $X$. A directed edge $X\to Y$ corresponds to the possibility of a direct causal influence from the variable $X$ to the variable $Y$. In this way, the edges implement causal relations.

Our terminology for the causal relations between the nodes in a DAG is the standard one. The parents of a node $X$ in $G$ are defined as those nodes from which an outgoing edge terminates at $X$, i.e.~$\Pa[G]{X} = \{\:Y\:|\:Y\to X\:\}$. When the graph $G$ is clear from the context, then we also omit the subscript. Similarly, the children of a node $X$ are defined as those nodes at which edges originating at $X$ terminate, i.e.~$\Ch[G]{X} = \{\:Y\:|\: X\to Y\:\}$. If $\bm{U}$ is a set of nodes, then we put $\Pa[G]{\bm{U}} := \bigcup_{X\in\bm{U}} \Pa[G]{X}$ and $\Ch[G]{\bm{U}} := \bigcup_{X\in\bm{U}} \Ch[G]{X}$. The \tblue{ancestors} of a set of nodes $\bm{U}$, denoted $\An[G]{\bm{U}}$, are defined as those nodes which have a directed \emph{path} to some node in $\bm{U}$, including the nodes in $\bm{U}$ themselves\footnote{The inclusion of a node within the set of its ancestors is contrary to the colloquial use of the term ``ancestors''. 
%definition of ``ancestors'' the anti-colloquial self-inclusive definition of ``ancestors" here. 
One uses this definition so that any correlation between two variables can always be attributed to a common ``ancestor''. This includes, for instance, the case where one variable is a parent of the other.
% folding the case whence one variable is e.g.~a parent of the other into the umbrella of common ancestry.
}. 
 %{\color{purple} R: Does Pearl include $U$ among the ancestors?  I wonder if ``ancestry'' might be better terminology.} 
Equivalently, $\An{\bm{U}} := \bigcup_{n\in\mathbb{N}} \mathsf{Pa}^n(\bm{U})$, where $\mathsf{Pa}^n(\bm{U})$ is inductively defined via $\mathsf{Pa}^0(\bm{U}) := \bm{U}$ and $\mathsf{Pa}^{n+1}(\bm{U}) := \mathsf{Pa}(\mathsf{Pa}^n(\bm{U}))$. 

A \tblue{causal structure} is a DAG $G$ that incorporates a distinction between two types of nodes: the set of observed nodes $\obsnodes{G}$, and the set of latent nodes $\latnodes{G}$.  %Following Ref.~[HensonLalPusey], we will term a DAG that incorporates this distinction a {\em generalized DAG}, or GDAG, and we will denote the observed nodes by triangles and the latent nodes by circles. 
Following~\cite{pusey2014gdag}, we will depict the observed nodes by triangles and the latent nodes by circles, as in~\cref{fig:TriMainDAG}.
%~\footnote{Unlike Ref.~[HensonLalPusey], who term these {\em generalized DAGs}, we will continue to refer to them as simply DAGs. }  
Henceforth, we will use the terms ``DAG'' and ``causal structure'' interchangeably, so that the specification of which variables are observed is considered to be part of the DAG.
% , unless explicitly stated otherwise.
Frequently we supplement the causal structure by a specification of the cardinalities of the observed variables. While these are finite in all our examples, the inflation technique applies just as well in the case of continuous variables.
% at each node.
%Henceforth, we will assume that $G$ denotes not just a DAG, but also the information about which variables are observed and their cardinalities.
%whether it is continuous or discrete, and, if the latter, the cardinality of the set of possible values that the variable can take.

 The second component of a causal model is a family of \tblue{causal parameters}.
%Moving towards causal models, we consider \tblue{causal parameters}. 
The causal parameters specify, for each node $X$, the conditional probability distribution over the values of the random variable $X$, given the values of the variables $\Pa{X}$.  In the case of root nodes, we have $\Pa{X} = \emptyset$, and the conditional distribution is an unconditioned distribution.
We write $\pfunc{Y|X}$ for the conditional distribution of a variable $Y$ given a variable $X$, while the particular conditional probability of the variable $X$ taking the value $x$ given that the variable $Y$ takes the values $y$ is denoted\footnote{Although our notation suggests that all variables are either discrete or described by densities, we do not make this assumption.  All of our equations can be translated straightforwardly into proper measure-theoretic notation.} $\p[Y|X]{y|x}$.    Therefore, a family of causal parameters has the form
\begin{align}
 \{ \pfunc{A|\Pa[G]{A}} : A \in \nodes{G} \}.
\end{align}
Finally, a \tblue{causal model} $M$ consists of a causal structure together with a family of causal parameters,
\[
	M = ( G,   \{ \pfunc{A|\Pa[G]{A}} : A \in \nodes{G} \}).
\]
A causal model specifies a joint distribution of all variables in the DAG via
\begin{align}\label{Markov}
P_{\nodes{G}} = \prod_{A\in \nodes{G}} \pfunc{A|\Pa[G]{A}},
\end{align}
where $\prod$ denotes the usual product of functions, so that e.g.~$(P_{Y|X} \times P_Y)(x,y) := P_{Y|X}(y|x) P_X(x)$. A distribution $P_{\nodes{G}}$ arises in this way if and only if it satisfies the Markov conditions associated to $G$.

The joint distribution over the observed variables is obtained from the joint distribution over all variables by marginalization over the latent variables,
\begin{align}\label{MarkovObserved}
P_{\obsnodes{G}} =  \sum_{\{X :X \in\latnodes{G}\}} P_{\nodes{G}},
\end{align}
where $\sum_X$ denotes marginalization over the variable $X$, so that $(\sum_X P_{XY})(y):= \sum_x P_{XY}(xy)$.
%if $P_Y:=\sum_X P_{XY}$, then $P_Y(y) = \sum_x P_{XY}(xy)$.

A given distribution of observed variables is said to be \tblue{compatible} with a given causal structure if there is some choice of the causal parameters that yields the given distribution via Eqs.~\eqref{Markov} and \eqref{MarkovObserved}. Furthermore, a given set of marginal distributions on various subsets of observed variables is said to be compatible with a given causal structure if and only if there exists a joint distribution of observed variables that yields these marginals and is compatible with the causal structure.


%\section{Inflation: a tool for causal inference}
%\section{Witnessing incompatibility using the Inflation technique}
\section{The inflation technique for causal inference}

\subsection{Inflations of a causal model}

We now introduce the notion of \tblue{an inflation of a causal model}.  %Let $C_G$ denote a causal model associated to a DAG $G$.  
If a causal model lives on a DAG $G$, then an inflation of this model lives on an \tblue{inflation DAG} $G'$.  
%An inflation of this model is another causal model, denoted $C_{G'}$ and associated to a different DAG, $G'$.  
There are many possible choices of inflation DAGs $G'$ for a given $G$, forming a set $\SmallNamedFunction{Inflations}{G}$. The particular choice of $G'\in \SmallNamedFunction{Inflations}{G}$ then determines the inflation model completely: the family of causal parameters of the inflation model $M'$ is determined by a function $M' = \SmallNamedFunction[G\to G']{Inflation}{M}$ that we define below. We begin by defining when a DAG $G'$ is an inflation of $G$, building on some preliminary definitions. 

For a subset of nodes $\bm{V}\subseteq\nodes{G}$, we denote the \tblue{induced subgraph} on $\bm{V}$ by $\subgraph[G]{\bm{V}}$. It consists of the nodes $\bm{V}$ and those edges of $G$ which have both endpoints in $\bm{V}$. Of special importance to us is the 
\tblue{ancestral subgraph} $\ansubgraph[G]{\bm{V}}$, which is the subgraph induced by the ancestry of $\bm{V}$, $\ansubgraph[G]{\bm{V}}\coloneqq\subgraph[G]{\An[G]{\bm{V}}}$. 

In an inflation DAG $G'$, every node is also labelled by a node of $G$. More precisely, the structure of being an inflation DAG also comprises a map $G'\to G$. We call the preimages of a node $A\in\nodes{G}$ the \tblue{copies} of $A$ in $G'$, and denote them by $A_1,\ldots, A_k$. The subscript that indexes the copies is termed the \tblue{copy-index}, and the map $G'\to G$ consists in dropping the copy-index.  When two objects (e.g.~nodes, sets of nodes, DAGs, etc\ldots) are the same up to copy-indices, then we use $\sim$ to indicate this, as in $A_i\sim A_j\sim A$. In particular, $\bm{U}\sim\bm{U}'$ for sets of nodes $\bm{U}\subseteq\nodes{G}$ and $\bm{U}'\subseteq\nodes{G'}$ if and only if $\bm{U}'$ contains exactly one copy of every node in $\bm{U}$. Similarly, $\subgraph[G']{\bm{U}'}\sim\subgraph[G]{\bm{U}}$ means in addition that an edge is present between two nodes in $\bm{U}'$ if and only if it is present between the two associated nodes in $\bm{U}$.

In order to be an inflation, $G'$ must locally mirror the causal structure of $G$:
%, and a set of variables in $G'$ that differ only by copy-index are called a {\em copy set}.  
\begin{definition}
%The necessary condition on $G'$ for being an inflation of $G$ is that
	The DAG $G'$ is said to be an \tblue{inflation} of $G$, that is, $G' \in \SmallNamedFunction{Inflations}{G}$, if and only if for every $A_i\in\nodes{G'}$, the ancestral subgraph of $A_i$ in $G'$ is equivalent, under removal of the copy-index, to the ancestral subgraph of $A$ in $G$,
\begin{align}\label{eq:definflationDAG}
G' \in\SmallNamedFunction{Inflations}{G} \quad\text{ iff }\quad \forall A_i\in \SmallNamedFunction{Nodes}{G'}:\; \ansubgraph[G']{A_i}\sim\ansubgraph[G]{A}.
\end{align}
\end{definition}
%Given this notational convention, we can formalize the condition for $G'$ to be an inflation of $G$ as follows:

To illustrate the notion of inflation, we consider the DAG of \cref{fig:TriMainDAG}, which is called the {\em Triangle scenario} (for obvious reasons) and which has been studied by many authors [\citealp{pusey2014gdag}~(Fig.~E\#8), \citealp{WoodSpekkens}~(Fig.~18b), \citealp{fritz2012bell}~(Fig.~3), \citealp{chaves2014novel}~(Fig.~6a), \citealp{Chaves2015infoquantum}~(Fig.~1a), \citealp{BilocalCorrelations}~(Fig.~8), \citealp{steudel2010ancestors}~(Fig.~1b), \citealp{chaves2014informationinference}~(Fig.~4b)].
%As an example, consider the Triangle scenario [\citealp{pusey2014gdag}~(Fig.~E\#8), \citealp{WoodSpekkens}~(Fig.~18b), \citealp{fritz2012bell}~(Fig.~3), \citealp{chaves2014novel}~(Fig.~6a), \citealp{Chaves2015infoquantum}~(Fig.~1a), \citealp{BilocalCorrelations}~(Fig.~8), \citealp{steudel2010ancestors}~(Fig.~1b), \citealp{chaves2014informationinference}~(Fig.~4b)]. The associated DAG, the shape of which explains the name, is depicted here in \cref{fig:TriMainDAG}. 
%The Triangle scenario is a correlation scenario in the sense of \citet{fritz2012bell}; see especially Sec. 2.3 there. 
Different inflations of the Triangle scenario are depicted in \cref{fig:TriFullDouble,fig:Tri222,fig:simpleinflation,fig:simplestinflation,fig:TriDagSubA2B1C1}, which, for ease of reference, will be referred to as the {\em Web}, {\em Spiral}, {\em Capped}, and {\em Cut} inflations respectively.
%The spiderweb inflation of the triangle scenario (Fig. 2)
%The Spiral galaxy inflation of the triangle scenario (Fig. 3)
%The Capped inflation of the triangle scenario (Fig. 4)
%The Cut inflation of the triangle scenario (Fig. 5)

\begin{figure}[h]
\centering
\begin{minipage}[t]{0.23\linewidth}
\centering
\includegraphics[scale=1]{TriDagRawALT.pdf}
\caption{The Triangle scenario.}\label{fig:TriMainDAG}
\end{minipage}
\hfill
\begin{minipage}[t]{0.43\linewidth}
\centering
\resizebox{\textwidth}{!}{\includegraphics[scale=1]{TriDagFull222ALT.pdf}}
\caption{The Web inflation of the 
%An inflated DAG of the 
Triangle scenario where each latent node has been duplicated and each observable node has been quadrupled. The four copies of each observed node correspond to the four possible choices of parentage given the pair of copies of each latent parent of the observed node.}\label{fig:TriFullDouble}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\centering
\includegraphics[scale=1]{TriDagSub222fixedcoordALT.pdf}
\caption{The Spiral inflation of the Triangle scenario.  Notably, this DAG is the ancestral subgraph of the set $\{ A_1 A_2 B_1 B_2 C_1 C_2\}$ in the Web inflation (\cref{fig:TriFullDouble}).}
% also notably $\ansubgraph[(\textrm{\cref{fig:TriFullDouble}})]{A_1 A_2 B_1 B_2 C_1 C_2}$.}
 \label{fig:Tri222}
\end{minipage}
\end{figure}

\begin{figure}[hb]
\centering
\begin{minipage}[t]{0.3\linewidth}
\centering
\includegraphics[scale=1]{broadcastingexamplenohighlightALT.pdf}
\caption{The Capped inflation of the Triangle scenario; notably also the ancestral subgraph of the set $\{ A_1 A_2 B_1 C_1\}$ in the Spiral inflation (\cref{fig:Tri222}).}
%, also notably $\ansubgraph[(\cref{fig:Tri222})]{A_1 A_2 B_1 C_1}$.}
\label{fig:simpleinflation}
\end{minipage}\hfill
\begin{minipage}[t]{0.275\linewidth}
\centering
\includegraphics[scale=1]{nobroadcastingexamplenohighlightALT.pdf}
\caption{The Cut inflation of the Triangle scenario; notably also the ancestral subgraph of the set $\{ A_2 B_1 C_1\}$ in the Capped inflation (\cref{fig:simpleinflation}). Unlike the other examples, this inflation does not contain the Triangle scenario as a subgraph. 
%Despite not containing the original scenario, this is a valid inflation per~\cref{eq:definflationDAG}.
}\color{black}
%, also notably $\ansubgraph[(\cref{fig:simpleinflation})]{A_2 B_1 C_1}$. }
\label{fig:simplestinflation}
\end{minipage}
\hfill
\begin{minipage}[t]{0.325\linewidth}
\centering
\includegraphics[scale=1]{TriDagSubA2B1C1.pdf}
\caption{A different depiction of the Cut inflation of \cref{fig:simplestinflation}. }\label{fig:TriDagSubA2B1C1}
\end{minipage}
\end{figure}

We now define the function $\mathsf{Inflation}_{G\to G'}$, that is, we specify how causal parameters are defined for a given inflation DAG in terms of causal parameters on the original DAG.
%a causal model inflates.

\begin{definition}
\label[definition]{def:inflat}
Consider causal models $M$ and $M'$ where $\SmallNamedFunction{DAG}{M}=G$ and $\SmallNamedFunction{DAG}{M'}=G'$, where $G'$ is an inflation of $G$. Then $M'$ is said to be the {\em \tblue{$G\to G'$ inflation of $M$}}, that is, $M' = \SmallNamedFunction[G\to G']{Inflation}{M}$,  if and only if for every node $A_i$ in $G'$, the manner in which $A_i$ depends causally on its parents within $G'$ is the same as the manner in which $A$ depends causally on its parents within $G$.  Noting that $A_i \sim A$ and that $\Pa[G']{A_i} \sim \Pa[G]{A}$ by~\cref{eq:definflationDAG}, one can formalize this condition as:
\begin{align}\label{eq:funcdependences}
%M' = \SmallNamedFunction{Inflation}{M}_{G\to G'}  \quad \text{iff}\quad 
 \forall A_i \in \SmallNamedFunction{Nodes}{G'}:\; \pfunc{A_i| \Pa[G']{A_i}}=\pfunc{A|\Pa[G]{A}}.
\end{align}
%where Eq.~\eqref{eq:definflationDAG} guarantees that $A_i \sim A$ and $\Pa[G']{A_i} \sim \Pa[G]{A}$.  
\end{definition}

For a given triple $G$, $G'$, and $M$, this definition specifies a unique inflation model $M'$, resulting in a well-defined function ${\operatorname{\mathsf{Inflation}}_{G\to G'}}$. %$\SmallNamedFunction[G\to G']{Inflation}{-}$.

%A causal model specifies the causal structure and the autonomous causal mechanisms.  
To sum up, the inflation of a causal model is a new causal model where (i) each variable in the original DAG may have counterparts in the inflated DAG with ancestral subgraphs mirroring those of the originals, and (ii) the manner in which a variable depends causally on its parents in the inflated DAG is given by the manner in which its counterpart in the original DAG depends causally on its parents. The operation of modifying a DAG and equipping the modified version with conditional probability distributions that mirror those of the original also appears in the \emph{do calculus} and \emph{twin networks} of~\citet{pearl2009causality}, and moreover bears some resemblance to the \emph{adhesivity} technique used in deriving non-Shannon-type entropic inequalities (\cref{sec:NonShannon}).

We are now in a position to describe the key property of the inflation of a causal model, the one that makes it useful for causal inference. With notation as in \cref{def:inflat}, let %$P$ and $P'$ be the joint distributions over observed variables arising in a causal model $M$ and its inflation $M'$, respectively.  Finally, let
$P_{\bm{U}}$ and $P_{\bm{U}'}$ denote marginal distributions on some $\bm{U}\subseteq\nodes{G}$ and $\bm{U}'\subseteq\nodes{G'}$, respectively. Then
\begin{align}\label{eq:coincidingdistrodef}
%P'_{\bm{U}'}=P_{\bm{U}} 
\quad\text{if }\quad \bm{U}'\sim \bm{U} \;\;\text{and}\;\; \ansubgraph[G']{\bm{U}'}\sim\ansubgraph[G]{\bm{U}}, \quad\text{then}\quad P_{\bm{U}'}=P_{\bm{U}}.
\end{align}
This follows from the fact that the distributions on $\bm{U}'$ and $\bm{U}$ depend only on their ancestral subgraphs and the parameters defined thereon, which by the definition of inflation are the same for $\bm{U}'$ and for $\bm{U}$.
It is useful to have a name for those sets of observed nodes in $G'$ which satisfy the antecedent of~\cref{eq:coincidingdistrodef}, that is, for which one can find a copy-index-equivalent set in the original DAG $G$ with a copy-index-equivalent ancestral subgraph.  We call such subsets of the observed nodes of $G'$ \tblue{injectable sets},
\begin{align}\begin{split}\label{eq:definjectable}
&\bm{U}'\in\SmallNamedFunction{InjectableSets}{G'} \\
&\quad\text{ iff }\quad \exists \bm{U}\subseteq \SmallNamedFunction{ObservedNodes}{G} \;\; :\;\; \bm{U}'\sim\bm{U} \;\;\text{and}\;\; \ansubgraph[G']{\bm{U}'}\sim\ansubgraph[G]{\bm{U}}.
\end{split}\end{align}

Similarly,  those sets of observed nodes in the original DAG $G$ which satisfy the antecedent of~\cref{eq:coincidingdistrodef}, that is, for which one can find a corresponding set in the inflated DAG $G'$ with a copy-index-equivalent ancestral subgraph, we describe as \tblue{images of the injectable sets},
\begin{align}\begin{split}\label{eq:defimageinjectable}
& \bm{U}\in\SmallNamedFunction{ImagesInjectableSets}{G} \\
& \quad\text{ iff }\quad \exists \bm{U}' \subseteq \SmallNamedFunction{ObservedNodes}{G'} \;\; :\;\; \bm{U'}\sim\bm{U} \;\;\text{and}\;\; \ansubgraph[G']{\bm{U}'}\sim\ansubgraph[G]{\bm{U}}.
\end{split}\end{align}
Clearly, $\bm{U}\in\SmallNamedFunction{ImagesInjectableSets}{G}$ iff $\exists \bm{U}' \subseteq \SmallNamedFunction{InjectableSets}{G'}$ such that $\bm{U}\sim \bm{U}'$.


For example in the Spiral inflation of the Triangle scenario depicted in~\cref{fig:Tri222}, the set $\brackets{A_1 B_1 C_1}$ is injectable because its ancestral subgraph is equivalent up to copy-indices to the ancestral subgraph of $\brackets{A B C}$ in the original DAG, and the set $\brackets{A_2 C_1}$ is injectable because its ancestral subgraph is equivalent to that of $\brackets{ A C}$ in the original DAG. 

A set of nodes in the inflated DAG can only be injectable if it contains at most one copy of any node from the original DAG. More strongly, it can only be injectable if its ancestral subgraph contains at most one copy of any observed or latent node from the original DAG.  
Thus, in \cref{fig:Tri222}, $\brackets{A_1 A_2 C_1}$ is not injectable because it contains two copies of $A$, and $\brackets{A_2 B_1 C_1}$ is not injectable because its ancestral subgraph contains two copies of $Y$. 

We can now express \cref{eq:coincidingdistrodef} in the language of injectable sets,
\begin{align}\label{keyinference}
%\text{if }  \quad  \bm{U}'\in\SmallNamedFunction{InjectableSets}{G'} \quad \text{and} \quad \bm{U} \sim \bm{U}'  \quad\text{then}\quad P'_{\bm{U}'}=P_{\bm{U}}.
P_{\bm{U}'}=P_{\bm{U}}\quad\text{if }  \;\; \bm{U}' \sim \bm{U}\;\; \text{and} \;\; \bm{U}'\in\SmallNamedFunction{InjectableSets}{G'}.% \quad \text{and} \quad \bm{U} \sim \bm{U}'  \quad\text{then}\quad P'_{\bm{U}'}=P_{\bm{U}}.
\end{align}

In the example of \cref{fig:Tri222}, injectability of the sets $\brackets{A_1 B_1 C_1}$ and $\brackets{A_2 C_1}$ thus implies that the marginals on each of these in anan model are equal to the marginals on their counterparts, $\brackets{A B C}$ and $\brackets{A C}$, in the original causal model, so that $P_{A_1 B_1 C_1} = P_{A B C}$ and $P_{A_2 C_1} = P_{A C}$.

\subsection{Witnessing incompatibility\label{subsec:witnessingincompat}}

Finally, we can explain why inflation is relevant for deciding whether a distribution is compatible with a causal structure.  For a family of marginal distributions $\{ P_{\bm{U}} : \bm{U} \in \SmallNamedFunction{ImagesInjectableSets}{G}\}$ to be compatible with $G$, there must be a causal model $M$ that yields a joint distribution with this family as its marginals. Looking at the inflation model $M' = \SmallNamedFunction[G\to G']{Inflation}{M}$, \cref{keyinference} implies that $M'$ has the corresponding family of marginals given by $\{ P_{\bm{U}'} : \bm{U}' \in \SmallNamedFunction{InjectableSets}{G'}\}$ with $P_{\bm{U}'} = P_{\bm{U}}$ for $\bm{U}'\sim\bm{U}$, and thus this family is compatible with $G'$.

The same considerations apply for any collection of injectable sets:

\begin{lemma} \label[lemma]{mainlemma}
Let $G'$ be an inflation DAG of $G$. 
Let $S'  \subseteq \SmallNamedFunction{InjectableSets}{G'}$ be a collection of injectable sets, and let $S \subseteq \SmallNamedFunction{ImagesInjectableSets}{G}$ be the images of this collection.   If the family of marginal distributions $\{ P_{\bm{U}} : \bm{U} \in S \}$ is compatible with $G$, then the corresponding family of marginal distributions $\{ P_{\bm{U}'} : \bm{U}' \in S' \}$, defined via $P_{\bm{U}'}= P_{\bm{U}}$ for $\bm{U}' \sim \bm{U}$, is compatible with $G'$.
\end{lemma}

We have thereby related a question about compatibility with the original causal structure to one about compatibility with the inflated causal structure.  If one can show that the new compatibility question on $G'$ is answered in the negative, then one can infer that the original question is answered in the negative as well.    Some simple examples serve to illustrate the idea.




%\color{purple}
%[Define notational convention of $[x]$]
%\color{black}

\begin{example}[\tred{Incompatibility of perfect three-way correlation with the Triangle scenario}]
\label{example:noGHZ}

\begin{figure}[bh]
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[scale=1]{TriDagRawALT.pdf}
\caption{The Triangle scenario. (Repeat of \cref{fig:TriMainDAG}.)}\label{fig:TriMainDAGv2}
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\linewidth}
\centering
%\includegraphics[scale=1]{TriDagSubA2B1C1.pdf}
\includegraphics[scale=1]{nobroadcastingexamplenohighlightALT.pdf}
\caption{The Cut inflation of the Triangle scenario. (Repeat of \cref{fig:simplestinflation}.)}\label{fig:TriDagSubA2B1C1v2}
%\cref{fig:TriDagSubA2B1C1}.)}\label{fig:TriDagSubA2B1C1v2}
\end{minipage}
\end{figure}

Consider the following causal inference problem.  We are given a joint distribution of three binary variables, $P_{A B C}$, where the marginal on each variable is uniform and the three are perfectly correlated,
\begin{align}\label{eq:ghzdistribution1}
P_{A B C} =\frac{[000]+[111]}{2},\quad\text{i.e.,}\quad P_{A B C}(a b c)=\begin{cases}\tfrac{1}{2}&\text{if }\; a = b = c, \\ 0&\text{otherwise},\end{cases}
\end{align}
and one would like to determine whether it is compatible with the Triangle scenario (\cref{fig:TriMainDAGv2}). The notation $[abc]$ in \cref{eq:ghzdistribution1} is shorthand for the deterministic distribution where $A$, $B$, and $C$ take the values $a, b$, and $c$ respectively; in terms of the Kronecker delta, $[abc]:= \delta_{A,a} \delta_{B,b} \delta_{C,c}$.
%  \color{red} The sum-over-brackets notation in \cref{eq:ghzdistribution1} is a shorthand for indicating discrete probability distributions: the coefficient of each bracketed tuple indicates the probability of that particular joint value-assignment.

Since there are no conditional independence relations among the observed variables in the Triangle scenario, there is no opportunity for ruling out the distribution on the grounds that it fails to satisfy the required conditional independences. 

%The causal hypothesis is that the DAG corresponds to the triangle scenario, depicted in \cref{fig:Tri222}.  
%The problem is to decide whether the given distribution is compatible with this causal hypothesis.

To solve the causal inference problem, we consider the Cut inflation (\cref{fig:TriDagSubA2B1C1v2}). The injectable sets include $\brackets{A_2 C_1}$ and $\brackets{B_1 C_1}$.  Their images on the original DAG are $\brackets{AC}$ and $\brackets{BC}$, respectively.
%We therefore consider the marginals on these sets.

We will show that the distribution of \cref{eq:ghzdistribution1} is not compatible with the Triangle scenario by demonstrating that the contrary assumption of compatibility implies a contradiction. If the distribution of Eq.~\eqref{eq:ghzdistribution1} is compatible, then so is the family of its marginals on $\brackets{AC}$ and $\brackets{BC}$, which are given by:
\begin{align*}
P_{A C} = P_{B C} = \frac{[00]+[11]}{2}.
\end{align*}
By \cref{mainlemma}, this compatibility assumption entails that the family of marginals
\begin{align}\label{ghzmarginals}
P_{A_2 C_1} = P_{B_1 C_1} = \frac{[00]+[11]}{2}
\end{align}
is compatible with the Cut inflation. We now show that this is actually not the case, thereby obtaining our contradiction.  It suffices to note that (i) the only joint distribution that exhibits perfect correlation between $A_2$ and $C_1$ and between $B_1$ and $C_1$ also exhibits perfect correlation between $A_2$ and $B_1$, and (ii) $A_2$ and $B_1$ have no common ancestor in the Cut inflated DAG and hence must be marginally independent in any distribution that is compatible with it. 

We have therefore certified that the distribution $P_{A B C}$ of~\cref{eq:ghzdistribution1} is not compatible with the Triangle scenario, recovering a result originally proven by \citet{steudel2010ancestors}.
\end{example}

\begin{example}[\tred{Incompatibility of the W-type distribution with the Triangle scenario}]
\label{example:noWdist}
\begin{figure}[bh]
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[scale=1]{TriDagRawALT.pdf}
\caption{The Triangle scenario. (Repeat of \cref{fig:TriMainDAG}.)}\label{fig:TriMainDAGv3}
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[scale=1]{TriDagSub222fixedcoordALT.pdf}
\caption{The Spiral inflation of the Triangle scenario. (Repeat of \cref{fig:Tri222}.)}\label{fig:Tri222v2}
\end{minipage}
\end{figure}


Consider another causal inference problem on the Triangle scenario, namely, that of determining whether the distribution 
%$P^{\text{W}}_{A B C}$
\begin{align}\label{eq:wdistribution1}
P_{A B C}=\frac{[100]+[010]+[001]}{3},\quad\text{i.e.,}\quad P_{A B C}(a b c)=\begin{cases}\tfrac{1}{3}&\text{if }\; a + b + c = 1, \\ 0&\text{otherwise}.\end{cases}
\end{align}
is compatible with it. We call this the W-type distribution\footnote{The name stems from the fact that this distribution is reminiscent of 
%hese \color{black} correlations are reminiscent of those one obtains for 
the famous quantum state appearing in~\cite{3Qubits2Ways}, called the \emph{W state}.}. To settle this compatibility question, we consider the Spiral inflation of the Triangle scenario (\cref{fig:Tri222v2}).
%inflated DAG of \cref{fig:Tri222v2}.  
The injectable sets in this case include $\{A_1 B_1 C_1\}$, $\{A_2 C_1\}$, $\{B_2 A_1\}$, $\{C_2 B_1\}$,  $\{A_2\}$, $\{B_2\}$ and $\{C_2\}$. 

Therefore, we turn our attention to determining whether the marginals of the W-type distribution on the images of these injectable sets are compatible with the Triangle scenario.  These marginals are:
\begin{align}
P_{A B C}&= \frac{[100]+[010]+[001]}{3}, \label{V4}\\
P_{A C}= P_{B A} = P_{C B} & = \frac{[10]+[01]+[00]}{3}, \label{V1}\\
P_{A}= P_B = P_C & = \frac{2}{3}[0] + \frac{1}{3}[1]. \label{V5}
\end{align}
By \cref{mainlemma}, this compatibility holds only if the associated marginals for the injectable sets, namely, 
\begin{align}
P_{A_1 B_1 C_1}&= \frac{[100]+[010]+[001]}{3}, \label{W4}\\
P_{A_2 C_1} = P_{B_2 A_1} = P_{C_2 B_1} & = \frac{[10]+[01]+[00]}{3}, \label{W1}\\
P_{A_2} = P_{B_2} = P_{C_2} & = \frac{2}{3}[0] + \frac{1}{3}[1], \label{W5}
\end{align}
are compatible with the Spiral inflation (\cref{fig:Tri222v2})\color{black}. \cref{W1} %together with the form of $P_{\text{W}}$ 
implies that $C_1 = 0$ whenever $A_2 = 1$. It similarly implies that $A_1 = 0$ whenever $B_2 = 1$, and that $B_1 = 0$ whenever $C_2 = 1$, 
%, that is, $A_2=1$ and $B_2=1$ and $C_2=1$.  
%Summarizing, we have
\begin{align} 
\begin{split}\label{Ws}
&A_2  = 1 \:\implies\: C_1 = 0,\\
&B_2 = 1 \:\implies\: A_1 = 0,\\
&C_2  = 1 \:\implies\: B_1  = 0.
\end{split}
\end{align}
Our inflated DAG is such that $A_2$, $B_2$ and $C_2$ have no common ancestor and consequently are marginally independent in any distribution compatible with it. Together with \cref{W5}, this implies that %$A_2$,$B_2$, and $C_2$ sometimes all take the value 1,
\begin{align} \label{WW2}
\text{Sometimes} \quad &A_2  = 1\,\text{ and }\, B_2  = 1\,\text{ and }\, C_2  = 1.
\end{align} 
Finally, \cref{Ws} together with \cref{WW2} entails
\begin{align} \label{WW3}
\text{Sometimes} \quad &A_1  = 0\,\text{ and }\, B_1  = 0\,\text{ and }\, C_1  = 0.
\end{align}
This, however, contradicts~\cref{W4}.  Consequently, the family of marginals described in \cref{W4,W1,W5} is \emph{not} compatible with the DAG of~\cref{fig:Tri222v2}.  By \cref{mainlemma}, this implies that the family of marginals described in \cref{V4,V1,V5}---and therefore the W-type distribution of which they are marginals---is not compatible with the Triangle scenario.
% and the fact that $P_{\text{W}}$ has no weight on $[000]$.

To our knowledge, this is a new result. In fact, the incompatibility of the W-type distribution with the Triangle scenario cannot be derived via any of the following existing causal inference techniques:
\begin{enumerate}
\item Checking conditional independence relations is not relevant here, as there are \emph{no} conditional independence relations implied between any observable variables in the Triangle scenario. 
\item The relevant Shannon-type entropic inequalities for the Triangle scenario have been classified, and they do not witness the incompatibility either~\cite{fritz2013marginal,chaves2014novel,chaves2014informationinference}. 
\item Moreover, \emph{no} entropic inequality can witness the W-type distribution as unrealizable. \citet{weilenmann2016entropic} have constructed an inner approximation to the entropic cone of the Triangle causal structure, and the W-distribution lies inside this. In other words, a distribution with the same entropic profile as the W-type distribution \emph{can} arise from the Triangle scenario.
\item The newly-developed method of covariance matrix causal inference due to \citet{kela2016covariance}, which gives tighter constraints than entropic inequalities for the Triangle scenario, also cannot detect the incompatibility.
\end{enumerate}
%\par\noindent But the inflation technique can, and does so very easily.
Therefore, in this case at least, the inflation technique appears to be more powerful. 

We have arrived at our incompatibility verdict by combining inflation with reasoning reminiscent of  Hardy's version of Bell's theorem~\cite{L.Hardy:PRL:1665,Mansfield2012}. \cref{sec:TSEM} will present a generalization of this kind of argument and its applications to causal inference. 
\end{example}

\begin{example}[\tred{Incompatibility of PR-box correlations with the Bell scenario}]
\label{example:noPR}

Bell's theorem~\cite{bell1964einstein,Brunner2013Bell,bell1966lhvm,CHSHOriginal} concerns the question of whether the distribution obtained in an experiment involving a pair of systems that are measured at space-like separation is compatible with a causal structure of the form of \cref{fig:NewBellDAG1}. Here, the observed variables are $\brackets{A,B,X,Y}$, and $\Lambda$ is a latent variable acting as a common cause of $A$ and $B$. We shall term this causal structure the \emph{Bell scenario}. While the causal inference formulation of Bell's theorem is not the traditional one, several recent articles have introduced and advocated this perspective~[\citealp{WoodSpekkens}~(Fig.~19), \citealp{pusey2014gdag}~(Fig.~E\#2), \citealp{BeyondBellII}~(Fig.~1), \citealp{chaves2014novel}~(Fig.~1), \citealp{wolfe2015nonconvexity}~(Fig.~2b), \citealp{steeg2011relaxation}~(Fig.~2)].  

%Consider the causal structure associated to the Bell \cite{bell1964einstein,Brunner2013Bell,bell1966lhvm,CHSHOriginal} scenario [\citealp{pusey2014gdag}~(Fig.~E\#2), \citealp{WoodSpekkens}~(Fig.~19), \citealp{chaves2014novel}~(Fig.~1), \citealp{BeyondBellII}~(Fig.~1), \citealp{wolfe2015nonconvexity}~(Fig.~2b), \citealp{steeg2011relaxation}~(Fig.~2)], depicted here in \cref{fig:NewBellDAG1}. The observable variables are $\brackets{A,B,X,Y}$, and $\Lambda$ is the latent common cause of $A$ and $B$. 

\begin{figure}[ht]
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[scale=1]{BellDagRaw.pdf}
\caption{The causal structure of the bipartite Bell scenario. The local outcomes $A$ and $B$ of Alice's and Bob's measurements is assumed to be a function of some latent common cause and their independent local experimental settings $X$ and $Y$.}\label{fig:NewBellDAG1}
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\linewidth}
\centering
\includegraphics[scale=1]{BellDagCopy.pdf}
\caption{An inflation DAG of the bipartite Bell scenario, where both local settings and outcome variables have been duplicated.}\label{fig:BellDagCopy1}
\end{minipage}
\end{figure}

%P^{\text{obs-inf}}_{A_2 C_1}

We consider the distribution ${P_{A B X Y} = P_{A B | X Y} P_{X} P_{Y}}$, where $P_{X}$ and $P_{Y}$ are arbitrary full-support distributions\footnote{In the literature on the Bell scenario, these variables are known as ``settings''. Generally, we may think of observable root variables as settings, coloring them light green in the DAG figures. They are natural candidates for variables to condition on.} over the binary variables $X$ and $Y$, and
\begin{align}\begin{split}\label{eq:PRbox}
% & p_{\text{PR}}\parens{a b |x y}=\frac{[00|00]+[11|00]+[00|10]+[11|10]+[00|01]+[11|01]+[01|11]+[10|11]}{8}\\
P_{A B | X Y}\parens{a b |x y}=\begin{cases}\tfrac{1}{2}&\text{if }\; a \oplus b = x \cdot y , \\ 0&\text{otherwise},\end{cases}
\end{split}\end{align}
a conditional distribution that was discovered by Tsirelson~\cite{Tsirelson1980} and later independently by Popescu and Rohrlich~\cite{PROriginal,PRUnit}. It has become known in the field of quantum foundations as the \emph{PR-box} after the latter authors.\footnote{The PR-box is of interest because it represents a manner in which experimental observations could deviate from the predictions of quantum theory while still being consistent with relativity.}

The Bell scenario implies nontrivial conditional independences\footnote{Recall that variables $X$ and $Y$ are conditionally independent given $Z$ if $P_{XY|Z}(xy|z) = P_{X|Z}(x|z) P_{Y|Z}(y|z)$ for all $z$ with $P_{Z}(z)>0$. Such a conditional independence is denoted by $X\indep Y \:|\: Z$.} among the observed variables, namely, $X \indep Y$, $A \indep Y| X$, and\footnote{In the context of a Bell experiment, where $\{X,A\}$ are space-like separated from $\{Y,B\}$, the conditional independences $A \indep Y| X$ and $B \indep X|Y$ encode the impossibility of sending signals faster than the speed of light.} $B \indep X|Y$, as well as those that can be generated from these by the semi-graphoid axioms \cite{WoodSpekkens}.
%We will use the inflation technique to show that this distribution is incompatible with the Bell scenario.
It is straightforward to check that these conditional independence relations are respected by the $P_{ABXY}$ resulting from~\cref{eq:PRbox}. It is well-known that this distribution is nonetheless incompatible with the Bell scenario, for example since it violates the CHSH inequality.
%, and they are well-known to be incompatible with the Bell scenario \cite{PROriginal,PRUnit}. 
%Here we prove the incompatibility using the inflation technique. 
Here we prove this incompatibility via the inflation technique, using the inflation of the Bell scenario depicted in \cref{fig:BellDagCopy1}.

We begin by noting that $\{A_1 B_1 X_1 Y_1\}$, $\{A_2 B_1 X_2 Y_1\}$, $\{A_1 B_2 X_1 Y_2\}$, $\{A_2 B_2 X_2 Y_2\}$, $\{X_1\}$, $\{X_2\}$, $\{Y_1\}$, and $\{Y_2\}$ are all injectable sets. 
By \cref{mainlemma}, it follows that any causal model that recovers $P_{ABXY}$ inflates to a model that results in marginals
\begin{align}
P_{A_1 B_1 X_1 Y_1}=P_{A_2 B_1 X_2 Y_1}=P_{A_1 B_2 X_1 Y_2}=P_{A_2 B_2 X_2 Y_2}&=P_{A B X Y},\label{PR1}\\
P_{X_1}=P_{X_2}=P_X, \qquad P_{Y_1}=P_{Y_2}&=P_Y.\label{PR5}
\end{align}
Using the definition of conditional probability, we infer that
\begin{align}
P_{A_1 B_1 |X_1 Y_1}=P_{A_2 B_1 |X_2 Y_1}=P_{A_1 B_2 |X_1 Y_2}=P_{A_2 B_2 |X_2 Y_2}=P_{A B |X Y}\label{PRb}.
\end{align}
Because $\{X_1\}$, $\{X_2\}$, $\{Y_1\}$, and $\{Y_2\}$ have no common ancestor in the inflated DAG, these variables must be marginally independent in any distribution compatible with the inflated DAG. This applies in particular to the inflation model, so that $P_{X_1 X_2 Y_1 Y_2} = P_{X_1} P_{X_2} P_{Y_1} P_{Y_2}$. Given the assumption that the distributions $P_{X}$ and $P_{Y}$ have full support, it follows from~\cref{PR5} that
\begin{align}\label{PRs}
\text{Sometimes} \quad &X_1 = 0\,\text{ and }\, X_2  =1\,\text{ and }\, Y_1  = 0\,\text{ and }\, Y_2  = 1.
\end{align} 
On the other hand, from~\cref{PRb} together with  the definition of PR-box,~\cref{eq:PRbox}, we conclude that 
\begin{align} 
\begin{split}
\label{PRsi}
&X_1  = 0,\: Y_1  = 0 \:\implies\: A_1 = B_1,\\
&X_1  = 0,\: Y_2  = 1 \:\implies\: A_1 = B_2,\\
&X_2  = 1,\: Y_1  = 0 \:\implies\: A_2 = B_1,\\
&X_2  = 1,\: Y_2  = 1 \:\implies\: A_2\ne B_2.
\end{split}
\end{align}
Combining this with~\cref{PRs}, we obtain
\begin{align}
\text{Sometimes} \quad &A_1 = B_1\,\text{ and }\, A_1 = B_2\,\text{ and }\, A_2 = B_1\,\text{ and }\, A_2\neq B_2.
\end{align} 
No values of $A_1$, $A_2$, $B_1$, and $B_2$ can jointly satisfy these conditions. So we have reached a contradiction, showing that our original assumption of compatibility of $P_{ABXY}$ with the Bell scenario must have been false.

The structure of this proof parallels that of standard proofs of the incompatibility of the PR-box with the Bell scenario. Standard proofs focus on a set of variables $\{A_0 A_1 B_0 B_1\}$ where $A_x$  is the value of $A$ when $X=x$ and $B_y$  is the value of $B$ when $Y=y$, and note that  the distribution
%if the Bell DAG describes the experiment, then by taking 
%the product of the probability of each of these four variables given $\lambda$, that is,
 $\sum_{\lambda} P(A_0|\lambda)P(A_1|\lambda)P(B_0|\lambda)P(B_1|\lambda)P(\lambda)$
 %(the probability of $A_0$ given $\lambda$, of $A_1$ given $\lambda$, etcetera, one obtains 
 is a joint distribution of these four variables for which the marginals on pairs  $\{ A_0 B_0\}$, $\{ A_0 B_1\}$, $\{ A_1 B_0\}$ and $\{ A_1 B_1\}$ are those corresponding to the conditional distribution describing the PR-box, \cref{eq:PRbox}. Finally, the existence of such a joint distribution rules out the possibility of having $A_1 = B_1$, $A_1 = B_2$, $A_2 = B_1$ but $ A_2\neq B_2$, and therefore shows that the PR-box distribution is incompatible with the Bell scenario~\cite{LSW,roberts_thesis}. In light of our use of \cref{PRs}, our reasoning is really the same argument in disguise.

\cref{sec:Bellscenarios} shows that the inflation of~\cref{fig:BellDagCopy1}, with the number of copies corresponding to the cardinality of $X$ and $Y$, is enough to witness the incompatibility of any distribution that is incompatible with the Bell scenario.
\end{example}

\subsection{Deriving causal compatibility inequalities}\label{Sec:DerivingInequalities}

The inflation technique can be used not only to witness the incompatibility of a given distribution with a given causal structure, but also to derive generally applicable necessary conditions that a distribution must satisfy to be compatible with the given causal structure. When these conditions are expressed as inequalities, we will refer to them as {\em causal compatibility inequalities}.  Formally, we have:

\begin{definition}
Let $G$ be a causal structure and $S \subseteq 2^{\SmallNamedFunction{ObservedNodes}{G}}$.  Let $I_S$ denote an inequality that operates on a family of marginal distributions  $\{ P_{\bm{U}}: \bm{U} \in S\}$.  Then $I_S$ is a \tblue{\em causal compatibility inequality for the causal structure $G$} whenever it is satisfied by every family of marginal distributions $\{ P_{\bm{U}}: \bm{U} \in S\}$ that is compatible with $G$.
%Consider a DAG $G$ and a set of the observed nodes thereon, $S \subseteq \SmallNamedFunction{ObservedNodes}{G}$.  Let $I_S$ denote an inequality that is evaluated on a family of marginal distributions  $\{ P_{\bm{U}}: \bm{U} \in S\}$.  The inequality $I_S$ is termed a \tblue{\em causal compatibility inequality for the DAG $G$} whenever it is satisfied by every family of distributions $\{ P_{\bm{U}}: \bm{U} \in S\}$ that is compatible with the DAG $G$.
\end{definition}
%\begin{definition}
%Consider a set of distributions over subsets of observed nodes on a DAG $G$, $\{ P_{\bm{U}}: \bm{U} \in \SmallNamedFunction{Subsets}{\SmallNamedFunction{ObservedNodes}{G}}\}$.  An inequality on such a set of distributions, denoted $I(\{ P_{\bm{U}}: \bm{U} \in \SmallNamedFunction{Subsets}{\SmallNamedFunction{ObservedNodes}{G}}\} )$, is termed a {\em causal compatibility inequality} just in case it is satisfied  whenever $\{ P_{\bm{U}}: \bm{U} \in \SmallNamedFunction{Subsets}{\SmallNamedFunction{ObservedNodes}{G}}\}$ is compatible with the DAG.  
%\end{definition}
While violation of a causal compatibility inequality witnesses the incompatibility with the causal structure, satisfaction of the inequality does not guarantee compatibility.  This is the sense in which it merely provides a {\em necessary} condition for compatibility. 

The inflation technique is useful for deriving causal compatibility inequalities because of the following consequence of  \cref{mainlemma}:
%\begin{corollary} \label{maincorollary}
%Let $G$ and $G'$ be DAGs, with $G'$ an inflation of $G$.  Consider a set of distributions on the injectable sets on $G'$, denoted $S' := \{ P'_{\bm{U}'} : \bm{U}' \in \SmallNamedFunction{InjectableSets}{G'} \}$.  Consider also a set of distributions on the images of these injectable sets on $G$, denoted $S :=  \{ P_{\bm{U}} : \bm{U} \in \SmallNamedFunction{ImagesInjectableSets}{G} \}$.    Let $I'(S')$ be an inequality on $S'$, and let $I(S)$ be the inequality on $S$ that is obtained from $I'(S')$ as follows: for each injectable set $\bm{U'}$, replace $P'_{\bm{U}'}$ with $P_{\bm{U}}$ in $I'(S')$.  In this case, if $I'(S')$ is a causal compatibility inequality for the DAG $G'$ then $I(S)$ is a causal compatibility inequality for the DAG $G$.
%\end{corollary}

\begin{corollary} \label[corollary]{maincorollary}
Suppose that $G'$ is an inflation of $G$. Let $S'  \subseteq \SmallNamedFunction{InjectableSets}{G'}$ be a family of injectable sets and $S \subseteq \SmallNamedFunction{ImagesInjectableSets}{G}$ the images of members of $S'$.
%Let $S'$ be a family of injectable sets on $\SmallNamedFunction{ObservedNodes}{G'}$, $S'  \subseteq \SmallNamedFunction{InjectableSets}{G'}$, and let $S$ be the image on $\SmallNamedFunction{ObservedNodes}{G}$ of this family, $S \subseteq \SmallNamedFunction{ImagesInjectableSets}{G} \}$.    
%Consider a family of marginal distributions on the elements of $S$, $\{ P_{\bm{U}} : \bm{U} \in S\}$, whose marginals are consistent on the places where the elements of $S$ overlap. 
Let $I_{S'}$ be a causal compatibility inequality for $G'$ operating on families $\{ P_{\bm{U}'} : \bm{U}' \in S'\}$. Define an inequality $I_S$ as follows: in the functional form of $I_{S'}$, replace every occurrence of a term $P_{\bm{U}'}$ by $P_{\bm{U}}$ for the unique $\bm{U}\in S$ with $\bm{U} \sim \bm{U}'$. Then $I_S$ is a causal compatibility inequality for $G$ operating on families $\{ P_{\bm{U}} : \bm{U}\in S\}$.
\end{corollary}

The proof is as follows.  Suppose that the family $\{ P_{\bm{U}} : \bm{U} \in S\}$ is compatible with $G$.  By \cref{mainlemma}, it follows that the family $ \{ P_{\bm{U}'} : \bm{U}' \in S'\}$ where $P_{\bm{U}'}:= P_{\bm{U}}$ for $\bm{U}' \sim \bm{U}$  is compatible with $G'$.  Since $I_{S'}$ is a causal compatibility inequality for $G'$, it follows that $\{ P_{\bm{U}'} : \bm{U}' \in S'\}$ satisfies $I_{S'}$.  But by the definition of $I_{S}$, its evaluation on $\{ P_{\bm{U}} : \bm{U} \in S\}$ is equal to $I_{S'}$ evaluated on $\{ P_{\bm{U}'} : \bm{U}' \in S'\}$. It therefore follows that $\{ P_{\bm{U}} : \bm{U} \in S\}$ satisfies $I_{S}$. Since $\{ P_{\bm{U}} : \bm{U}\in S\}$ was an arbitrary family compatible with $G$, we conclude that $I_{S}$ is a causal compatibility inequality for $G$.  

We now present some simple examples of causal compatibility inequalities for the Triangle scenario that one can derive from the inflation technique via \cref{maincorollary}. Some terminology and notation will facilitate their description. We refer to a pair of nodes which do not share any common ancestor as being \tblue{ancestrally independent}. This is equivalent to being $d$-separated by the empty set~\cite{pearl2009causality,spirtes2011causation,studeny2005probabilistic,koller2009probabilistic}.  Given that the conventional notation for $X$ and $Y$ being $d$-separated by $Z$ in the DAG $G$ is $X\perp_G Y|Z$, we denote $X$ and $Y$ being ancestrally independent within $G$ as $X\perp_G Y$.  Generalizing to sets, $\bm{U}\aindep_G \bm{V}$ indicates that no node in $\bm{U}$ shares a common ancestor with any node in $\bm{V}$ within the DAG $G$, 
\begin{align}
\bm{U}\aindep_G \bm{V} \quad \text{iff} \quad \An[G]{\bm{U}}\cap\An[G]{\bm{V}}=\emptyset.
\end{align}
Furthermore, the notation ${\bm{U}\aindep_G \bm{V}\aindep_G \bm{W}}$ should be understood as indicating that $\bm{U}\aindep_G \bm{V}$ and $\bm{V}\aindep_G \bm{W}$ and $\bm{U}\aindep_G \bm{W}$.

\begin{example}[\tred{A causal compatibility inequality in terms of \tpurp{\emph{correlators}}}]
\label{example:polytriangle}

As in \cref{example:noGHZ} of the previous section, consider the Cut inflation of the Triangle scenario (\cref{fig:TriDagSubA2B1C1v2}), where all observed variables are binary. For technical convenience, we assume that they take values in the set $\{-1,+1\}$, rather than taking values in $\{0,1\}$ as was presumed in the last section. 

The injectable sets that we make use of are $\brackets{A_2 C_1}$, $\brackets{B_1 C_1}$, $\{ A_2\}$, and  $\brackets{B_1}$. From \cref{maincorollary}, any causal compatibility inequality for the inflated DAG that operates on the marginal distributions of $\brackets{A_2 C_1}$, $\brackets{B_1 C_1}$, $\{ A_2\}$, and  $\brackets{B_1}$ will yield a causal compatibility inequality for the original DAG that can be evaluated on the marginal distributions on $\brackets{A C}$, $\brackets{B C}$, $\brackets{A}$, and  $\brackets{B}$. We begin by noting that for {\em any} distribution on three binary variables $\{A_2 B_1 C_1\}$, that is, {\em regardless} of the causal structure in which they are embedded, the marginals on $\brackets{A_2 C_1}$, $\brackets{B_1 C_1}$ and $\brackets{A_2 B_1}$ satisfy the following inequality for expectation values~\cite{pitowsky_boole_1994,Pitowsky1989,kellerer_marginal_1964,leggett_garg_1985,araujo_cycle_2013},
\begin{equation}
	\label{eq:polymonogamyraw}
	\langle A_2 C_1\rangle + \langle B_2 C_1 \rangle - \langle A_2 B_1 \rangle \leq 1.
\end{equation}
This is an example of a constraint on pairwise correlators that arises from the presumption that they are consistent with a joint distribution. (The problem of deriving such constraints is the {\em marginal constraint problem}, discussed in detail in \cref{sec:ineqs}.)

But in the Cut inflation of the Triangle scenario~(\cref{fig:TriDagSubA2B1C1v2}) $A_2$ and $B_1$ have no common ancestor and consequently any distribution compatible with this DAG must make $A_2$ and $B_1$ marginally independent.  In terms of correlators, this can be expressed as 
%means that 
\begin{align}\label{corrfact}
A_2 \aindep B_1 \implies  \langle A_2 B_1 \rangle =  \langle A_2\rangle \langle B_1 \rangle.
\end{align}
Substituting this into~\cref{eq:polymonogamyraw}, we have
\begin{equation}
	\langle A_2 C_1\rangle + \langle B_2 C_1 \rangle   \leq 1 + \langle A_2 \rangle \langle B_1\rangle.
\end{equation}
This is an example of a simple but nontrivial causal compatibility inequality for the DAG of~\cref{fig:TriDagSubA2B1C1v2}. Finally, by \cref{maincorollary},  we infer that 
\begin{equation}
	\label{eq:polymonogamy}
	\langle A C\rangle + \langle B C\rangle \leq 1 + \langle A\rangle \langle B\rangle
\end{equation}
is a causal compatibility inequality for the Triangle scenario.   This inequality expresses the fact that as long as $A$ and $B$ are not completely biased, there is a tradeoff between the strength of $AC$ correlations and the strength of $BC$ correlations.   

Given the symmetry of the Triangle scenario under permutations and sign flips of $A$, $B$ and $C$, it is clear that the image of inequality~\cref{eq:polymonogamy} under any such symmetry is also a valid causal compatibility inequality.  Together, these inequalities constitute a type of monogamy\footnote{We are here using the term ``monogamy'' in the same sort of manner in which it is used in the context of entanglement theory~\cite{horo4}.}  of correlations in the Triangle scenario with binary variables:  if any two observed variables with unbiased marginals are perfectly correlated, then they are both uncorrelated with the third.
\end{example}

\begin{example}[\tred{A causal compatibility inequality in terms of \tpurp{\emph{entropic quantities}}}]
\label{ex:entropic}

One way to derive constraints that are independent of the cardinality of the observed variables is to express these in terms of the mutual information between observed variables rather than in terms of correlators.  The inflation technique can also be applied to achieve this.
%Inequalities expressed in terms of entropies and mutual information (rather than correlators) have the advantage that one can easily derive constraints that are independent of the cardinality of the observed variables.  
%This is the case with the inflation technique as well.  
To see how this works in the case of the Triangle scenario, consider again the Cut inflation~(\cref{fig:TriDagSubA2B1C1v2}).  

One can follow the same logic as in the preceding example, but starting from a different constraint on marginals.  For any distribution on three variables $\{A_2 B_1 C_1\}$ of arbitrary cardinality (again, regardless of the causal structure in which they are embedded), the marginals on $\brackets{A_2 C_1}$, $\brackets{B_1 C_1}$ and $\brackets{A_2 B_1}$ satisfy the inequality~\cite[Eq.~(29)]{fritz2013marginal}
\label{example:entropic}\begin{align}\label{eq:MIraw}
	I(A_2 : C_1) + I(C_1 : B_1) - I(A_2 : B_1) \leq H(C_1),	
\end{align}
where $H(X)$ denotes the Shannon entropy of the distribution of $X$, and $I(X: Y)$ denotes the mutual information between $X$ and $Y$ with respect to the marginal on $X$ and $Y$. The fact that $A_2$ and $B_1$ have no common ancestor in the inflated DAG implies that in any distribution that is compatible with the inflated DAG, $A_2$ and $B_1$ are marginally independent.  This is expressed entropically as the vanishing of their mutual information, 
\begin{align}\label{entropicfact}
A_2 \aindep B_1 \implies  I(A_2 : B_1)  =0.
\end{align}
Substituting the latter equality into~\cref{eq:MIraw}, we have
\begin{align}
	I(A_2 : C_1) + I(C_1 : B_1)  \leq H(C_1).
\end{align}
This is another example of a nontrivial causal compatibility inequality for the DAG of~\cref{fig:TriDagSubA2B1C1v2}. By \cref{maincorollary}, it follows that 
\begin{align}\label{eq:monogomyofcorrelations}
	I(A : C) + I(C : B) \leq H(C)
\end{align}
is also a causal compatibility inequality for the Triangle scenario.  This inequality was originally derived in~\cite{fritz2012bell}. Our rederivation in terms of inflation coincides with the proof found by~\citet{pusey2014gdag}.
\end{example}

\begin{example}[\tred{A causal compatibility inequality in terms of \tpurp{\emph{joint probabilities}}}]
\label{example:probineq}
Consider the Spiral inflation of the Triangle scenario (\cref{fig:Tri222v2}) with the injectable sets $\{A_1 B_1 C_1\}$, $\{A_1 B_2\}$, $\{B_1 C_2\}$, $\{ A_1, C_2\}$, $\{A_2\}$, $\{B_2\}$, and $\{C_2\}$. We derive a causal compatibility inequality under the assumption that the observed variables are binary, adopting the convention that they take values in $\{0,1\}$.

We begin by noting that the following is a constraint that holds for any joint distribution of $\{A_1 B_1 C_1 A_2 B_2 C_2\}$, regardless of the causal structure, 
\begin{align}\label{eq:FritzF3raw}
	P_{A_2 B_2 C_2}(111) \leq P_{A_1 B_1 C_1}(000) + P_{A_1 B_2 C_2}(111) + P_{B_1 C_2 A_2}(111) + P_{A_2  C_1 B_2}(111).
	% Mermin: \langle A_1 B_1 C_1 \rangle - \langle A_2 B_2 C_1 \rangle - \langle A_2 B_1 C_2 \rangle - \langle A_1 B_2 C_2 \rangle \leq 2.
\end{align}
To prove this claim, it suffices to check that the inequality holds for each of the $2^6$ deterministic assignments of outcomes to $\{A_1 B_1 C_1 A_2 B_2 C_2\}$, from which the general case follows by linearity.  A more intuitive proof will be provided in~\cref{sec:TSEM}.

Next, we note that certain sets of variables have no common ancestors with other sets of variables in the inflated DAG, which implies marginal independences resulting in factorization of distributions,
\begin{align}\begin{split}\label{eq:tri222fac}
A_1 B_2 \aindep C_2 \:\implies\:	P_{A_1 B_2 C_2} &= P_{A_1 B_2} P_{C_2}, \\
B_1 C_2 \aindep A_2 \:\implies\:	P_{B_1 C_2 A_2} &= P_{B_1 C_2} P_{A_2}, \\
A_2 C_1 \aindep B_2 \:\implies\:	P_{A_2 C_1 B_2} &= P_{A_2 C_1} P_{B_2}, \\
A_2 \aindep B_2 \aindep C_2 \:\implies\:	P_{A_2 B_2 C_2} &= P_{A_2} P_{B_2} P_{C_2} .
\end{split}\end{align}
Substituting these equations into~\cref{eq:FritzF3raw}, we obtain the polynomial inequality
\begin{equation}%\label{eq:FritzF3}
	P_{A_2}(1) P_{B_2}(1) P_{C_2}(1) \leq P_{A_1 B_1 C_1 }(000) + P_{A_1 B_2}(11) P_{C_2}(1) + P_{B_1 C_2}(11) P_{A_2}(1) + P_{A_2 C_1}(11) P_{B_2}(1).
	% Mermin-poly: \langle A B C\rangle \leq 2 + \langle A B\rangle \langle C\rangle + \langle B C \rangle \langle A\rangle + \langle C A\rangle \langle B\rangle,
\end{equation}
This, therefore, is a causal compatibility inequality for the DAG of \cref{fig:Tri222v2}. Finally, by \cref{maincorollary}, we infer that 
\begin{equation}\label{eq:FritzF3}
	P_{A}(1) P_{B}(1) P_{C}(1) \leq P_{ABC}(000) + P_{AB}(11) P_C(1) + P_{BC}(11) P_A(1) + P_{AC}(11) P_B(1)
	% Mermin-poly: \langle A B C\rangle \leq 2 + \langle A B\rangle \langle C\rangle + \langle B C \rangle \langle A\rangle + \langle C A\rangle \langle B\rangle,
\end{equation}
is a causal compatibility inequality for the Triangle scenario.  

What is distinctive about this inequality is that---through the presence of the term $P_{ABC}(000)$---it takes into account genuine three-way correlations, while our earlier inequalities only depend on the two-variable marginals.  This inequality is strong enough to demonstrate the incompatibility of the W-type distribution of \cref{eq:wdistribution1} with the Triangle scenario: for this distribution, the right-hand side of the inequality vanishes while the left-hand side does not.
\end{example}

Of the known techniques for witnessing the incompatibility of a distribution with a DAG or deriving necessary conditions for compatibility, the most straightforward is to consider the constraints implied by ancestral independences among the observed variables of the DAG. 
%There are many well-known tricks for witnessing the incompatibility of a distribution with a DAG or deriving necessary conditions for compatibility.  The absolutely most straightforward of these is to consider the ancestral independences in the DAG.   
The constraints derived in the last two sections have all made use of this basic technique, but at the level of the inflated DAG rather than the original DAG.  The constraints that one thereby infers for the original DAG reflect facts about its causal structure that cannot be expressed in terms of ancestral independences among its observed variables.  The inflation technique exposes these facts in the ancestral independences among observed variables of the inflated DAG.

In the rest of this article, we shall continue to rely only on the ancestral independences among observed variables within the inflated DAG to infer compatibility constraints on the original DAG.   Nonetheless, it seems plausible that the inflation technique can also amplify the power of {\em other} techniques that do not merely consider ancestral independences among the observed variables.  We consider some prospects in \cref{sec:otherprospects}.

\section{Systematically Witnessing Incompatibility and Deriving Inequalities}
\label{sec:ineqs}

In the examples from the previous section, the initial inequality---a constraint upon marginals that is independent of the causal structure---involves sets of observed variables that are \emph{not} all injectable sets.  Each of these sets can, however, be partitioned into disjoint subsets each of which {\em is} injectable such that the partitioning represents ancestral independence in the inflated DAG. For instance in \cref{example:noGHZ}, the set $\{ A_2 B_1\}$ is not injectable, but it can be partitioned into the singleton sets $\{ A_2 \}$ and $\{ B_1\}$ which are ancestrally independent and each of which is injectable.  It is useful to have a name for such sets of observed variables: we call them \tblue{pre-injectable}. So for any $\bm{U}'$ in the inflated DAG $G'$,
\begin{align}\label{eq:defpreinj}
\begin{split}
\bm{U}'\in & \SmallNamedFunction{PreInjectableSets}{G'} \\
	& \quad\text{ iff }\quad  \exists \{ \bm{U}'_i \in \SmallNamedFunction{InjectableSets}{G'} \} \quad \text{s.t.}\quad \bm{U}'=\bigcup_i \bm{U}'_i  \quad\text{and} \quad  \forall i\ne j: \bm{U}'_i \aindep_{G'} \bm{U}'_j.
\end{split}
\end{align}
For example, every injectable set is trivially pre-injectable.  A pre-injectable set is \emph{maximal} if it is not a proper subset of another pre-injectable set.

Because ancestral independence in the DAG implies statistical independence for any distribution compatible with the DAG, it follows that  if 
$\bm{U}'$ is a pre-injectable set with ancestrally independent components $\bm{U}'_1,\ldots,\bm{U}'_n$, then we have the factorization
\begin{align}\label{eq:preinjfactor}
%\forall \bm{U}\in\SmallNamedFunction{PreInjectableSets}{G'}:	
P_{\bm{U}'} = P_{\bm{U}'_1} \cdots P_{\bm{U}'_n}
\end{align}
for any distribution compatible with $G'$. The situation, therefore, is this: for any constraint that one can derive for the marginals on the pre-injectable sets based on the existence of a joint distribution---and hence without reference to the causal structure---one can infer a constraint that {\em does} refer to the causal structure by substituting within the derived constraint a factorization of the form of~\cref{eq:preinjfactor}. As a build-up to our exposition of a systematic application of the inflation technique, we now revisit \cref{example:noGHZ}.

As before, we infer the marginal distributions on injectable sets,
\begin{equation}
P_{A_2 C_1} = P_{B_1 C_1} = \frac{1}{2} [00] +\frac{1}{2} [11], \qquad P_{A_2} = P_{B_1}=\frac{1}{2} [0] +\frac{1}{2} [1],
\label{marginals1}
\end{equation}
from the given W distribution of \cref{eq:ghzdistribution1} via \cref{mainlemma}. From the fact that $A_2$ and $B_1$ are ancestrally independent, we also infer the distribution on the pre-injectable set $\{A_2 B_1\}$ as
\begin{equation}
P_{A_2 B_1} = P_{A_2}P_{B_1} = \left(\frac{1}{2} [0] +\frac{1}{2} [1]\right)\cramp{\times}\left(\frac{1}{2} [0] +\frac{1}{2} [1]\right)=\frac{1}{4} [00]+\frac{1}{4} [01]+\frac{1}{4} [10]+\frac{1}{4} [11].
\label{marginals2}
\end{equation}
The incompatibility with the Triangle scenario then follows from the fact there is no three-variable distribution $P_{A_2 B_1 C_1}$ that would have the two-variable marginals of \cref{marginals1,marginals2}. For as we noted in our prior discussion of this example, the perfect correlation between $A_2$ and $C_1$ exhibited by $P_{A_2 C_1}$ and the perfect correlation between $B_1$ and $C_1$ exhibited by $P_{B_1 C_1}$ would entail perfect correlation between $A_2$ and $B_1$ as well, but this is at odds with \eqref{marginals2}. It follows that there is no joint distribution that has the distributions of \cref{marginals1,marginals2} as its marginals. 

Generalizing to an arbitrary DAG, therefore, the procedure is as follows:
\begin{enumerate}
\item Based on the inflation DAG, identify the pre-injectable sets and how they each partition into injectable sets.
\item From the given distribution on the DAG, infer the family of marginal distributions on the pre-injectable sets of the inflated DAG as follows: the distribution on any injectable set is equal to the corresponding distribution on its image in the original DAG; the distribution on any pre-injectable set is the product of the distributions on the injectable sets into which it is partitioned.
\item Determine whether the family of distributions obtained in step 2 are the marginals of a single joint distribution. If no, then the original distribution is incompatible with the original DAG; otherwise, it may or may not be compatible.
\end{enumerate}
Thus the pre-injectable sets play a crucial role in linking the original DAG with the inflated DAG: they are precisely those sets of variables whose joint distributions in the inflation model are fully specified by the causal model on the original DAG, as they can be computed using \cref{eq:preinjfactor} and \cref{mainlemma}. 

The problem of determining whether a given family of marginal distributions can arise as marginals of some joint distribution is known as the {\em marginal problem}. A closely related problem is to determine necessary and sufficient \emph{constraints} that a family of marginal distributions must satisfy in order for the marginal problem to have a solution. For better clarity, we distinguish these two variants of the marginal problem as the \tblue{marginal satisfiability problem} and the \tblue{marginal constraint problem}. The generic \tblue{marginal problem} is an umbrella term referring to both types.

Per the above, the marginal satisfiability problem comes up in an application of the inflation technique to deciding the compatibility of a given distribution with a given causal structure. As \cref{example:probineq} indicates, the marginal constraint problem comes up in the systematic derivation of causal compatibility inequalities. More precisely, an inequality for the marginal constraint problem, after applying the factorizations of~\cref{eq:preinjfactor}, becomes a causal compatibility inequality for the inflated DAG. This inequality can be converted into a polynomial causal compatibility inequality for the original DAG using \cref{maincorollary}.

This section considers the problem of how to leverage the marginal satisfiability and constraint problems systematically as auxiliary tools for causal inference via the inflation technique. As far as causal compatibility inequalities are concerned, we limit ourselves to those expressed in terms of probabilities\footnote{Or, for binary variables, equivalently in terms of correlators, as in the first example of \cref{Sec:DerivingInequalities}.}, as these are generally the most powerful. However, the very same techniques can be used to derive inequalities expressed in terms of entropies~\cite{fritz2013marginal}, as demonstrated in \cref{ex:entropic}. We also show in \cref{sec:NonShannon} that the inflation technique implies the core lemma for deriving non-Shannon-type entropic inequalities.

Summarizing, we have shown that, through the inflation technique, the marginal satisfiability problem can be leveraged to witness causal incompatibility of particular distributions, while the marginal constraint problem can be leveraged to derive causal compatibility inequalities. This section begins with a discussion of how to find {\em all} of the pre-injectable sets for an arbitrary inflation of an arbitrary DAG. We then describe how to obtain {\em complete solutions} of any marginal satisfiability problem and the marginal constraint problem. For the latter, one must determine all the facets of the \tblue{marginal polytope} (\cref{sec:projalgorithms}), which is computationally costly.  It is therefore useful to also consider relaxations of the marginal constraint problem that are less computationally burdensome by deriving valid linear inequalities which may or may not bound the marginal polytope tightly. We describe one such approach based on possibilistic Hardy-type paradoxes and the hypergraph transversal problem in \cref{sec:TSEM}. 


\begin{comment}
In what follows we consider three different strategies for constraining possible marginal distributions from the inflation hypothesis. 
\begin{compactitem}
\item The full nonlinear strategy attempts to leverage different kinds of constraints which follow from the inflation hypothesis. This strategy yields the strongest incompatibility witnesses, but relies on computationally-difficult nonlinear quantifier elimination.
\item An intermediate strategy asks only if the various marginal distributions are compatible with \emph{any} joint distribution, without regard to the specific causal structure of the inflated DAG whatsoever. Solving the marginal problem amounts to determining all the facets of the \tblue{marginal polytope}, for which we discuss algorithms in~\cref{sec:projalgorithms}. The resulting incompatibility witnesses are nevertheless still polynomial inequalities at the level of the original distribution.
\item Since computing all facets of the marginal polytope is computationally costly, one can try to derive instead only a collection of linear inequalities which bound it. One strategy for doing so is based on possibilistic Hardy-type paradoxes, which we connect to the hypergraph transversal problem. This strategy requires the least computational effort, but is limited in that it only yields polynomial inequalities of a very particular form.
\end{compactitem}

In the narrative below the marginal problem is discussed first; the nonlinear strategy is presented as supplementing the marginal problem with additional constraints. The most computationally efficient strategy is presented as a relaxation of the marginal problem, and is discussed separate from the other two strategies, namely in \cref{sec:TSEM}.
\end{comment}

Preliminary to every strategy is the identification of the pre-injectable sets, so we begin with this problem.

\subsection{Identifying the pre-injectable sets}
\label{step:findpreinjectable}

To identify the pre-injectable sets of an inflation DAG, we must first identify the injectable sets. This problem can be reduced to identifying the injectable pairs, because if all of the pairs in a set of nodes are injectable, then so too is the set itself.  The latter claim is proven as follows.   
%To prove this, it suffices to prove that if all of the pairs in a set of nodes are injectable, then so too is the set itself.  
Let $\varphi : G' \to G$ be the projection map from the inflated DAG $G'$ to
the original DAG $G$, corresponding to removing the copy-indices.  Then $\varphi$ has the characteristic feature that it takes edges to edges: if $A  \to B$ in $G'$, then also $\varphi(A) \to \varphi(B)$ in $G$. Conversely, if
$\varphi(A) \to \varphi(B)$ in $G$ then also $A \to B$ in $G'$; this follows from the
assumption that $G'$ is an inflation of $G$. 
A set $\bm{U} \subseteq \SmallNamedFunction{ObservedNodes}{G'}$ is injectable if and only if the
restriction of $\varphi$ to the ancestors of $\bm{U}$ is an injective map. 
%This is simply a more formal way to state the definition of an injective set. 
%(Recall that U itself is considered included in its set of ancestors.)
But now injectivity of a map means precisely that no two different
elements of the domain get mapped to the same element of the codomain.
So if $\bm{U}$ is injectable, then so is each of its two-element subsets;
conversely, if $\bm{U}$ is not injectable, then $\varphi$ maps two nodes among the
ancestors of $\bm{U}$ to the same node, which means that there are two nodes in the
ancestry that differ only by copy-index. Each of these two nodes must be
an ancestor of at least some node in $\bm{U}$; if one chooses two such
descendants, then one gets a two-element subset of $\bm{U}$ such that $\varphi$ is not
injective on the ancestry of that subset, and therefore this two-element
set of observed nodes is not injectable.
\color{black}

To enumerate the injectable sets, it is useful to encode certain features of the inflated DAG in an undirected graph which we call the \tblue{injection graph}. The nodes of the injection graph are the observed nodes of the inflated DAG, and a pair of nodes $A_i$ and $B_j$ share an edge if the pair $\{ A_i B_j\}$ is injectable. For example, \cref{fig:injection222} shows the injection graph of the  Spiral inflation of the Triangle scenario (\cref{fig:Tri222}).
 %$\An{A_i B_j}$ does not contain two distinct nodes that are equivalent up to copy-index. 
The property noted above states that the injectable sets are precisely the cliques\footnote{A \emph{clique} is a set of nodes in an undirected graph any two of which share an edge.} of the injection graph.
%the injectable sets are characterized by the injection graph as follows.  
%a set of nodes in the inflated DAG is injectable if and only if the corresponding set of nodes in the injection graph forms a clique. 
%The injectable sets of the inflated DAG are the cliques of the injection graph. 
 % The injectable sets are then precisely the cliques\footnote{A clique is a subset of nodes such that every node in the subset is adjacent to every other node in the subset.} in this graph, per \cref{eq:definjectable}. 
While for many other other applications only the maximal cliques are of interest, our application of the inflation technique requires knowledge of all nonempty cliques. 
% Note that it is usually necessary to enumerate \emph{all} the nonempty cliques, i.e.~not only the maximal ones.

Given a list of the injectable sets, the pre-injectable sets can be read off from the \tblue{pre-injection graph}.
%Determining the pre-injectable sets from there can be done via constructing another graph that we call the \tblue{independence graph}. 
The nodes of the pre-injection graph are taken to be the injectable sets in $G'$, and two nodes share an edge if the associated injectable sets are ancestrally independent. %Then, by definition,
\cref{fig:preinjectiongraph222} depicts an example. 
The pre-injectable sets correspond to the cliques of the pre-injection graph: the union of all the injectable sets that make up the nodes of a clique is a pre-injectable set, while the individual nodes already give us the partition into injectable sets relevant for the factorization relation of \cref{eq:preinjfactor}. 
%represented by such a clique results in a pre-injectable set. 
For our purposes, it is sufficient to enumerate the maximal pre-injectable sets, so that one only needs to consider the maximal cliques of the pre-injection graph.


%Let us also define the \tblue{ancestral dependence graph}, in which two nodes are adjacent if they share a common ancestor, and its complement the \tblue{ancestral independence graph}, in the ancestrally independent nodes are adjacent. To ascertain the factorization of a node set $\bm{U}$ into ancestrally-independent partitions one considers the subgraph on  $\bm{U}$ of the ancestral dependence graph: the ancestrally-independent partitions are identically the distinct connected components of that subgraph. By examining the injection graph and the ancestral dependence graph, therefore, one is able to quickly determine all injectable sets and all ancestral independence relations.

%It is also useful to define another auxiliary graph, the \tblue{pre-injection graph} in which a pair of nodes $A_i$ and $B_j$ are connected if either $\An{A_i B_j}$ or if $A_i\aindep B_j$. The pre-injection graph is identically the union of the injection graph with the ancestral independence graph. Any clique in the pre-injection graph is \emph{not} necessarily a pre-injectable set, but every pre-injectable set must correspond to a clique in the pre-injection graph, per \cref{eq:defpreinjectable}. Moreover, maximal-size pre-injectable sets must correspond to maximal cliques in the pre-injection graph. This makes the pre-injection graph a handy tool for determining the pre-injectable sets. We start by enumerating all maximal cliques in the pre-injection graph to obtain candidate pre-injectable sets. Each candidate set is then factored into ancestrally-independent partitions by means of the ancestral dependence graph. A candidate set is a legitimately pre-injectable if and only if all of its ancestrally-independent partitions are themselves injectable. Isolating the genuine pre-injectable sets from the candidates is therefore quite easy, especially since the complete set of injectable sets is already known.

\begin{figure}[t]
\centering
\begin{minipage}[t]{0.3\linewidth}
\centering
\includegraphics[scale=1]{injectiongraph222.pdf}
\caption{The injection graph corresponding to the Spiral inflation of the Triangle scenario (\cref{fig:Tri222}), wherein a pair of nodes are adjacent iff they are pairwise injectable.}\label{fig:injection222}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\centering
\includegraphics[scale=1]{preinjectiongraph222.pdf}
\caption{The pre-injection graph corresponding to the  Spiral inflation of the Triangle scenario (\cref{fig:Tri222}), wherein a pair of injectable sets are adjacent iff they are ancestrally independent. }\label{fig:preinjectiongraph222}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\linewidth}
\centering
\includegraphics[scale=0.25]{simplicialcomplex.pdf}
\caption{The simplicial complex of pre-injectable sets for the  Spiral inflation of the Triangle scenario (\cref{fig:Tri222}). The 5 faces correspond to the maximal pre-injectable sets, namely $\{A_1 B_1 C_1\}$, $\{A_1 B_2 C_2\}$, $\{A_2 B_1 C_2\}$, $\{A_2 B_2 C_1\}$ and $\{A_2 B_2 C_2\}$.}\label{fig:simplicialcomplex222}
\end{minipage}
\end{figure}

%\begin{figure}[t]
%\centering
%\includegraphics[scale=1]{preinjectiongraph222.pdf}
%\caption{***Pre-injection graph}\label{fig:preinjectiongraph222}
%\end{figure}

From \cref{fig:injection222,fig:preinjectiongraph222}, we easily infer the injectable sets and the maximal pre-injectable sets, as well as the partition of the maximal pre-injectable sets into ancestrally independent subsets, for the  Spiral inflation of the Triangle scenario (\cref{fig:Tri222}) to be:
\begin{align}\label{eq:basicsetup222}
%{\underbrace{\begin{matrix}
%A_2\aindep B_1\\
%A_2\aindep C_2\\
%B_2\aindep A_2\\
%B_2\aindep C_1\\
%C_2\aindep A_1\\
%C_2\aindep B_2
%\end{matrix}}_{\substack{\text{ancestrally independent}\\\text{pairs of nodes}}}}
%\qquad\qquad
{\underbrace{\begin{matrix}
\, \\
\brackets{A_1},\:\brackets{B_1},\:\brackets{C_1},\\
\brackets{A_2},\:\brackets{B_2},\:\brackets{C_2},\\
\brackets{A_1 B_1},\:\brackets{A_1 C_1},\:\brackets{B_1 C_1},\\
\brackets{A_1 B_2}.\:\brackets{A_2 C_1},\:\brackets{B_1 C_2},\\
\brackets{A_1 B_1 C_1}
\end{matrix}}_{\substack{\text{injectable sets}}}}
%\qquad\quad
%{\underbrace{\begin{matrix}
%\\ \\
%\brackets{A_2}\aindep \brackets{B_1 B_2 C_2}\\
%\brackets{B_2}\aindep \brackets{A_2 C_1 C_2}\\
%\brackets{C_2}\aindep \brackets{A_1 A_2 B_2}\\
%\brackets{A_2}\aindep \brackets{B_2}\aindep \brackets{C_2}
%\end{matrix}}_{\substack{\text{maximal}\\\text{ancestral}\\\text{independencies}}}}
%\qquad\quad
%{\underbrace{\begin{matrix}
%\brackets{ A_1 B_1 }\\
%\brackets{ B_1 C_1 }\\
%\brackets{ A_1 C_1 }\\
%\brackets{ A_2 C_1 }\\
%\brackets{ B_2 A_1 }\\
%\brackets{ C_2 B_1 }\\
%\end{matrix}}_{\substack{\text{pairwise}\\\text{injectable}\\\text{sets}}}}
\qquad\qquad
{\underbrace{\begin{matrix}
\brackets{A_1 B_1 C_1} \\
\brackets{A_1 B_2 C_2} \\
\brackets{B_1 C_2 A_2} \\
\brackets{C_1 A_2 B_2} \\
\brackets{A_2 B_2 C_2}
\end{matrix}}_{\substack{\text{maximal}\\\text{pre-injectable sets}}}}
\qquad
{\underbrace{\begin{matrix}
\\
\{A_1 B_2\} \aindep \{ C_2\} \\
\{B_1 C_2\} \aindep \{ A_2\} \\
\{C_1 A_2\} \aindep \{ B_2\} \\
\{A_2\} \aindep \{B_2\} \aindep \{ C_2\}
\end{matrix}}_{\substack{\text{relevant}\\\text{ancestral independences}}}}
\end{align}
%where we have placed commas in the maximal pre-injectable sets in order to indicate how each of these arises as a disjoint union of injectable sets with disjoint ancestry, which one can read off from the corresponding clique in the independence graph. 
Using the ancestral independence relations, the marginal distributions for the maximal pre-injectable sets factorize in the manner described by the right-hand side of \cref{eq:tri222fac}.

Having identified the pre-injectable sets together with the factorization relations implied by ancestral independences, we now discuss how to obtain constraints on the marginal distributions over the pre-injectable sets.

\subsection{The marginal problem and the marginal satisfiability problem}
\label{step:marginalsproblem}

For a given set of variables and a family of subsets thereof, determining the constraints that must hold for a family of distributions over these subsets to be obtainable as the marginals of a joint distribution over the full set of variables is known as the {\em marginal problem}.
%family of marginal distributions, each defined on a subset of the variables, determining whether there exists a joint probability distribution over the full set of variables from which all of these can be obtained as marginal distributions is known as the {\em marginal problem}.
%they can be obtained through marginalization of a single joint probability 
%The most trivial constraint on possible marginal probabilities, regardless of causal structure,  
%on the pre-injectable set
%is simply the \emph{existence of some joint probability distribution} from which the marginal distributions can be recovered through marginalization. 
%This isn't really causal inference---as no nontrivial causal hypothesis is considered---but rather more of a preliminary sanity check. If the marginal distributions are not \tblue{consistent}, then the answer to ``Can these marginal distributions be explained by this particular causal hypothesis?'' is automatically ``No''. 
%This type of problem is known as a \tblue{marginal problem}. 
For some of its history and for further references, see~\cite{fritz2013marginal}; for a more modern account using the language of presheaves, see~\cite{abramsky_contextuality_2011}.
Substantially easier than this is the problem is determining, for a numerically-specified family of distributions over these subsets, whether there exists a joint probability distribution over the full set of variables from which these can be obtained as marginals.  We refer to this as the {\em marginal satisfiability problem}.



%More precisely, a \emph{marginal problem} is specified by 
To specify either sort of marginal problem, 
%such a problem, 
one must specify the full set of variables to be considered, denoted $\bm{X}$, together with a family of subsets of $\bm{X}$, denoted $(\bm{U}_1,\ldots,\bm{U}_n)$ and called \tblue{contexts}.
%, as well as a specification of the (finite) number of outcomes that each variable is allowed to take. 
A family of contexts can be visualized through 
%It may help to draw the visualize contexts in terms of 
the simplicial complex that they generate, as the example in~\cref{fig:simplicialcomplex222} illustrates. 

Every joint distribution $P_{\bm{X}}$ %marginalization to each of $(\bm{U}_1,\ldots,\bm{U}_n)$, 
defines a family of marginal distributions, $(P_{\bm{U}_1},\ldots,P_{\bm{U}_n})$ through marginalization,  $P_{\bm{U}_i} := \sum_{\bm{X} \setminus \bm{U}_i} P_{\bm{X}}$.  
%A \emph{marginal problem} concerns
 The marginal problem and the marginal satisfiability problem concern 
 the converse inference.  
In the marginal problem, one seeks to find conditions on the family of distributions $(P_{\bm{U}_1},\ldots,P_{\bm{U}_n})$, considered as parameters, for when a joint distribution $\hat{P}_{\bm{X}}$ exists which reproduces these as marginals, that is, for which $P_{\bm{U}_i} = \sum_{\bm{X}\setminus\bm{U}_i} \hat{P}_{\bm{X}}$ for all $i$.
In the marginal satisfiability problem, a concrete family of distributions $(P_{\bm{U}_1},\ldots,P_{\bm{U}_n})$ is given, and one wants to simply decide whether there exists a joint distribution $\hat{P}_{\bm{X}}$ such that $P_{\bm{U}_i} = \sum_{\bm{X}\setminus\bm{U}_i} \hat{P}_{\bm{X}}$ for all $i$.
%as $P_{\bm{U}_i} = \hat{P}_{\bm{U}_i}$ for all $i$?

  
  \color{blue} [reordering of material starts here. T: shouldn't we mention the two items below before talking about $Mx=b$?]\color{black}
  
 We illustrate this with the example of the marginal problem where $\bm{X} := \{ A_1, A_2, B_1, B_2, C_1, C_2\}$ and the contexts are the 
%case of the five three-variable marginal distributions corresponding to the 
maximal pre-injectable sets in \cref{eq:basicsetup222}.
% For simplicity, we assume that all observable variables are binary.
%\footnote{If the observables are not binary, then the resulting  binary-outcome inequalities are necessary for marginal compatibility, in that they should hold for any course-graining of the observational data into two classes, but the binary-outcome inequalities are no longer sufficient.}.
% In order for the five pre-injectable sets in \cref{eq:preinjectableuses222} to be marginally compatible there must exist 64 nonnegative joint probabilities, i.e. satisfying
Besides normalization of probability, the only constraint on the probabilities making up the joint distribution is nonnegativity,
\begin{align}\label{eq:nonnegativity}
\forall{a_1 a_2 b_1 b_2 c_1 c_2}:\; \p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2} \geq 0.
\end{align}
We require the joint distribution to reproduce the marginal distribution on each context via
\begin{align}\label[eqs]{eq:marginalequalities222}
\begin{split}
&\forall{a_1 b_1 c_1}:\;\p[A_1 B_1 C_1]{a_1 b_1 c_1} = \sum\nolimits_{a_2 b_2 b_2}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2},\\
&\forall{a_1 b_2 c_2}:\;\p[A_1 B_2 C_2]{a_1 b_2 c_2} = \sum\nolimits_{a_2 b_1 c_1}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2},\\
&\forall{a_2 b_1 c_2}:\;\p[A_2 B_1 C_2]{a_2 b_1 c_2} = \sum\nolimits_{a_1 b_2 c_1}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2},\\
&\forall{a_2 b_2 c_1}:\;\p[A_2 B_2 C_1]{a_2 b_2 c_1} = \sum\nolimits_{a_1 b_1 c_2}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2},\\
&\forall{a_2 b_2 c_2}:\;\p[A_2 B_2 C_2]{a_2 b_2 c_2} = \sum\nolimits_{a_1 b_1 c_1}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2}.
\end{split}
\end{align}
%For example in the case of binary variables, we therefore 
If each variable is binary, then we have $64$ inequalities and $40$ equations, although the latter are not all independent. 

\color{blue} To formalize the generic problem, we introduce \color{black}
%the marginal problem in terms of
  a \tblue{marginal description matrix} $\bm{M}$, a \tblue{marginal distribution vector} $\bm{b}$, and some unknown \tblue{joint distribution vector} $\bm{x}$. The generic
  %marginal 
  problem can then be stated as
\begin{align}\label{eq:marginalproblemgeneric}
    \exists {\bm{x} \geq \bm{0}} :\; \bm{M}\bm{x}=\bm{b}.
\end{align}
In the example we have been discussing, $\bm{M}$ would be a $48\times 64$ matrix, so that $\bm{M}\bm{x}=\bm{b}$ represents 48 equations and $\bm{x} \geq \bm{0}$ represents 64 inequalities. Note that the marginal description matrix $\bm{M}$  has only zeroes and ones as its constituent elements.

 
 \color{blue} We begin with the marginal problem.  \color{black}
 
 %There is a simple necessary condition: in 
In order for $\hat{P}_{\bm{X}}$ to exist, \color{blue} distributions on different contexts \color{black} clearly must be consistent, in the sense that marginalizing $P_{\bm{U}_i}$ to the variables in $\bm{U}_i\cap\bm{U}_j$ results in the same distribution as marginalizing $P_{\bm{U}_j}$ to those variables.  
%\footnote{This is difficult to express explicitly in our notation, since $P_{\bm{U}_i\cap \bm{U}_j}$ could refer to either marginal.}. 
 %we have already seen in the previous section, 
  In many cases, this is not sufficient; indeed, we have already seen examples of additional constraints, namely, the inequalities \eqref{eq:polymonogamyraw}, \eqref{eq:MIraw} and \eqref{eq:FritzF3raw} from \cref{Sec:DerivingInequalities}\footnote{Depending on how the contexts intersect with one another, this \emph{may} be sufficient. A precise characterization for when this occurs has been found by~\citet{vorobev_extension_1960}.}. 
% To provide a complete solution,  one must determine not just necessary conditions on the family of distributions for these to arise as the marginals of a single distribution, but the necessary and sufficient conditions. \color{black}
So what are the necessary and sufficient conditions?

To answer this question, it helps to realize two things:
\begin{itemize}
	\item The set of possibilities for the distribution $P_{\bm{X}}$ is the convex hull of the deterministic assignments of values to $\bm{X}$ (the point distributions), and 
%	Every joint distribution $P_{\bm{X}}$ is a convex combination of deterministic assignments of values to all variables (delta distributions), and conversely.
	\item The map $P_{\bm{X}}\to (P_{\bm{U}_1},\ldots,P_{\bm{U}_n})$, describing marginalization to each of the contexts in $(\bm{U}_1,\ldots,\bm{U}_n)$, is linear.
\end{itemize}
Hence the image of the set of possibilities for the distribution $P_{\bm{X}}$ under the map $P_{\bm{X}}\to (P_{\bm{U}_1},\ldots,P_{\bm{U}_n})$ is exactly the convex hull of the deterministic assignments of values to $(\bm{U}_1,\ldots,\bm{U}_n)$ (more precisely, the deterministic assignments that are consistent where these contexts overlap). Since there are only finitely many such deterministic assignments, this convex hull is a polytope; it is called the \tblue{marginal polytope}~\cite{kahle_marginal_2010}. Together with the above equations on coinciding submarginals, the facet inequalities of the marginal polytope form necessary and sufficient conditions for the marginal problem to have a solution.

%Thus solving the marginal problem is an instance of a facet enumeration problem, or equivalently a linear quantifier elimination problem;~\cref{sec:projalgorithms} gives an overview of how to solve this in practice. 


% quantifier-free form in terms of inequalities such that satisfaction of all such inequalities is necessary and sufficient for marginal compatibility. An efficient algorithm to solve the marginal problem is given in \cref{sec:projalgorithms}. The marginal problem comes up in a variety of applications, and has been studied extensively; see~\cite{fritz2013marginal} for further references.

As every facet enumeration problem, this can also be phrased as a problem of \tblue{linear quantifier elimination}. 
The marginal problem is a linear system of equations and inequalities relating the unknown joint probabilities to the accessible marginal probabilities. The problem of quantifier elimination consists in finding an equivalent system of equations and inequalities that is satisfied if and only if the original system has a solution for the unknown probabilities. This requires eliminating 64 unknowns $\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2}$ for each of the 64 choices of the values $a_1,\ldots,c_2$. The resulting new system consists of the coinciding-submarginals equations together with the facet inequalities of the marginal polytope.
%joint probabilities $\{ \p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2} : (a_1 a_2 b_1 b_2 c_1 c_2) {\underline{\phantom{xxxxx}}}$, 
%and to thereby compute the inequalities that constrain the marginal probabilities.


%In this formulation, 
\color{blue} In terms of the formalization of the generic problem in terms of the marginal description matrix $\bm{M}$,\color{black} 
a valid inequality---such as a facet of the marginal polytope---is represented by a vector $\bm{y}$ such that $\bm{y}^T\bm{M}\geq\bm{0}$. The marginal problem for a given distribution has a negative solution if and only if there is a valid inequality $\bm{y}$ with $\bm{y}^T\bm{b} < 0$. For if \cref{eq:marginalproblemgeneric} has a solution $\bm{x}$, then $\bm{y}^T\bm{M}\geq \bm{0}$ and $\bm{x}\geq \bm{0}$ imply $\bm{y}^T\bm{b} = \bm{y}^T\bm{M}\bm{x} \geq 0$; the other direction is Farkas' lemma. Upon substituting \cref{eq:preinjfactor} and deleting copy indices, such an inequality turns into a causal compatibility inequality.

Linear quantifier elimination is already used in causal inference for deriving entropic causal compatibility inequalities \cite{chaves2014novel,chaves2014informationinference}. In that task, however, the unknowns being eliminated are entropies on sets of variables of which one or more is latent. By contrast, the unknowns being eliminated above are all probabilities on sets of variables all of which are observed---but on the inflated DAG rather than the original DAG.
%The unknowns we eliminate are the not-pre-injectable joint probabilities, which are, at least on first look, quite different from probabilities involving latent variables;
\cref{sec:Bellscenarios} will partly elucidate the relation.

The marginal problem is a standard facet enumeration problem, in that the vertices of the polytope are given. The derivation of entropic inequalities, by contrast, is a priori only a linear quantifier elimination task, and more difficult to cast as a facet enumeration problem with given vertices, since the vertices (extremal rays) of the Shannon cone elude a simple description. As such, while facet enumeration tools are useful for deriving polynomial inequalities via the inflation technique, they are not directly available for the derivation of entropic inequalities; see \cref{sec:projalgorithms} for further details.

\color{blue} We turn now to a formalization of the marginal satisfiability problem.  In this case, the numerical values for 
%the left-hand sides of the equations defining the marginal problem, such as \cref{eq:marginalequalities222}. 
the marginal distribution vector $\bm{b}$ 
%$\bm{b}\to\bm{b}_{\mbox{numeric}}$
in \cref{eq:marginalproblemgeneric} are given; we denote these by $\bm{b}_{\text{numeric}}$. \color{black} A single linear program can then assess whether the marginal problem equalities, i.e., the matrix equality of \cref{eq:marginalproblemgeneric}, can be solved using nonnegative values for the unknown joint probabilities, $\bm{x} \geq \bm{0}$, or not. If the marginal problem cannot be satisfied, then the original distribution is witnessed as incompatible with the original DAG. 

As this satisfiability problem is a linear program, testing specific distributions for compatibility for a given inflation DAG is computationally inexpensive. For instance, using the rather complex Web inflation of the Triangle scenario, depicted in \cref{fig:TriFullDouble}, our numerical computations have reproduced the result of~\cite[Theorem~2.16]{fritz2012bell}, that a certain distribution considered therein is incompatible with the Triangle scenario\footnote{This distribution {\em is}, however, quantum-compatible with the Triangle scenario (\cref{sec:classicallity}).  It was constructed from a distribution that is quantum-compatible but classically-incompatible with the Bell scenario.}.

When $\bm{M}\bm{x}=\bm{b}_{\text{numeric}}$ has no nonnegative solution $\bm{x}$, then the system is considered \emph{primal infeasible}. Many linear programming tools are capable of returning a \emph{Farkas infeasibility certificate} \cite{infeasibilitycertificates} whenever a linear system is primal infeasible\footnote{Farkas infeasibility certificates are available, for example, in \href[pdfnewwindow]{http://docs.mosek.com/8.0/pythonapi/optimizer-task-gety.html}{\textit{Mosek}}, \href[pdfnewwindow]{https://www.gurobi.com/documentation/6.5/refman/farkasdual.html}{\textit{Gurobi}}, and \href[pdfnewwindow]{http://www-01.ibm.com/support/docview.wss?uid=swg21400058}{\textit{CPLEX}}, as well as by accessing dual variables in \href[pdfnewwindow]{http://cvxr.com/cvx/doc/basics.html\#dual-variables}{\textit{cvxr}}/\href[pdfnewwindow]{http://cvxopt.org/userguide/coneprog.html\#linear-cone-programs}{\textit{cvxopt}}.}. This is given by the coefficient vector $\bm{y}$ of an inequality that is valid in the sense that $\bm{y}^T\bm{M}\geq \bm{0}$, but violated on the given data, $\bm{y}^T\bm{b}_{\text{numeric}} < 0$. 
%\color{blue} causal compability inequality 

\color{blue} The Farkas infeasibility certificate therefore defines a causal compatibility inequality for the inflated DAG, one that is violated by the given family of distributions on the pre-injectable sets.  This inequality in turn defines a causal compatibility inequality for the original DAG that is violated by the given joint distribution.  In other words, if a numerically-specified distribution is witnessed as incompatible with a DAG using the technique we have described, then with little additional numerical effort, one can also obtain a causal compatibility inequality that exhibits the incompatibility.  

This may well have applications for problems where it is numerically infeasible to obtain a complete solution of the marginal problem. 
%In this way, witnessing the causal incompatibility of a given distribution via the inflation technique results also in a concrete causal incompatibility that may also have other applications.
 \color{black} 


\subsection{Causal compatibility inequalities via a complete solution of the marginal problem}\label{sec:CCineqs}

For deriving causal compatibility inequalities systematically, one chooses an inflation DAG and identifies the maximal pre-injectable sets, as described above. Then ones solves the marginal problem via facet enumeration\footnote{In \cref{sec:projalgorithms}, we provide an overview of techniques for facet enumeration.} of the marginal polytope, where the contexts are the maximal pre-injectable sets. This results in linear inequalities at the level of the inflation DAG.
%As we note there, it can be reduced to a linear quantifier elimination problem, which is the technique we apply here.
By substituting into these inequalities the factorization conditions implied by ancestral independences per \cref{eq:preinjfactor}, one obtains causal compatibility inequalities for the inflated DAG.  Finally, these can be converted into causal compatibility inequalities for the original DAG using \cref{maincorollary}.

%\color{purple} Move this paragraph to later. \color{black}
%Given a facet of the marginal polytope---or any other linear inequality that bounds it---we can construct a polynomial inequality for our original causal inference problem by plugging in the factorization relations of \cref{mainlemma}. Doing the same with the equations of coinciding submarginals shows that these are trivially satisfied, and thus it is only the inequalities that are of interest to us.



As an example, 
%To illustrate the power of the inflation technique, 
we present all of the causal compatibility inequalities that one can derive for the Triangle scenario with binary observed variables using the Spiral inflation of the Triangle scneario~(\cref{fig:Tri222}). The contexts for the marginal problem are the maximal pre-injectable sets of \cref{eq:basicsetup222} and \cref{fig:simplicialcomplex222}. We solve this marginal problem using facet enumeration. It turns out that the marginal polytope has 64 symmetry classes of facets, where the symmetry transformations are given by permutations of the observed variables, by flipping the value of one variable, and by composites of these.
%The following polynomial inequalities for the Triangle scenario with binary observed variables have been derived via the linear quantifier elimination method of~\cref{sec:ineqs} using the inflated DAG of~\cref{fig:Tri222}. 
%This results in 64 symmetry classes of causal compatibility inequalities for the Triangle scenario, where the symmetries are given by permuting the variables and inverting the outcomes. 
Applying the factorization of probabilities according to ancestral independences per \cref{eq:basicsetup222} and converting into inequalities for the original DAG using \cref{maincorollary} results in 64 polynomial inequalities up to symmetry. However, there is no guarantee that each one of these inequalities is nontrivial at the level of the original DAG, where nontriviality of an inequality means that it is violated by at least one distribution. Numerically, we find that only 37 of these inequalities are indeed nontrivial. We present all  37 symmetry classes of causal compatibility inequalities  here in correlator form\footnote{A machine-readable version of this list of inequalities may be found in \cref{sec:38ineqs}.}:
 %For the resulting 64 inequalities, numerical checks have found violations of only 38 of them: although they are all facets of the marginal polytope over the distributions on pre-injectable sets, there is no guarantee that they are also nontrivial inequalities at the level of the original DAG, and this has indeed turned out not to be the case for 26 of these symmetry classes of inequalities. 
\begin{align*}%\label{nontriv.humanreadable}
\hspace{-\mathindent}\resizebox{\linewidth}{!}{\(
\begin{array}{ll}
 \text{($\#$} 1^* \text{):  } & 0\leq 1+\expec{B} \expec{C}+\expec{AB}+\expec{AC} \\
 \text{($\#$} 2 \text{):  } & 0\leq 2+\expec{A} \expec{B} \expec{C}-\expec{C} \expec{AB}-2 \expec{AC} \\
 \text{($\#$} 3^* \text{):  } & 0\leq 3+\expec{A}-\expec{B}+\expec{C}+\expec{B} \expec{C}+\expec{A} \expec{B}
   \expec{C}+\expec{AB}-\expec{C} \expec{AB}+3 \expec{AC}-\expec{B} \expec{AC} \\
 \text{($\#$} 4^* \text{):  } & 0\leq 3+\expec{A}-\expec{B}+\expec{C}+\expec{B} \expec{C}-\expec{A} \expec{B}
   \expec{C}+\expec{AB}+\expec{C} \expec{AB}+3 \expec{AC}-\expec{B} \expec{AC} \\
 \text{($\#$} 5 \text{):  } & 0\leq 3+\expec{B}-\expec{A} \expec{B}+\expec{A} \expec{C}+\expec{A} \expec{B}
   \expec{C}+\expec{AB}+\expec{C} \expec{AB}-\expec{B} \expec{AC}-2 \expec{BC} \\
 \text{($\#$} 6 \text{):  } & 0\leq 3+\expec{B}+\expec{A} \expec{C}+\expec{A} \expec{B} \expec{C}-\expec{C} \expec{AB}-2
   \expec{AC}-\expec{B} \expec{AC}-2 \expec{BC} \\
 \text{($\#$} 7 \text{):  } & 0\leq 3+\expec{B}+\expec{A} \expec{B}-\expec{A} \expec{C}-\expec{A} \expec{B}
   \expec{C}+\expec{AB}+\expec{C} \expec{AB}+\expec{B} \expec{AC}-2 \expec{BC} \\
 \text{($\#$} 8^* \text{):  } & 0\leq 3+\expec{A}+\expec{B}+\expec{A} \expec{B}+\expec{C}+\expec{A} \expec{C}+\expec{B}
   \expec{C}-\expec{A} \expec{B} \expec{C}+2 \expec{AB}+\expec{C} \expec{AB}+2 \expec{AC}+\expec{B} \expec{AC}+2 \expec{BC}+\expec{A}
   \expec{BC}-\expec{ABC} \\
 \text{($\#$} 9^* \text{):  } & 0\leq 3+\expec{A}+\expec{B}-\expec{A} \expec{B}+\expec{C}+\expec{A} \expec{C}+\expec{B}
   \expec{C}-\expec{A} \expec{B} \expec{C}+\expec{C} \expec{AB}+2 \expec{AC}+\expec{B} \expec{AC}-2 \expec{BC}-\expec{A}
   \expec{BC}+\expec{ABC} \\
 \text{($\#$} 10^* \text{):  } & 0\leq 4+2 \expec{A} \expec{B}+2 \expec{C}+2 \expec{B} \expec{C}-2 \expec{AB}+\expec{C} \expec{AB}-2
   \expec{AC}+\expec{B} \expec{AC}+\expec{A} \expec{BC}-\expec{ABC} \\
 \text{($\#$} 11^* \text{):  } & 0\leq 4-2 \expec{B}+\expec{B} \expec{C}+\expec{A} \expec{B} \expec{C}-2 \expec{AB}+\expec{C}
   \expec{AB}-\expec{B} \expec{AC}-3 \expec{BC}+\expec{ABC} \\
 \text{($\#$} 12^* \text{):  } & 0\leq 4-2 \expec{B}+2 \expec{A} \expec{C}+\expec{B} \expec{C}-\expec{A} \expec{B} \expec{C}-2
   \expec{AB}+\expec{C} \expec{AB}-2 \expec{AC}+\expec{B} \expec{AC}-3 \expec{BC}+\expec{ABC} \\
 \text{($\#$} 13^* \text{):  } & 0\leq 4-2 \expec{A} \expec{B}-2 \expec{A} \expec{C}-\expec{B} \expec{C}-\expec{A} \expec{B}
   \expec{C}+2 \expec{AB}-\expec{C} \expec{AB}-2 \expec{AC}+\expec{B} \expec{AC}+\expec{BC}+\expec{ABC} \\
 \text{($\#$} 14^* \text{):  } & 0\leq 4-2 \expec{A} \expec{B}+2 \expec{A} \expec{C}-\expec{B} \expec{C}+\expec{A} \expec{B}
   \expec{C}+2 \expec{AB}+\expec{C} \expec{AB}-2 \expec{AC}+\expec{B} \expec{AC}+\expec{BC}+\expec{ABC} \\
 \text{($\#$} 15^* \text{):  } & 0\leq 4+2 \expec{A} \expec{C}+\expec{B} \expec{C}+\expec{A} \expec{B} \expec{C}-\expec{C} \expec{AB}-2
   \expec{AC}-\expec{B} \expec{AC}+3 \expec{BC}+\expec{ABC} \\
 \text{($\#$} 16^* \text{):  } & 0\leq 4-2 \expec{B}+2 \expec{A} \expec{C}-2 \expec{AB}+\expec{C} \expec{AB}-2 \expec{AC}+\expec{B}
   \expec{AC}-2 \expec{BC}-\expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 17^* \text{):  } & 0\leq 4+2 \expec{A} \expec{B}+2 \expec{A} \expec{C}+2 \expec{B} \expec{C}-2 \expec{AB}+\expec{C}
   \expec{AB}-2 \expec{AC}+\expec{B} \expec{AC}-2 \expec{BC}+\expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 18 \text{):  } & 0\leq 5+\expec{A}+\expec{B}-2 \expec{A} \expec{B}+\expec{C}+\expec{B} \expec{C}+\expec{A} \expec{B}
   \expec{C}+3 \expec{AB}+\expec{C} \expec{AB}+\expec{AC}-\expec{B} \expec{AC}-4 \expec{BC} \\
 \text{($\#$} 19^* \text{):  } & 0\leq 5+\expec{A}+\expec{B}+2 \expec{A} \expec{B}+\expec{C}-2 \expec{A} \expec{C}+\expec{B}
   \expec{C}-\expec{A} \expec{B} \expec{C}+3 \expec{AB}+\expec{C} \expec{AB}-\expec{AC}+\expec{B} \expec{AC}-4 \expec{BC} \\
 \text{($\#$} 20^* \text{):  } & 0\leq 5+\expec{A}-\expec{B}-2 \expec{A} \expec{B}+\expec{C}-\expec{A} \expec{C}+\expec{B}
   \expec{C}+\expec{AB}+\expec{C} \expec{AB}+2 \expec{AC}-2 \expec{B} \expec{AC}-2 \expec{BC}-2 \expec{A} \expec{BC}-2 \expec{ABC} \\
 \text{($\#$} 21^* \text{):  } & 0\leq 5+\expec{A}+\expec{B}+\expec{C}-\expec{A} \expec{C}-\expec{B} \expec{C}-2 \expec{A} \expec{B}
   \expec{C}+\expec{AB}+2 \expec{C} \expec{AB}+2 \expec{AC}+\expec{B} \expec{AC}-2 \expec{BC}+\expec{A} \expec{BC}-\expec{ABC} \\
 \text{($\#$} 22^* \text{):  } & 0\leq 5-\expec{A}+\expec{B}-2 \expec{A} \expec{B}+\expec{C}-2 \expec{A} \expec{C}+2 \expec{B}
   \expec{C}+\expec{AB}-2 \expec{C} \expec{AB}+\expec{AC}-2 \expec{B} \expec{AC}-\expec{BC}-2 \expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 23^* \text{):  } & 0\leq 5+\expec{A}+\expec{B}-\expec{A} \expec{B}+\expec{C}+2 \expec{B} \expec{C}+\expec{A} \expec{B}
   \expec{C}+2 \expec{AB}-\expec{C} \expec{AB}+\expec{AC}-2 \expec{B} \expec{AC}-\expec{BC}-2 \expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 24^* \text{):  } & 0\leq 5+\expec{A}+\expec{B}-2 \expec{A} \expec{B}+\expec{C}-\expec{A} \expec{C}-\expec{B} \expec{C}-2
   \expec{A} \expec{B} \expec{C}-\expec{AB}+2 \expec{C} \expec{AB}+2 \expec{AC}+\expec{B} \expec{AC}+2 \expec{BC}-\expec{A}
   \expec{BC}+\expec{ABC} \\
 \text{($\#$} 25 \text{):  } & 0\leq 6+2 \expec{A} \expec{B}+\expec{A} \expec{C}+2 \expec{B} \expec{C}+\expec{A} \expec{B} \expec{C}-4
   \expec{AB}-2 \expec{C} \expec{AB}-3 \expec{AC}-\expec{B} \expec{AC}-2 \expec{A} \expec{BC} \\
 \text{($\#$} 26 \text{):  } & 0\leq 6-2 \expec{A}+\expec{A} \expec{B}+2 \expec{C}+\expec{A} \expec{C}+2 \expec{A} \expec{B}
   \expec{C}-5 \expec{AB}-\expec{C} \expec{AB}-3 \expec{AC}+\expec{B} \expec{AC}-2 \expec{A} \expec{BC} \\
 \text{($\#$} 27 \text{):  } & 0\leq 6+2 \expec{A} \expec{B}+2 \expec{C}+\expec{A} \expec{C}+\expec{A} \expec{B} \expec{C}-4
   \expec{AB}-2 \expec{C} \expec{AB}+3 \expec{AC}+\expec{B} \expec{AC}-2 \expec{A} \expec{BC} \\
 \text{($\#$} 28 \text{):  } & 0\leq 6+\expec{A} \expec{B}+\expec{A} \expec{C}-4 \expec{B} \expec{C}-2 \expec{A} \expec{B}
   \expec{C}+\expec{AB}+\expec{C} \expec{AB}-3 \expec{AC}-\expec{B} \expec{AC}+2 \expec{BC}-2 \expec{A} \expec{BC} \\
 \text{($\#$} 29 \text{):  } & 0\leq 6+2 \expec{B}+\expec{A} \expec{B}-2 \expec{A} \expec{C}+\expec{B} \expec{C}-2 \expec{A} \expec{B}
   \expec{C}+3 \expec{AB}+\expec{C} \expec{AB}+2 \expec{B} \expec{AC}-5 \expec{BC}+\expec{A} \expec{BC} \\
 \text{($\#$} 30 \text{):  } & 0\leq 6+2 \expec{B}-2 \expec{A} \expec{B}+4 \expec{A} \expec{C}-\expec{B} \expec{C}+\expec{A} \expec{B}
   \expec{C}+2 \expec{AB}+2 \expec{C} \expec{AB}-2 \expec{AC}+2 \expec{B} \expec{AC}+\expec{BC}+\expec{A} \expec{BC} \\
 \text{($\#$} 31 \text{):  } & 0\leq 6+\expec{A} \expec{C}+4 \expec{B} \expec{C}+\expec{A} \expec{B} \expec{C}-2 \expec{AB}-2 \expec{C}
   \expec{AB}-3 \expec{AC}-\expec{B} \expec{AC}-2 \expec{BC}-2 \expec{ABC} \\
 \text{($\#$} 32 \text{):  } & 0\leq 7+\expec{A}+\expec{B}+\expec{A} \expec{B}+\expec{C}-2 \expec{A} \expec{C}+2 \expec{B}
   \expec{C}-\expec{A} \expec{B} \expec{C}+2 \expec{AB}+3 \expec{C} \expec{AB}+\expec{AC}+2 \expec{B} \expec{AC}-3 \expec{BC}-2
   \expec{A} \expec{BC}+3 \expec{ABC} \\
 \text{($\#$} 33 \text{):  } & 0\leq 8+2 \expec{A} \expec{B}+4 \expec{A} \expec{C}-2 \expec{B} \expec{C}+2 \expec{A} \expec{B}
   \expec{C}-2 \expec{AB}-\expec{C} \expec{AB}-4 \expec{AC}+\expec{B} \expec{AC}-2 \expec{BC}-3 \expec{A} \expec{BC}-3 \expec{ABC} \\
 \text{($\#$} 34 \text{):  } & 0\leq 8+2 \expec{A}-2 \expec{C}-\expec{A} \expec{C}+2 \expec{B} \expec{C}+3 \expec{A} \expec{B}
   \expec{C}-6 \expec{AB}+\expec{C} \expec{AB}+\expec{AC}+2 \expec{B} \expec{AC}-3 \expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 35 \text{):  } & 0\leq 8+2 \expec{A}+\expec{A} \expec{C}+2 \expec{B} \expec{C}+3 \expec{A} \expec{B} \expec{C}+6
   \expec{AB}-\expec{C} \expec{AB}+\expec{AC}-2 \expec{B} \expec{AC}-2 \expec{BC}-3 \expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 36 \text{):  } & 0\leq 8-2 \expec{B}+2 \expec{A} \expec{B}-2 \expec{C}-\expec{B} \expec{C}-3 \expec{A} \expec{B}
   \expec{C}+3 \expec{C} \expec{AB}-6 \expec{AC}+\expec{B} \expec{AC}+\expec{BC}-2 \expec{A} \expec{BC}+\expec{ABC} \\
 \text{($\#$} 37 \text{):  } & 0\leq 8+2 \expec{B}+\expec{A} \expec{B}-2 \expec{A} \expec{C}-3 \expec{A} \expec{B}
   \expec{C}+\expec{AB}+2 \expec{C} \expec{AB}+2 \expec{AC}+3 \expec{B} \expec{AC}-6 \expec{BC}-\expec{A} \expec{BC}+\expec{ABC} \\
\end{array}
\)}
\end{align*}
A star next to the index of an inequality indicates that the inequality can also be derived by considering the possibilistic constraints per \cref{sec:TSEM}. It is likely that these 37 symmetry classes of causal compatibility inequalities are not a minimal generating set, where a minimal generating set is defined to be one such that, for every inequality, there is a distribution that violates it while satisfying all of the others. 


\subsection{Causal compatibility inequalities via Hardy-type inferences from logical tautologies}\label{sec:TSEM}


%\color{red}
Enumerating all the facets of the marginal polytope is computationally feasible only for small examples. But our method transforms \emph{every} inequality that bounds the marginal polytope into a causal compatibility inequality. We now present a general approach for deriving a special type of such inequalities very quickly.

In the literature on Bell inequalities, it has been noticed that incompatibility with the Bell DAG can sometimes be witnessed by merely looking at which joint outcomes have zero probability and which ones have nonzero probability. In other words, instead of considering the \emph{probability} of an outcome, the inconsistency of some marginal distributions can be evident from considering only the \emph{possibility} or \emph{impossibility} of each outcome. This insight is originally due to~\citet{L.Hardy:PRL:1665}, and versions of Bell's theorem that are based on the violation of such \tblue{possibilistic constraints} are known as \tblue{Hardy-type paradoxes}~\cite{Garuccio95,CabelloHardyInequality,Braun08,Mancinska14,LSW}; a partial classification of these can be found in~\cite{Mansfield2012}. The method that we describe in the second half of this section can be used to compute a complete classification of possibilistic constraints for \emph{any} marginal problem.

Possibilistic constraints follow from a consideration of {\em logical relations} that can hold among deterministic assignments to the observed variables. Such logical constraints can also be leveraged to derive probabilistic constraints instead of possibilistic ones, as shown in~\cite{Pitowsky1989,Ghirardi08}. This results in a partial solution to any given (probabilistic) marginal problem. Essentially, we solve a possibilistic marginal problem \cite{Mansfield2012}, then upgrade the possibilistic inequalities into probabilistic inequalities, resulting in a set of probabilistic inequalities whose cumulative satisfaction is a necessary but insufficient condition for satisfying the corresponding probabilistic marginal problem. We now demonstrate how to systematically derive all inequalities of this type.

We have already provided a simple example of a Hardy-type argument in \cref{Sec:DerivingInequalities}, in the logic used to demonstrate that the marginal distributions of \cref{W4,W1,W5} are incompatible with the DAG depicted in \cref{fig:Tri222v2}.   For our present purposes, it is useful to recast the argument of \cref{Sec:DerivingInequalities} into a new but manifestly equivalent form.    

First, for the distribution in question, we have
\begin{align} 
\begin{split}\label{WWs}
&A_2 \eql 1 \implies C_1\eql 0,\\
&B_2\eql 1 \implies A_1\eql 0,\\
&C_2 \eql 1 \implies B_1 \eql 0,\\
\text{Never}  &\quad A_1 \eql 0\,\text{ and }\, B_1 \eql 0\,\text{ and }\, C_1 \eql 0.
\end{split}
\end{align}
From the last constraint one infers that at least one of $A_1$, $B_1$ and $C_1$ must be 1, which from the three other constraints implies that at least one of $A_2$, $B_2$ and $C_2$ must be 0, so that it is not the case that all of $A_2$, $B_2$ and $C_2$ are 1.  Thus~\cref{WWs} implies
\begin{align} \label{consequent2}
\text{Never}  \quad &A_2 \eql 1\,\text{ and }\, B_2 \eql 1\,\text{ and }\, C_2 \eql 1.
\end{align}
However, the DAG of~\cref{fig:Tri222v2} is such that $A_2$,$B_2$, and $C_2$ have no common ancestor and consequently these variables are marginally independent in any distribution compatible with this DAG.  Combining this with the fact that the marginal distribution for each of these three variables has full support implies that $A_2$,$B_2$, and $C_2$ sometimes all take the value 1, which contradicts \cref{consequent2}.  What is nice about this form of the reasoning is that the appeal to the causal structure occurs only in the very last step.  

We are here interested in recasting the argument in such a way that the appeal to {\em both} the causal structure {\em and} the form of the marginal distributions occurs only in the very last step.  This is done as follows.  The first step of the argument is to note that\footnote{Here, $\land$, $\lor$ and $\lnot$ denote conjunction, disjunction and negation respectively.}
\begin{align}\begin{split}\label{tautology1}
&\lnot [A_2 \eql 1 \land C_1 \eql 1] \bigwedge \lnot [B_2 \eql 1 \land A_1 \eql 1] \bigwedge \lnot [C_2 \eql 1 \land B_1 \eql 1] \bigwedge \lnot [A_1 \eql 0 \land B_1 \eql 0 \land C_1 \eql 0]\\
 &\qquad\implies
\lnot [A_2 \eql 1 \land B_2 \eql 1 \land C_2 \eql 1].
\end{split}\end{align}
is a logical tautology for binary variables. The second and final step of the argument notes that the given distribution and the given causal structure imply that the antecedent is true while the consequent is false, so that the distribution and causal structure together imply a contradiction.

%Such Hardy-type arguments for incompatibility actually only require one to be given an assignment of {\em possible} or {\em impossible} to certain valuations of variables rather an assignment of probabilities thereto. We call such assignments {\em possibilistic}.  

In our recasting of the Hardy-type argument, the first step---identifying a logical tautology among valuations of certain subsets of the variables---can be understood as a constraint on marginal {\em deterministic assignments}, and it is a constraint that follows from logic alone.  
%It can be understood as the logical analogue of identifying a constraint on marginals distributions that holds for {\em any} joint distribution.  
It is useful to think of this first step as the logical counterpart of a constraint on marginals. 
%the marginal problem.


%Imagine that one has specified the full set of variables, denoted $\bm{X}$, together with a family of subsets of $\bm{X}$, termed contexts and denoted $(\bm{U}_1,\ldots,\bm{U}_n)$.  A \emph{joint deterministic assignment} to $\bm{X}$ specifies a joint valuation of the variables in $\bm{X}$.  A \emph{marginal deterministic assignment} for the context $\bm{U}_i$, specifies a  joint valuation of the variables in $\bm{U_i}$. Clearly, every joint deterministic assignment defines a family of marginal deterministic assignments through restriction.   For any given family of marginal deterministic assigments, one can seek to find the conditions under which therese are the restriction of some joint deteministic assignment.  [IS THAT LAST THING RIGHT?]


%As such, \cref{tautology1} can indeed be understood as a constraint on marginal possibilistic assignments.  Thinking of it this way makes it clear that witnessing incompatibility by starting with a Hardy-type logical tautology is the possibilistic analogue of deriving causal compatibility inequalities starting with a solution of the marginal problem.  More importantly, such constraints on marginal possibilistic assignments are interesting because they can be used to derive constraints on marginal distributions, as was shown by \citet{Mansfield2012}.  

We illustrate this last claim with the example just discussed.  It can be cast as a marginal scenario where the contexts are $\{A_2 B_2 C_2\}$, $\{A_2 C_1\}$, $\{B_2 A_1\}$, $\{C_2 B_1\}$, and  $\{A_1 B_1 C_1\}$.  The logical tautology \eqref{tautology1} is then a constraint on marginal determinstic  assignments for this marginal scenario.   To see how to obtain a constraint on marginal {\em distributions}, we start by rewriting \cref{tautology1} in its contrapositive form,
\begin{align}\begin{split}\label{tautology2}
&[\mgreen{A_2 \eql 1} , \mgreen{B_2 \eql 1} , \mgreen{C_2 \eql 1}]  \implies [\mgreen{A_2 \eql 1}, C_1 \eql 1] \lor  [\mgreen{B_2 \eql 1}, A_1 \eql 1] \lor  [\mgreen{C_2 \eql 1}, B_1 \eql 1] \lor  [A_1 \eql 0 \land B_1 \eql 0 \land C_1 \eql 0].
\end{split}\end{align}
Next, we note that if a logical tautology can be expressed as
\begin{align}\label{eq:inference}
    \SmallNamedFunction{}{E_0} \implies \SmallNamedFunction{}{E_1} \lor \ldots \lor \SmallNamedFunction{}{E_n},
\end{align}
then by applying the union bound---which asserts that the probability of at least one of a set of events occuring is no greater than the sum of the probabilities of each event occuring---one obtains
\begin{align}\label{eq:possinference}
\p{E_0}\leq \sum\limits_{j=1}^n{\p{E_j}}.
\end{align}
Applying the union bound to \cref{tautology2} in particular yields
\begin{align}\label{eq:F3rawweak}
P_{A_2 B_2 C_2}\parens{\mgreen{1} \mgreen{1} \mgreen{1}} \leq P_{A_1 B_1 C_1}\parens{0 0 0}+P_{A_1 B_2}\parens{1 \mgreen{1 }}+P_{ B_1 C_2}\parens{ 1 \mgreen{1}}+P_{A_2 C_1}\parens{\mgreen{1 } 1},
\end{align}
which is a constraint on the marginal {\em distributions}.
 
Note that this inequality allows one to demonstrate the incompatibility of the marginal distributions of \cref{W4,W1,W5} with the Spiral inflation of the Triangle scenario just as easily as one can with the tautology of \cref{tautology1}.  It suffices to note that the given distribution and causal structure imply that the left-hand side has nonzero probability (which corresponds to the consequent of \cref{tautology1} being false) while every term on the right-hand side has zero probability (which corresponds to the antecedent of  \cref{tautology1} begin true).
%This is a causal compatibility inequality for the inflated DAG.  It can be used to demonstrate the incompatibility of the marginal distributions of Eqs.~\eqref{W4}-\eqref{W7} with the inflated DAG because these marginal distributions assing probability 0 to all terms on the right-hand side, while these together with the causal structure imply a nonzero probability for the term on the left-hand side.  
But, of course, the inequality can witness many other incompatibilities in addition to this one.

As another example, consider the marginal problem where the variables are $\{ A,B,C\}$, with each being binary, and the contexts are the pairs $\{AB\}$, $\{AC\}$, and $\{BC\}$.  
%where the pairwise joint distributions of three variables $A$, $B$ and $C$ are given. %, and these two variables are binary with values in $\{0,1\}$. 
The following tautology provides a constraint on marginal deterministic assignments:\footnote{This is a tautology since $E \land F  \implies  E \land F \land (G \lor \lnot G) = (E \land F \land G) \lor (E\land F \land \lnot G) \implies (E \land G) \lor (F \land \lnot G)$.}
%A possibilistic constraint that follows from logic alone, and therefore is true regardless of the joint distribution over $A, B, C$, is this one:
%One Hardy-type possibilistic constraint which we would want to enumerate is
\begin{align}\label{GHZtautology}
 \bracks{\mgreen{A \eql 1}, \mgreen{C \eql 1}} \implies \bracks{\mgreen{A \eql 1}, B \eql 1} \lor \bracks{B \eql 0, \mgreen{C \eql 1}}.
\end{align}
Applying the union bound, one obtains a constraint on marginal distributions,\footnote{This inequality is equivalent to \cref{eq:polymonogamyraw}.}
\begin{align}\label{eq:trivmarginalconstraint}
	P_{AC}(\mgreen{1 1}) \leq P_{AB}(\mgreen{1} 1) + P_{BC}(0 \mgreen{1}).
\end{align}

In this section, we seek to determine, for any marginal scenario, the set of \emph{all} inequalities that can be derived in this manner.  We do so by \tblue{enumerating} the full set of tautologies of the form \cref{tautology1,GHZtautology}, which boils down to solving the possibilistic marginal problem.
% that arise in a given marginal problem.

We outline the general procedure using 
%a slightly more sophisticated example than the one provided above. Consider 
the marginal scenario of~\cref{fig:simplicialcomplex222}, where the full set of variables is $\{ A_1, A_2, B_1, B_2, C_1, C_2\}$ and the contexts are $\{A_1 B_1 C_1\}$, $\{A_1 B_2 C_2\}$, $\{A_2 B_1 C_2\}$, $\{A_2 B_2 C_1\}$ and $\{A_2 B_2 C_2\}$, pursuant to \cref{eq:basicsetup222}.
%\begin{align*}
%	\{A_1 B_1 C_1\},\\
%	\{A_1 B_2 C_2\},\\
%	\{A_2 B_1 C_2\},\\
%	\{A_2 B_2 C_1\},\\
%	\{A_2 B_2 C_2\}.
%\end{align*}
As before, we will express the constraints on marginal deterministic assignments as logical implications with
%Now a possibilistic constraint on this marginal problem consists of a logical implication with 
a joint valuation of one of the contexts as the \tblue{antecedent} and a disjunction over contexts of joint valuations thereon as the \tblue{consequent}. In the following, we explain how to generate \emph{all} such implications which are tight in the sense that the consequent is minimal, i.e., involves as few terms as possible in the disjunction. 
%ir right-hand sides are minimal.

First, we fix the antecedant by choosing some context and a joint valuation of its variables. In order to generate all contraints on marginal deterministic assignments, one will have to perform this procedure for \emph{every} context as the antecedent and every choice of joint valuation thereof. For the sake of concreteness, we take the above example with $\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$ as the antecedent.  
Each logical implication we consider is required to have the property 
%The consequent will be a disjunction over contexts of joint valuations for each context, with the additional property
 that any variable that appears in both the antecendent and the consequent must be given the same value in both. 
%all outcomes of variables that also occur in the antecedent carry the same outcome. 
%For the implication to be valid, the consequent must further be such that \tred{for any \emph{joint} composite outcome which extends the antecedent's marginal composite outcome, also at least one of the marginal composite outcomes in the consequent must occur.}

To formally determine all valid consequents, we consider two hypergraphs, or equivalently as 0/1 matrices with rows that enumerate the vertices and the columns that correspond to hyperedges, so that every $1$ indicates an incidence between a vertex and a hyperedge. %Take the set of nodes to be the disjoint union over all the contexts of all the joint outcomes which are compatible with~\eqref{eq:lhshardy}\footnote{In the left-hand side context there will thus be only one node, and one can also omit this one node without changing the result.}. 

%\color{red} The nodes in the first hypergraph correspond to every possible joint valuation of the variables in a context for every possible context. 
  Each node in the first hypergraph corresponds to an assignment of outcomes (valuation) to the variables in some particular context. 
The hyperedges in the first hypergraph correspond to all possible joint valuations of all the variables. A hyperedge (joint valuation of all variables) contains a node (joint valuation on the marginal contexts) iff the hyperedge is an extension of the node; for example the hyperedge $\bracks{A_1 \eql 0, \mgreen{A_2 \eql 1}, B_1 \eql 0, \mgreen{B_2 \eql 1}, C_1 \eql 1, \mgreen{C_2 \eql 1}}$ is an extension of the node $\bracks{A_1 \eql 0,  \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$. In our example following \cref{fig:simplicialcomplex222}, this initial hypergraph has $5\cdot 2^3 = 40$ nodes and $2^6 = 64$ hyperedges. Indeed, in 0/1 matrix notation, this first hypergraph is precisely the marginal description matrix $\bm{M}$ introduced near \cref{eq:marginalproblemgeneric}.

The second hypergraph is a sub-hypergraph of the first one. We delete from the first hypergraph all nodes and hyperedges which contradict the outcomes supposed by the antecedent. For example, the node $\bracks{\mgreen{A_2 \eql 1}, \mred{B_2 \eql 0}, C_1 \eql 1}$ contradicts the antecedent $\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}}$. We also delete the node corresponding to the antecedent itself. In our example, this final resulting hypergraph has $2^3 + 3\cdot 2^1 = 14$ nodes and $2^3 = 8$ hyperedges.

All valid (minimal) consequents are (minimal) \tblue{transversals} of this latter hypergraph. A transversal is a set of nodes which has the property that it intersects every hyperedge in at least one node. In order to get implications which are as tight as possible, it is sufficient to enumerate only the minimal transversals. Doing so is a well-studied problem in computer science with various natural reformulations and for which manifold algorithms have been developed~\cite{eiter_dualization_2008}.

%It is then possible right-hand sides of the implications are precisely the \tblue{transversals} of this hypergraph, i.e.~the sets of nodes which have the property that they intersect every hyperedge in at least one node. In order to get implications which are as tight as possible, it is sufficient to enumerate only the \tblue{minimal transversals}. Doing so is a well-studied problem in computer science with various natural reformulations and for which manifold algorithms have been developed~\cite{eiter_dualization_2008}. We expect that this enumeration of minimal transversals will be computationally much more tractable than the linear quantifier elimination, even if one does it for every possible left-hand side of the implication.

In our example, it is not hard to check that the consequent of
\begin{align}\begin{split}\label{eq:F3implicationform}
	\bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}} \quad\Longrightarrow\quad &\bracks{A_1 \eql 0, B_1 \eql 0, C_1 \eql 0} \lor \bracks{A_1 \eql 1, \mgreen{B_2 \eql 1}, \mgreen{C_2 \eql 1}} \\
	\lor\: & \bracks{\mgreen{A_2 \eql 1}, B_1 \eql 1, \mgreen{C_2 \eql 1}} \lor \bracks{\mgreen{A_2 \eql 1}, \mgreen{B_2 \eql 1}, C_1 \eql 1}
\end{split}\end{align}
is such a minimal transversal: every assignment of values to all variables which extends the assignment on the left-hand side satisfies at least one of the terms on the right, but this ceases to hold as soon as one removes any one term on the right. 

We convert these implications into inequalities in the usual way via the union bound (i.e., replacing ``$\Rightarrow$'' by ``$\leq$'' at the level of probabilities and the disjunctions by sums). For example the constraint on marginal deterministic assignments \cref{eq:F3implicationform} translates into the constraint on marginal distributions
\begin{align}\label{eq:F3rawprobform}
    P_{A_2 B_2 C_2}\parens{\mgreen{1} \mgreen{1} \mgreen{1}} \leq P_{A_1 B_1 C_1}\parens{0 0 0}+P_{A_1 B_2 C_2}\parens{1 \mgreen{1 1}}+P_{A_2 B_1 C_2}\parens{\mgreen{1} 1 \mgreen{1}}+P_{A_2 B_2 C_1}\parens{\mgreen{1 1} 1}.
\end{align}
%\[
%	P_{A_2 B_2 C_2}(111) \leq P_{A_1 B_1 C_1}(000) + P_{A_1 B_2 C_2}(111) + P_{A_2 B_1 C_2}(111) + P_{A_2 B_2 C_1}(111).
%\]
This inequality is a strengthening of \cref{eq:F3rawweak}.  \cref{eq:F3rawprobform} was used earlier in this article as the starting point of our third example of how to derive a causal compatibility inequality for the Triangle scenario, \cref{eq:FritzF3raw}. Because \cref{eq:F3implicationform} is the progenitor of this inequality, it can be thought of as the progenitor of the causal compatibility inequality that one derives from it, namely, \cref{eq:FritzF3}.  


Inequalities on marginal distributions that one derives from hypergraph transversals are generally weaker than those that result from a complete solution of the marginal problem. Nevertheless, many Bell inequalities are of this form, the CHSH inequality among them \cite{Ghirardi08}.  So it seems that this method is still sufficiently powerful to generate plenty of interesting inequalities. At the same time, it should be significantly easier to perform in practice than the full-fledged facet enumeration, even if one does it for every possible antecedent.

In conclusion, facet enumeration is the preferable method for deriving inequalities for the marginal problem whenever it is computationally tractable; but whenever it is not, then enumerating hypergraph transversals presents a good alternative. %: \cref{eq:trisimplestunmapped} here corresponds to Eq. (2-4) in~\cite{Pitowsky1989}%, and \cref{eq:bellcondeq} here corresponds to Eq. (30) in Ref. \cite{Ghirardi08}

%\color{black}




\section{Further prospects for the inflation technique}\label{sec:otherprospects}

\cref{maincorollary} states that any causal compatibility inequality on the injectable sets of an inflation DAG $G'$ can be translated into a causal compatibility inequality on the original DAG $G$. Consequently any technique for deriving causal compatibility inequalities on $G'$ can potentially be amplified by the inflation technique.  As we discovered in \cref{sec:ineqs}, even weak constraints at the level of the inflated DAG can translate into strong constraints at the level of the original DAG. In the following two subsections, we consider two additional possibilities for constraints that might be exploited in this way to derive better inequalities.

\subsection{Using \textit{d}-separation relations of the inflated DAG}\label{sec:fulldsep}

In \cref{sec:ineqs}, we considered deriving causal compatibility inequalities on the inflated DAG by taking valid inequalities for the marginal polytope on the pre-injectable sets of the inflated DAG, and then making of use the ancestral independences to factorize the joint distributions on the pre-injectable sets into those on the injectable sets.
% into the distributions over each of the ancestrally-independent injectable sets contained therein.  

It is natural to wonder whether one can sometimes make use of facts about the causal structure that go beyond ancestral independences.  It is standard practice, when deriving compatibility conditions for a DAG, to make use of arbitrary $d$-separation relations among variables: if, in a given DAG, $\bm{X}$ and $\bm{Y}$ are $d$-separated\footnote{The notion of $d$-separation is treated at length in~\cite{pearl2009causality,studeny2005probabilistic,WoodSpekkens,pusey2014gdag}, so we elect not to review it here.} by $\bm{Z}$, then a distribution is compatible with that DAG only if it satisfies the conditional independence relation $\bm{X}\indep\bm{Y}|\bm{Z}$. For $\bm{Z} = \emptyset$, this specializes to ancestral independence of $\bm{X}$ and $\bm{Y}$. Thus it is natural to ask: can the inflation technique also sensibly make use of other $d$-separation relations among sets of observed variables?

%The marginal problem asks about the existence of \emph{any} joint distribution which recovers the given marginal distributions. In causal inference, however, there are plenty of other constraints on the sorts of joint distributions which are consistent with some causal hypothesis. The minimal constraint embedded in any causal hypothesis is the idea of causal structure. Thus it is natural to supplement the marginal problem with additional constraints, motivated by causal structure, constraining the hypothetical distribution over observable variables of the inflated DAG.

%The most familiar causally-motivated constraints on a joint distribution are \tblue{conditional independence relations}, say among observable variables. Conditional independence relations are inferred by $d$-separation; if $\bm{X}$ and $\bm{Y}$ are $d$-separated in the (inflation) DAG by $\bm{Z}$, then we infer the conditional independence $\bm{X}\bot\bm{Y}|\bm{Z}$. The $d$-separation criterion is explained at length in~\cite{pearl2009causality,studeny2005probabilistic,WoodSpekkens,pusey2014gdag}, so we elect not to review it here.

Every conditional independence relation $\bm{X}\indep\bm{Y}|\bm{Z}$ can be expressed as a polynomial equation in terms of probabilities: while it is most commonly written as $P_{\bm{X}\bm{Y}|\bm{Z}}(\bm{x}\bm{y}|\bm{z})=P_{\bm{X}|\bm{Z}}(\bm{x}|\bm{z})P_{\bm{Y}|\bm{Z}}(\bm{y}|\bm{z})$ for all $\bm{x}$, $\bm{y}$, and $\bm{z}$, it can also be written in terms of unconditional probabilities, in which case it takes the form
\[
\forall{\bm{x} \bm{y} \bm{z}}: \p[\bm{X}\bm{Y}\bm{Z}]{\bm{x}\bm{y}\bm{z}}\p[\bm{Z}]{\bm{z}}=\p[\bm{X}\bm{Z}]{\bm{x}\bm{z}}\p[\bm{Y}\bm{Z}]{\bm{y}\bm{z}}
\]
for all $\bm{x}$, $\bm{y}$, and $\bm{z}$. Such a nonlinear constraint can be incorporated as a further restriction on the joint distributions compatible with the inflated DAG, supplementing the basic constraints of nonnegativity of probabilities for the joint distribution of the observed variables and the constraints implied by ancestral independences.
% of the marginal problem discussed above.

For example, in the Spiral inflation of the Triangle scenario~(\cref{fig:Tri222}), $A_1$ and $C_2$ are $d$-separated by $\{A_2 B_2\}$ (in addition to being ancestrally independent). Hence one can try to incorporate the constraint that 
%might incorporate the family of nonlinear equalities 
\begin{align}\label{nonlinearequality}
\forall{a_1 a_2 b_2 c_2}: \p[A_1 A_2 B_2 C_2]{a_1 a_2 b_2 c_2}\p[A_2 B_2]{a_2 b_2}=\p[A_1 A_2 B_2]{a_1 a_2 b_2}\p[A_2 B_2 C_2]{a_2 b_2 c_2}
\end{align}
 %for all $a_1$, $a_2$, $b_2$ and $c_2$. 
 Every probability that appears in such an equation, though not defined on an injectable set, can still be expressed as a marginal of the joint distribution over all observed variables.  For instance, we can express $\p[A_2 B_2]{a_2 b_2}$ as
%  like this must occur as a marginal as well, i.e.,~it can be written as a sum of various joint probabilities, as in
\begin{align}
\forall{a_2 b_2}:\;\p[A_2 B_2]{a_2 b_2} = \sum\nolimits_{a_1 b_1 c_1 c_2}\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2}.
\end{align}
Upon substituting such relations into~\cref{nonlinearequality}, one obtains a system of polynomial equations and inequalities in terms of the observable joint probabilities.  We can then proceed as we did before, eliminating the unknowns $\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2}$ from this system. The additional difficulty now is that some the equations are nonlinear. This idea even applies to some ancestral independences between sets that are not pre-injectable: for example, $A_1 A_2 B_2 \indep C_2$ is also guaranteed in the Spiral inflation of the Triangle scenario~(\cref{fig:Tri222}), and results in a polynomial equation closely related to \cref{nonlinearequality}.
%In particular, the number of unknown quantities to be eliminated is still the same, but now the system of equations and inequalities is nonlinear. 
%Note also that incorporating such constraints also increases the number of quantifier which must be eliminated, as additional non-injectable probabilities are now featured in the equalities corresponding to conditional independence which do not appear in the unconstrained marginal problem. 

Many modern computer algebra systems have functions capable of tackling nonlinear quantifier elimination symbolically\footnote{For example \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://reference.wolfram.com/language/ref/Resolve.html}{\texttt{Resolve}} command, \textit{Redlog}'s \href[pdfnewwindow]{http://www.redlog.eu/documentation/reals/rlqe.php}{\texttt{rlposqe}}, or \textit{Maple$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://maplesoft.com/support/help/Maple/view.aspx?path=RegularChains/SemiAlgebraicSetTools/RepresentingQuantifierFreeFormula}{\texttt{RepresentingQuantifierFreeFormula}}.}. 
%One might then hope to use such software systems to rid the hybrid inequalities of the gedankenprobabilities. 
Currently, however, it is generally not practical to perform nonlinear quantifier elimination on large polynomial systems with many unknowns to be eliminated. It may help to exploit results on the concrete algebraic-geometric structure of these particular systems~\cite{garcia_bayesian_2005}. 

If one is seeking merely to assess the compatibility of a {\em given} distribution with the causal structure, then one can avoid the quantifier elimination problem and simply try and solve an existence problem: after substituting the values that the given distribution prescribes for the joint outcomes on pre-injectable sets into the polynomial system in terms of the unknown global joint probabilities, one must only determine whether that system has a solution. Most computer algebra systems can resolve such \emph{satisfiability} questions quite easily\footnote{For example \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://reference.wolfram.com/language/Experimental/ref/ExistsRealQ.html}{\texttt{Reduce\`{}ExistsRealQ}} function. Specialized satisfiability software such as SMT-LIB's \href[pdfnewwindow]{http://smtlib.cs.uiowa.edu/solvers.shtml}{\texttt{check-sat}} \cite{BarFT-SMTLIB} are particularly apt for this purpose.



%But also without using quantifier elimination, the nonlinear constraints can be easily accounted for numerically. Upon substituting numerical values for all the injectable probabilities, the former quantifier elimination problem is converted to simpler existence problem: Do there exist joint probabilities that satisfy the full set of linear and nonlinear constraints numerically? Most computer algebra systems can resolve such \emph{satisfiability} questions quite easily\footnote{For example \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$} \href[pdfnewwindow]{http://reference.wolfram.com/language/Experimental/ref/ExistsRealQ.html}{\texttt{Reduce\`{}ExistsRealQ}} function. Specialized satisfiability software such as SMT-LIB's \href[pdfnewwindow]{http://smtlib.cs.uiowa.edu/solvers.shtml}{\texttt{check-sat}} \cite{BarFT-SMTLIB} are particularly apt for this purpose.
%One can also exploit the fact than any nonlinear optimizer will return an error when a set of constraints cannot be satisfied. Nonlinear optimizers include \textit{Maple$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://www.maplesoft.com/support/help/Maple/view.aspx?path=Optimization/NLPSolveMatrixForm}{\texttt{NLPSolve}}, \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://reference.wolfram.com/language/ref/message/NMinimize/nsol.html}{\texttt{NMinimize}}, and dozens of free and commercial optimizers for \href[pdfnewwindow]{http://ampl.com/products/solvers/all-solvers-for-ampl}{\textit{AMPL}} and/or \href[pdfnewwindow]{https://neos-server.org/neos/solvers/index.html\#nco}{\textit{GAMS}}
}.

It is also possible to use a mixed strategy of linear and nonlinear quantifier elimination, such as \citet{ChavesPolynomial} advocates. The explicit results of~\cite{ChavesPolynomial} are directly causal implications of the \emph{original} DAG, achieved by applying a mixed quantifier elimination strategy. Perhaps further causal compatibility inequalities will be derivable by applying such a mixed quantifier elimination strategy to inflation DAGs.

\subsection{Using copy-index equivalence on the inflated DAG}\label{Sec:copyindexequivalence}

By the definition of an inflated model (\cref{def:inflat}), if two variables in the inflated DAG $G'$ are copy-index-equivalent, $A_i \sim A_j$, then each depends on its parents in the same fashion as $A$ depends on its parents in the original DAG $G$. Hence $A_i$ and $A_j$ have the same dependence on their parents.  Formally, from $A_i \sim A$ and \cref{eq:funcdependences}, we infer that $\pfunc{A_i| \Pa[G']{A_i}}=\pfunc{A|\Pa[G]{A}}$, and similarly $\pfunc{A_j| \Pa[G']{A_j}}=\pfunc{A|\Pa[G]{A}}$.  These two equations imply that 
\begin{align}\label{copyindexequivalence}
\pfunc{A_i| \Pa[G']{A_i}}=\pfunc{A_j|\Pa[G']{A_j}}.
 \end{align}
By the definition of inflation, the ancestral subgraphs of $A_i$ and $A_j$ are identical, and equations like \cref{copyindexequivalence} also hold for all their ancestors. We conclude that also the marginal distributions of $A_i$ and $A_j$ must be equal, $\pfunc{A_i}=\pfunc{A_j}$.
%for any pair of single-variable contexts corresponding to variables that differ only in their copy-index, such as $A_i$ and $A_j$, the marginal distributions are equal, $ \pfunc{A_i}=\pfunc{A_j}$.
More generally, it may be possible to find pairs of contexts in $G'$ of any size such that constraints of the form of~\cref{copyindexequivalence} imply that the marginal distributions on these two contexts must be equal. 
%This condition implies that for certain pairs of marginal contexts in the inflated model, the marginal distributions on each are equal.   

%For example, 
For example, consider the pair of contexts $\brackets{A_1 A_2 B_1}$ and $\brackets{A_1 A_2 B_2}$ for the marginal scenario defined by the Spiral inflation of the triangle scenario~(\cref{fig:Tri222}). Neither of these two contexts is an injectable set.  Nonetheless, because of~\cref{copyindexequivalence}, we can conclude that their marginal distributions coincide in any inflation model,
\begin{align}\label{CIEconsequence}
\forall{a a' b}:\;\p[A_1 A_2 B_1]{a a' b} = \p[A_1 A_2 B_2]{a a' b}.
\end{align}
We can also conclude that in the inflation model these marginal distributions satisfy  $P_{A_1 A_2 B_1}=P_{A_2 A_1 B_2}$---where now the order of $A_1$ and $A_2$ is opposite on the two sides of the equation---or equivalently, 
\begin{align}\label{CIEconsequence2}
\forall{a a' b}:\;\p[A_1 A_2 B_1]{a a' b} = \p[A_1 A_2 B_2]{a' a b}.
\end{align}
These constraints entail that $P_{A_1 A_2 B_2}$ must be symmetric under exchange of $A_1$ and $A_2$, which in itself is another equation of the type above.

%Indeed, even if we focus on the single context $\brackets{A_1 A_2}$, the constraint of~\cref{copyindexequivalence} implies a constraint on the marginal distribution $P_{A_1 A_2}$, namely, that it is symmetric under exchange of $A_1$ and $A_2$, 
%\begin{align}\label{CIEconsequence3}
%\forall{a a'}:\;\p[A_1 A_2]{a a'} = \p[A_1 A_2 ]{a' a}.
%\end{align}

%we can no longer describe the resulting constraints as ``coincidence'' of marginal distributions for a pair of contexts.  The resulting constraint might simply by a restriction on the marginal distribution for a single context.]  If $\varphi$ is not the identity map, then the equation $P_{\bm{U}} = P_{\bm{V}}$ is nontrivial even when $\bm{U}=\bm{V}$: in this case, it is effectively requiring $P_{\bm{U}}$ to be invariant under permuting the variables according to the automorphism $\varphi$.

Parameters such as $\p[A_1 A_2 B_1]{a_1 a_2 b}$, $\p[A_1 A_2 B_2]{a_1 a_2 b}$ and $\p[A_1 A_2]{a_1 a_2}$ can each be expressed as sums of the $\p[A_1 A_2 B_1 B_2 C_1 C_2]{a_1 a_2 b_1 b_2 c_1 c_2}$, so that relations such as \cref{CIEconsequence,CIEconsequence2} each constitute an additional equation that can be added to the system of equalities and inequalities that constitute the starting point of the satisfiability problem (if one is seeking to test the compatibility of a given distribution with the inflated DAG) or the quantifier elimination problem (if one is seeking to derive causal compatibility inequalities for the inflated DAG).  If any such additional constraints yield stronger constraints at the level of the inflated DAG, then they may translate into stronger constraints at the level of the original DAG.

%  incorporated into either linear or nonlinear quantifier eliminations in order to derive stronger causal compatibility inequalities. 
The general problem of finding pairs of marginal contexts in the inflated DAG for which relations of copy-index-equivalence imply equality of the marginal distributions, and the conditions under which such equalities may yield tighter inequalities, are discussed in \cref{sec:coincidingdetails}.



%For example, $P_{A_1 A_2 B_1}=P_{A_1 A_2 B_2}$ follows from \cref{fig:Tri222} and the inflation hypothesis, even though $\brackets{A_1 A_2 B_1}$ and $\brackets{A_1 A_2 B_2}$ are not injectable sets.

%Hence equations such as 
%\begin{align}
%\forall{a_1 a_2 b}:\;\p[A_1 A_2 B_1]{a_1 a_2 b} = \p[A_1 A_2 B_2]{a_1 a_2 b}
%\end{align}
% are true of the inflated model and consequently can be  incorporated into either linear or nonlinear quantifier eliminations in order to derive stronger causal compatibility inequalities. The details of how to recognize coinciding distributions beyond the obvious coincidences implied by injectable or pre-injectable sets and under what conditions they may yield tighter inequalities are discussed in \cref{sec:coincidingdetails}.



%One may also substitute numeric values for all the pre-injectable probabilities appearing in the marginal problem. Upon doing so, the quantifier elimination problem is converted to a quantifier existence problem: Do there exist gedankenprobabilities that satisfy the resulting system of inequalities? Such \emph{satisfiability} questions can be resolved quite rapidly, especially when the quantifiers are linear \cite{Korovin2012ImplementingCRA,Bobot2012SimplexSAT}. Note that real-world data with uncertainties can also be incorporated into these satisfiability questions. Instead of asserting that a particular probability is equal to a given \emph{value}, one can incorporate new inequalities which constrain the experimentally-known probabilities to lie in given \emph{intervals}. Assigning probabilities to intervals as opposed to numeric values results in further free parameters in the system, but the problem nevertheless remains one of \emph{universal} existential closure, and can be resolved with extreme efficiency.


%One useful alternative to linear quantifier elimination is to identify representative probability distributions which are incompatible with the (unprojected) constraints; \citet{ChavesNoSignalling} use this technique, for example. %That technique essentially translates the elimination problem to a satisfiability problem, and moreover an ultra-efficient \emph{linear} quantifier existence problem at that! In the context of polytope projection, these representative probability distributions correspond to extreme rays of the so-called ``projection cone" \cite{jones2004equality,Jones2008,BalasProjectionCone}.

%A final alternative to linear quantifier elimination is to restrict one's consideration to quantifier-free inequalities with a particular form. We found this alternative technique — trading generality for speed — to be extraordinarily practical. The subtype of causal criteria which can be most rapidly recognized are those which follow from certain tautologies in classical propositional logic, see \cref{sec:TSEM} for further details.








\color{black}


\subsection{Causal inference in quantum theory and in generalized probabilistic theories\label{sec:classicallity}}
%\section{Quantum Causal Inference and the No-Broadcasting Theorem}\label{sec:classicallity}


%In the causal inference problems with latent nodes that we have considered so far, the latent nodes correspond to unobserved random variables. In \emph{quantum} physics, however, the latent nodes may instead represent \emph{quantum systems}. 

Recent work has sought to explore quantum generalizations of the notion of a causal model, termed {\em quantum causal models} \cite{leifer2013conditionalstates,pusey2014gdag,BeyondBellII,Chaves2015infoquantum,ried2015quantum}. We sketch the definition used in~\cite{pusey2014gdag}.
%, which is the most general. 
The causal structures are still represented by DAGs, but now in a quantum causal model the outgoing edges of latent nodes carry physical systems. Thus each such edge must be labelled by a Hilbert space. Each latent node takes all its incoming information---represented by its observed parent variables together with the incoming physical systems---and turns it into outgoing information via a quantum channel. Similarly, an observed node takes all its incoming information and applies a joint measurement on its incoming physical system as well as some classical information processing resulting in an outcome for its associated variable. Root variables can be thought of as settings of preparation procedures, while terminal nodes often represent the outcomes of measurements that are used in an experiment on quantum systems. In most cases that are of interest to quantum foundations, this complicated definition of quantum causal model can be formulated in an equivalent form that does not require a distinction of two kinds of edges~\cite{BeyondBellII}.

  %each latent node represents a quantum system associated to a complex Hilbert space and the way in which it depends causally on its parents is represented by a completely-positive trace-preserving linear map.  
A quantum causal model is still ultimately in the service of explaining joint distributions over classical variables. The joint distribution of these variables is the only experimental data with which one can confront a given quantum causal model. The basic problem of causal inference for quantum causal models, therefore, concerns the compatibility of a joint distribution over observed classical variables with a given DAG when the model supplementing the DAG is quantum. If this happens, we say that the distribution is {\em quantumly compatible} with the DAG.  
 
%[provide definition of a quantum causal model?]

One motivation for studying quantum causal models is that they offer a new perspective on an old  problem in the foundations of quantum theory: that of establishing precisely which of the principles of classical physics must be abandoned in quantum physics. It was noticed by~\citet{fritz2012bell} and~\citet{WoodSpekkens} that Bell's theorem~\cite{bell1966lhvm} states that there are distributions on observed variables of the Bell DAG that are quantumly compatible but not classically compatible with the DAG. Moreover, these distributions cannot be explained by \emph{any} causal structure while complying with the additional principle that conditional independences should not be fine-tuned~\cite{WoodSpekkens}, i.e.,~while demanding that any observed conditional independence should be accounted for by the DAG. These results suggest that quantum theory is perhaps best understood as revising our notions of the nature of unobserved entities, how one represents causal dependencies thereon and incomplete knowledge thereof, while 
%the innovation of quantum theory may be best understood as an innovation to how one represents incomplete knowledge of unobserved entities (the latent nodes), while 
nonetheless {\em preserving} the spirit of causality and the principle of no fine-tuning~\cite{leifer2013conditionalstates,Spekkens2015paradigm,henson2011ontic}.
% is represented while offer the possibility of securing causal explanations of such distributions while maintaining the spirit of these principles.

Another motivation for studying quantum causal models is a practical one.  Violations of Bell inequalities have  been shown to constitute resources for information processing \cite{NoSigPolytope,scarani2012device,BancalDIApproach}. Hence it seems plausible that the existence of distributions on other DAGs that are quantumly compatible but not classically compatible may have similar applications to information processing. 
% To witness such an advantage, it may seem necessary that a given information processing task can be recast in such a way that the causal structure of the protocol mirrors that of the Bell scenario.  Many tasks, however, may not be amenable to being cast in this form.  And yet the Bell scenario is not the only DAG for which there exist distributions that are quantumly but not classically compatible.
 %one can identify distributions that are quantum compatible but  where there is a separation between the distributions consistent with a quantum causal model and those consistent with a classical causal model. 
For example, it has been shown that in addition to the Bell scenario, such a quantum-classical separation also exists 
%not just for the Bell scenario, but for other causal structures as well, such as
in the bilocality scenario \cite{BilocalCorrelations} and the Triangle scenario~\cite{fritz2012bell}, and it is likely that many more DAGs with this property will be found.  The hope is that on any DAG supporting a quantum-classical separation, some of the separating distributions may constitute a resource for information processing. 
%achieving a quantum-classical separation in novel DAGs might, like distributions that violate the Bell inequalities, be resources for information processing.

%In a causal model, each latent node of the causal structure represents a random variable and the way in which a node depends causally on its parents is represented by a conditional probability distribution.  In the field of quantum foundations, however, there has recently been interest in defining a quantum generalization of the notion of a causal model---a quantum causal model---wherein the latent nodes instead represent \emph{quantum systems} and the way in which a node depends causally on its parents is represented by a completely-positive trace-preserving map. 

%Whenever this is allowed, we say that the DAG represents a \tblue{quantum causal structure}. Some quantum causal structures are famously capable of generating distributions over the observed variables that would not be possible classically\footnote{The incompatibility of quantum correlations with practical causal structure which generates them is known as Bell's theorem \cite{bell1966lhvm}. The particular distributions which violate Bell inequalities are known as nonlocal correlations~\cite{Brunner2013Bell}. Although the term suggests the existence of nonlocal interactions, in the sense that the actual causal structure may be different from the hypothesized one, this interpretation is at odds with the fact that no nonlocal interactions have been observed in nature, implying that their presence would require fine-tuning~\cite{WoodSpekkens}. A less problematic alternative conclusion from Bell's theorem is the impossibility to model quantum physics in terms of the usual notions of ``classical'' probability theory.}.

So for both foundational and practical reasons, there is a strong motivation to find examples of DAGs that exhibit a quantum-classical separation.
%and distributions over its observed variables such that the distribution is compatible with a quantum causal model on the DAG but incompatible with a classical causal model. 
%, or to show that there is no separation. 
However, this is by no means an easy task.
The set of distributions that are quantumly compatible with a given DAG is actually very similar to the set of distributions that are classically compatible with that DAG~\cite{pusey2014gdag,fritz2012bell}. For example, both the classical and quantum sets respect all the conditional independence relations among observed nodes that are implied by the $d$-separation relations of the DAG~\cite{pusey2014gdag}, and entropic inequalities are only of very limited use~\cite{chaves2012entropic,fritz2012bell}. We hope that the inflation technique will provide better tools for finding such separations.
% It is an interesting problem to find distributions that are realizable quantumly but not classically on a given DAG, or to show that there are no separation. 
%However, this is by no means an easy task. For example, 
%a Shannon-type entropic inequality on observed variables that is derived from the Markov conditions on all nodes \cite{chaves2012entropic,fritz2012bell}. Fine-graining the scenario by conditioning on root variables (``settings'') leads to a different kind of entropic inequality, and these have proven somewhat quantum-sensitive \cite{braunstein1988entropic,SchumacherInequality,chaves2014novel}. Such inequalities are still limited, however, in that they only apply to DAGs that include root nodes that are observed\footnote{Rafael Chaves and E.W.~are exploring the potential of entropic analysis based on considering distributions conditioned on \emph{non}-root observed nodes. Jacques Pienaar has alluded to similar considerations as a possible avenue for further research as well \cite{pianaar2016interesting}.}, and they still fail to witness cases of classical incompatibility of certain distributions with a given DAG where the incompatibility is witnessed by other techniques~\cite{chaves2014novel,fritz2012bell}.

%Some constraints on compatibility can be proven to apply not only to quantum generalizations of causal models, but also to {\em postquantum} generalizations as well~\cite{pusey2014gdag}. 

In addition to quantum generalizations of causal models, one can define generalizations for other operational theories that are neither classical nor quantum~\cite{pusey2014gdag,BeyondBellII}.
%also define {\em postquantum} generalizations thereof, as was done in Henson, Lal and Pusey~\cite{pusey2014gdag}.
%The latter notion is
Such generalizations are formalized using the framework of {\em generalized probabilistic theories} (GPTs) \cite{Barnum2012GPT,Janotta2014GPT}, which is sufficiently general to describe any operational theory that makes statistical predictions about the outcomes of experiments and passes some basic sanity checks.  Some constraints on compatibility can be proven to be \emph{theory-independent} in that they apply not only to classical and quantum causal models, but to any kind of generalized probabilistic causal model~\cite{pusey2014gdag}. For example, the classically-valid conditional independence relations implied between observed variables in a DAG are all also valid in the GPT framework.
%In [Henson, Lal, Pusey], it was shown that under the constraints that ..., one can derive causal compatibility inequalities that are necessary conditions on compatibility relative to {\em any} GPT. 
Another example is the entropic monogamy inequality \cref{eq:monogomyofcorrelations}, which was proven in \cite{pusey2014gdag} to be GPT valid as well. These kinds of constraints are of interest because they clarify what any conceivable theory of physics must satisfy in a given causal scenario. 

The essential element in deriving such constraints is to only make reference to the observed nodes, as done in~\cite{pusey2014gdag}. In fact, we now understand the argument of~\cite{pusey2014gdag} to be an instance of the inflation technique. Nonetheless, we have seen that the inflation technique often yields inequalities that hold for the {\em classical} notion of compatibility, but which have quantum and GPT violations, such as the Bell inequalities of \cref{example:noPR} of \cref{subsec:witnessingincompat} and \cref{sec:Bellscenarios}. In fact, inflation can be used to derive inequalities with quantum violations for the Triangle scenario as well \cite{TC2016trianglequantum}.

%We here restrict ourselves to explaining 
So what distinguishes applications of the inflation technique that yield inequalities for GPT compatibility from those that yield inequalities for classical compatibility?   The distinction rests on a structural feature of the inflated DAG:

%As noted earlier in this article, the inflation technique also refers {\em only} to the observed nodes in a DAG.  Indeed, this is one of its strengths.  \sout{However, this same fact may suggest, at first glance, that the technique will only causal compatibility inequalities of the sort derived by HLP, that is, inequalities that are necessary conditions for compatibility in {\em all} GPTs.  At first glance, therefore, it might seem that the inflation technique will be unable to distinguish classical compatibility, quantum compatibility, and GPT compatibility. }

%This is clearly not a concern given that we ruled out PR-box correlations. Also we witness the incompability of Tobias's distribution with the triangle scenario by solving the satisfiability problem.  How can that be?  How does one understand that?


\begin{definition}
In $G'\in\SmallNamedFunction{Inflations}{G}$, an \tblue{inflationary fan-out} is a latent node that has two or more children that are copy-index equivalent.  
\end{definition}

 The Web and Spiral inflations of the triangle DAG, depicted in \cref{fig:TriFullDouble} and \cref{fig:Tri222} respectively,
contain one or more inflationary fan-outs, as does the inflation of the Bell DAG that is depicted in \cref{fig:BellDagCopy1}.  On the other hand, the simplest inflation of the triangle DAG that we consider in this article, the Cut inflation depicted in \cref{fig:simplestinflation}, does not contain any inflationary fan-outs.
%Examples of inflated DAGs that exhibit inflationary fan-out are \cref{fig:TriFullDouble}, \cref{fig:Tri222},  and \cref{fig:BellDagCopy1}, while an example of an inflated DAG that does not is ~\cref{fig:simplestinflation}.

%Some inflations, such as the one of~\cref{fig:simplestinflation}, do not require such broadcasting. By removing $A_1$ from the broadcasting inflation of \cref{fig:simpleinflation} we obtain the non-broadcasting inflation of \cref{fig:simplestinflation}. In \cref{fig:simplestinflation} the channel from $X$ to $A$ is merely \emph{redirected} from it original configuration in \cref{fig:TriMainDAG}; there is no broadcasting of information required.

  The inflation technique can only detect a GPT-classical separation if the inflation DAG has an inflationary fan-out. 
We now explain the intuition for why this is the case. 
%using the inflation technique with an inflationary fan-out may detect a GPT-classical separation. 
In an inflation model, the copy-index-equivalent children of an inflationary fan-out causally depend on it in precisely the same way as their counterparts in the original DAG do. For example, this dependence may be such that these two children are exact \emph{copies} of the inflationary fan-out. So when one tries to write down a quantum or GPT version of our notion of inflation model, one quickly runs into trouble: in quantum theory, the {\em no-broadcasting theorem} shows that such duplication is impossible in a strong sense~\cite{NoCloningQuantum1996}, and an analogous theorem holds for GPTs~\cite{NoCloningGeneral2006}. This is why in the presence of an inflationary fan-out, one cannot expect our inequalities to hold in the quantum or GPT case, which is consistent with the fact that they often do have quantum and GPT violations.

On the other hand, for any inflation DAG that does not contain an inflationary fan-out, the notion of inflation model generalizes to the quantum case: one equips every latent node in $G'$ with the same quantum channel that the corresponding node in $G$ is labelled by, while possibly discarding the outgoing systems which leave the node on those edges that do not appear in $G'$. For observed nodes, one can likewise use the exact same data as on $G$. That these prescriptions make sense crucially rests on the assumption that $G'$ is an inflation of $G$, so that the ancestries of any node in $G'$ mirrors the ancestry of the corresponding node in $G$ perfectly. Hence for inflation DAGs $G'$ without inflationary fan-outs, we have quantum analogues of \cref{mainlemma} and \cref{maincorollary}. The problem of quantum causal inference on $G$ therefore translates into the corresponding problem on $G'$, and any constraint that we can derive on $G'$ translates back to $G$. In particular, our \cref{example:noGHZ,example:polytriangle,example:entropic} also hold for quantum causal inference: perfect correlation is also quantumly incompatible with the Triangle scenario, and the inequalities \cref{eq:polymonogamy,eq:monogomyofcorrelations} have no quantum violations. All of the exact same statements apply likewise in the GPT case.
% These results are related to the monogamy of entanglement in quantum theory \cite{wootters2001monogomy,winter2004monogomy} (see also the discussion of the quantum conditional problem in Ref.~\cite{leifer2013conditionalstates}).

%From this perspective, a broadcasting inflated DAG is an abstract logical concept, as opposed to a feasible physical construct. However, this would result in a joint distribution over all observable variables that may have some negative probabilities, and one cannot expect~\cref{eq:nonnegativity} to hold in general. But one can still try to reformulate the marginal problem so as to refer only to the existence of joint distributions on non-broadcastings sets rather than the existence of a full joint distribution from which the marginal distributions might be recovered. Here, a set $\bm{U}$ of observable nodes is non-broadcasting if $\An{\bm{U}}$ does not contain two distinct copies of a node both sharing a common latent parent.

In the remainder of this section, we discuss the relation between the quantum and the GPT case. Since quantum theory is a particular generalized probabilistic theory, quantum compatibility trivially implies GPT compatibility. Through the work of Tsirelson \cite{Tsirelson1980} and \citet{PROriginal}, it is known that the converse is not true: the Bell scenario manifests a GPT-quantum separation.  The identification of distributions witnessing this difference, and the derivation of constraints on quantum compatibility with GPT violations, has been a focus of much foundational research in recent years. Traditionally, the foundational question has always been: why does quantum theory predict correlations that are {\em stronger} than one would expect classically?  But now there is a new question being asked: why does quantum theory only allow correlations that are {\em weaker} than those predicted by other GPTs?  There has been some interesting progress in identifying physical principles that can pick out the precise correlations that are exhibited by quantum theory \cite{PopescuReviewNatureComm,ScaraniML,Rohrlich2014,InfoCausArXiv,LONatureComm,LOExploring,EPNBody,barnum2014interference,AlmostQuantum}.  Further opportunities for identifying such principles would be useful.  This motivates the problem of classifying DAGs into those which have a quantum-classical separation, those which have a GPT-quantum separation and those which have both. Similarly, one can try to classify causal compatibility \emph{inequalities} into those which are GPT-valid, those which are GPT-violable-but-quantum-valid, and those which are quantum-violable. 

It may be possible to generalize the inflation technique to derive inequalities that can witness a GPT-quantum separation by finding a restricted notion of quantum causal model on inflation DAGs \emph{with} inflationary fan-outs that would not apply to the GPT case.
%For the moment, however, we 
In quantum theory, there {\em are} linear maps that can achieve broadcasting~\cite{Coecke2011}, but these are not completely positive. Thus if one uses these to define the inflation of a quantum causal model, then some of the joint probabilities for observable nodes in the inflated DAG may end up being negative.  Such inflations might still be useful as a mathematical tool for ultimately deriving causal compatibility inequalities on the original DAG, but one would need to proceed differently from the way we have proceeded in this article: whereas we have assumed that all joint outcomes on the inflated DAG have nonnegative probability, one could not impose such a constraint for the type of quantum inflation just described.  Instead, one could only demand nonnegativity for marginal distributions of collections of variables that do not include the children of an inflationary fan-out. The inflation DAG in such cases would not be physically realistic, but one could still interpret it as describing multiple different {\em counterfactual} scenarios within which the causal dependencies are the same.

An analysis along these lines has already been carried out successfully in the derivation of entropic inequalities that capture quantum compatibility. Namely, \citet{Chaves2015infoquantum} consider conditioning an observed variable on a ``setting'' variable, a structure that we would describe as an inflation DAG containing inflationary fan-outs. \citet{Chaves2015infoquantum} then take pains to avoid talking about a global joint distribution in any of the entropic inequalities they apply to this structure, %\color{purple} {R: why must they take pain to do so when the DAG has no inflationary fan-out?]\color{black}, 
precisely as we would want to do in constructing inequalities on our inflated DAG. In this way, they successfully derive entropic inequalities for quantum compatibility. So far, no inequalities polynomial in the probabilities have been derived using this method.

% Our current inflated DAG method can be employed to derive causal infeasibility criteria for general causal structures, thus generalizing Bell inequalities somewhat. From a quantum foundations perspective, however, generalizing Tsirelson inequalities \cite{Tsirelson1980,Brunner2013Bell}---the ultimate constraints on what quantum theory makes possible---is even more desirable. 

%A tight set of inequalities characterizing quantum distributions would provide the ultimate constraints on what quantum theory allows. Deriving additional inequalities that hold for quantum distributions is therefore a priority for future research.





\section{Conclusions}

We have described the \emph{inflation technique} for doing causal inference with latent variables.
%For a given DAG under consideration, one can construct many new DAGs, termed {\em inflations} of this DAG, which duplicate one or more of the nodes of the original DAG, while preserving their ancestral subgraph.  Furthermore, the causal parameters that one adds to the inflated DAG are constrained to mirror the causal dependences of the original DAG.
% An inflated DAG naturally carries inflated models, and the existence of an inflated model implies inequalities which constrain the set of distributions on observable nodes compatible with the original causal structure. Polynomial inequalities can be obtained through \emph{linear} inequalities which are necessary conditions for a collection of given marginal distributions to arise from a joint distribution (marginal problem). For deriving such inequalities in turn, we have considered the methods of computing all facets of the marginal polytope via facet enumeration, and deriving looser constraints more efficiently by enumerating hypergraph transversals.

We have shown that many existing techniques for witnessing incompatibility and for deriving causal compatibility inequalities can be enhanced by the inflation technique, independently of whether these pertain to entropic quantities, correlators or probabilities.
Furthermore, we have shown how a complete or partial solution of the marginal problem for the pre-injectable sets of the inflated DAG can be leveraged to obtain causal compatibility inequalities  for the original DAG.  These inequalities are polynomial in the joint probabilities of the observed variables.  As far as we can tell, our inequalities are not related to the nonlinear causal compatibility inequalities which have been derived specifically to constrain classical networks \cite{TavakoliStarNetworks,RossetNetworks,TavakoliNoncyclicNetworks}, nor to the nonlinear inequalities which account for interventions to a given causal structure \cite{kang2007polynomialconstraints,steeg2011relaxation}.

%The resulting polynomial inequalities are necessary conditions on a joint distribution to be explained by the causal structure.   
Because our technique is capable of exhibiting the incompatibility of the W-type distribution with the Triangle scenario, while entropic techniques cannot, it follows that our polynomial inequalities are stronger than entropic inequalities in at least some cases (see \cref{example:noWdist} of \cref{subsec:witnessingincompat}).   

A single causal structure has an unlimited number of potential inflations. Selecting a good inflation from which strong polynomial inequalities can be derived is an interesting challenge. To this end, it would be desirable to understand how particular features of the original causal structure are exposed when different nodes in the DAG are duplicated. By isolating which features are exposed in each inflation, we could conceivably quantify the utility for causal inference of each inflation. In so doing, we might find that inflated DAGs beyond a certain level of variable duplication need not be considered. The multiplicity beyond which further inflation is irrelevant may be related to the maximum degree of those polynomials which tightly characterize a causal scenario. Presently, however, it is not clear how to upper bound either number, or whether finite upper bounds can even be expected.


Causal compatibility inequalities are, by definition, merely {\em necessary} conditions for compatibility. Depending on what kind of causal inference methods one uses at the level of an inflation DAG $G'$, one may or may not obtain sufficient conditions. An interesting question is: if one only uses the existence of a joint distribution at the level of $G'$, then does one obtain sufficient conditions as $G'$ varies? In other words: if a given distribution is such that for every $G'$, the associated marginal problem is solvable, then is the distribution compatible with the original DAG? This occurs for the Bell scenario, where it is enough to consider only one particular inflation (\cref{sec:Bellscenarios}). Some evidence against sufficiency in the general case is that we have not seen a way to use the inflation technique to rederive Pearl's instrumental inequality.

We have described how the inflation technique can enhance the power of many diffferent techniques for deriving causal compatibility inequalities and witnessing incompatibility, by applying the latter technique to the inflated DAG and using \cref{mainlemma} or \cref{maincorollary}.  The computational difficulty of achieving this enhancement depends on the seed technique.  We summarize the computational difficulty of the approaches that we have considered in~\cref{table:difficulties}. While this focuses on deriving inequalities, the same table applies \emph{mutatis mutandis} to the satisfiability problem. 
%We've noted that there is a prospect for using the inflation technique to leverage arbitrary $d$-separation conditions on the inflated DAG, but this requires nonlinear quantifier elimination.  

%\begin{table}[ht]
%\centering
%\caption{A comparison of different approaches for testing causal compatibility of a given distribution with a given DAG by means of using the inflated DAG. These approaches are all means of witnessing the incompatibility of a given distribution with the inflated DAG.  
%}
%\begin{tabularx}{\linewidth}{ |c|RlL|c| } 
%\toprule
%%\hline
%Input from causal structure & General problem & $\to$ & Standard algorithm(s) & Difficulty \\
%\midrule
%\midrule
%\hline
%\hline
%Complete solution of marginal problem with arbitrary nonlinear 
%\parbox{5cm}{Only ancestral independences among the observed variables without \\(or with) supplementary copy-index equivalence relations [\cref{sec:coincidingdetails}]} & Linear Satisfiability of (supplemented) Marginal Problem [\cref{sec:satisfiable}] & $\to$ & Simplex method \cite{Korovin2012ImplementingCRA,Bobot2012SimplexSAT} & Very Easy \\
%\hline
%\parbox{5cm}{All $d$-separation conditions on the observable variables [\cref{sec:fulldsep}]} & Nonlinear Satisfiability & $\to$ & See \cite{BarFT-SMTLIB}, and semidefinite relaxations~\cite{laurent_polynomial_2012} & Easy \\
%\bottomrule
%\end{tabularx}
%\label{table:satisfiabledifficulties}
%\end{table}

\begin{table}[ht]
\centering
\caption{%\color{purple} [R: Provide references to the sections in which each case is discussed.] \color{black} 
A comparison of different approaches for deriving constraints on compatibility at the level of the inflated DAG, which then translate into constraints on compatibility at the level of the original DAG.  %The first three approaches derive causal compatibility inequalities for the inflated DAG.  The last two approaches merely provide a means of witnessing the incompatibility of a given distribution with the inflated DAG.  
%constraining the distributions on the pre-injectable sets. 
%The primary divide is producing inequalities, as in the more difficult first three approaches, versus satisfiability which can witness the infeasibility of specific distributions. 
%The approaches subdivide further into nonlinear, linear, and possibilistic variants.
}
\begin{tabularx}{\linewidth}{ |c|RlL|c| } 
\toprule
%\hline
Input from causal structure & General problem & $\to$ & Standard algorithm(s) & Difficulty \\
\midrule
\midrule
%\hline
%\hline
%Complete solution of marginal problem with arbitrary nonlinear 
	\multirow{ 2}{*}{\parbox{5cm}{\centering Only ancestral independences among the observed variables}}  & Facet enumeration of mar-\linebreak ginal polytope (\cref{sec:CCineqs})  & $\to$ & see \cref{sec:projalgorithms} & Hard \\\cline{2-5}

	& Finding possibilistic constraints \linebreak by identifying hypergraph transversals (\cref{sec:TSEM}) & $\to$ & see~\citet{eiter_dualization_2008} & Very easy \\

\hline
\parbox{5cm}{All $d$-separation conditions on the observable variables (\cref{sec:fulldsep})} & Real quantifier elimination & $\to$ & Cylindrical algebraic decomposition~\cite{ChavesPolynomial} & Very hard \\

\hline
\parbox{5cm}{Ancestral independences among the observed variables + copy-index equivalences (\cref{sec:coincidingdetails})} & Linear quantifier elimination & $\to$ & Fourier-Motzkin elimination~\cite{fordan1999projection,DantzigEaves,Bastrakov2015,BalasProjectionCone,Jones2008}, \linebreak Equality set projection \cite{JonesThesis2005,jones2004equality} & Hard \\

\bottomrule
\end{tabularx}
\label{table:difficulties}
\end{table}

For the remainder of this section, we focus on the ``only ancestral independences'' approach, where we only ask for the existence of a joint distribution on $G'$ reproducing the given marginals on pre-injectable sets.
%The resulting polynomial inequalities are necessary conditions on a joint distribution to be explained by the causal structure.   
Since this technique is capable of exhibiting the incompatibility of the W-type distribution with the Triangle scenario, while entropic techniques cannot, it follows that our polynomial inequalities are stronger than entropic inequalities in at least some cases (see \cref{example:noWdist} of \cref{subsec:witnessingincompat}).   

A single causal structure has unlimited potential inflations. Selecting a good inflation from which strong polynomial inequalities can be derived is an interesting challenge. To this end, it would be desirable to understand how particular features of the original causal structure are exposed when different nodes in the DAG are duplicated. By isolating which features are exposed in each inflation, we could conceivably quantify the causal inference strength of each inflation. In so doing, we might find that inflated DAGs beyond a certain level of variable duplication need not be considered. This may be related to the maximum degree of those polynomials which tightly characterize the distributions compatible with a causal structure. Presently, however, it is not clear how to upper bound either number, or whether a tight characterization by polynomial inequalities is even possible.


%The fact that  we have not been able to use it to rederive Pearl's instrumental inequality suggests that it may not be possible to obtain sufficient conditions from it.  
 %, although the instrumental scenario also contains only one latent node. % yet just how strong they are is still unclear. A distribution might satisfy all our polynomial inequalities and yet not be realizable from the causal structure. %What would such superficially-feasible distributions look like? Are inflated DAG inequalities ever tight? 
% Our methods yields tight causal infeasibility criteria for Bell scenarios, but those scenarios are exceptional in that the sets of realizable distributions form a convex polytope.

% The most elementary of all causal infeasibility criteria are the conditional independence (CI) relations. Our method explicitly incorporates all marginal independence relations implied by a causal structure. We have found that some CI relations also appear to be implied by our polynomial inequalities. In future research we hope to clarify the process through which CI relations are manifested as properties of the inflated DAG.





We have noted that some of the causal compatibility inequalities we derive by the inflation technique are necessary conditions not only for compatibility with a classical causal model, but also 
%for compatibility with a quantum causal model and 
for compatibility with a causal model in {\em any} generalized probabilistic theory, which includes quantum causal models as a special case.  
%As long as the inflated DAG does not include what we 

%Concerning the relation to quantum theory, our method turns the quantum no-broadcasting theorem \cite{NoCloningQuantum1996,NoCloningGeneral2006} on its head by crucially relying on the fact that classical hidden variables \emph{can} be cloned. The possibility of classical cloning motivates the inflated DAG method, and is often critical for deriving strong incompatibility witnesses. We have found that in the case of non-broadcasting inflations, our method also yields causal incompatibility witnesses that constitute necessary constraints even for \emph{quantum} or \emph{general probabilistic} causal scenarios, a common desideratum in recent works \cite{fritz2012bell,pusey2014gdag,Chaves2015infoquantum,ChavesNoSignalling,BeyondBellII}. 

It would be enlightening to understand the extent to which our (classical) polynomial inequalities for a given DAG can be violated by a distribution arising in a quantum causal model for that DAG, that is, the extent to which our inequalities can exhibit  a quantum-classical separation for DAGs other than the Bell scenario.  A variety of techniques exist for estimating the amount by which a Bell inequality \cite{NPA2008Long,I3322NPA1} is violated in quantum theory, but even finding a quantum violation of one of our \emph{polynomial} inequalities presents a new task for which we currently lack a systematic approach. Nevertheless, we know that there exists a difference between classical and quantum also beyond Bell scenarios~\cite[Theorem~2.16]{fritz2012bell}, and we hope that our polynomial inequalities will perform better in witnessing this difference than entropic inequalities do~\cite{pusey2014gdag,Chaves2015infoquantum}.

Finally, we hope that it is possible to generalize the inflation technique to derive inequalities that are necessary conditions for the compatibilty of a joint distribution of observed variables with a {\em quantum} causal model.  This may provide an alternative approach to understanding the Tsirelson bound \cite{Brunner2013Bell}.

%that one inflated DAG is or is not ``stronger" than another? Can we upper bound the maximum dimension of those polynomials which in-principle tightly characterize a given causal structure? A ``yes" answer to any of the aformentioned questions means that that perhaps inflated DAGs beyond a certain level of complexity need not be considered. These remain open questions, however.

%\end{spacing}





\begin{acknowledgments}
E.W.~would like to thank Rafael Chaves and T.C. Fraser for suggestions which have improved this manuscript. T.F.~would like to thank Nihat Ay and Guido Mont\'ufar for discussion and references. This research was supported in part by Perimeter Institute for Theoretical Physics. Research at Perimeter Institute is supported by the Government of Canada through the Department of Innovation, Science and Economic Development Canada and by the Province of Ontario through the Ministry of Research, Innovation and Science.
\end{acknowledgments}


\appendix
\numberwithin{equation}{section}
\let\stdsection\section
\renewcommand{\section}{\clearpage\stdsection} % new page for each section






\section{Algorithms for Solving the Marginal Problem}\label{sec:projalgorithms}

By solving the marginal problem, what we mean is to determine all the facets of the marginal polytope for a given marginal scenario. Since the vertices of this polytope are precisely the deterministic assignments of values to all variables, which are easy to enumerate, solving the marginal problem is an instance of a \tblue{facet enumeration problem}: given the vertices of a convex polytope, determine its facets. This is a well-studied problem in combinatorial optimization for which a variety of algorithms are available~\cite{avis_convexhull_2015}. 

A generic facet enumeration problem takes a matrix $\bm{V}\in\mathbb{R}^{d\times n}$, which lists the vertices as its columns, and asks for an inequality description of the set of vectors $\bm{b}\in\mathbb{R}^d$ that can be written as a convex combination of the vertices using weights $\bm{x}\in\mathbb{R}^n$ that are nonnegative and normalized,
\begin{align}
	\label{projsimplex}
	\left\{\: \bm{b}\in\mathbb{R}^d \quad\bigg|\quad \exists \bm{x}\in\mathbb{R}^n:\; \bm{b} = \bm{V}\bm{x} ,\;\; \bm{x}\geq \bm{0},\;\; {{\sum_i}{x_i}}=1 \:\right\}.
\end{align}
To solve the marginal problem one uses the marginal description matrix introduced in \cref{step:marginalsproblem} as the input to the facet enumeration algorithm, i.e. $\bm{V}=\bm{M}$, see \cref{eq:marginalproblemgeneric}.
% Geometrically, linear quantifier elimination is equivalent to projecting a high-dimensional polytope in halfspace representation (inequalities and equalities) into a lower-dimensional quotient space.
% Polytope projection is a well-understood problem in combinatorial optimization,

The oldest-known method for facet enumeration relies on \tblue{linear quantifier elimination} in the form of Fourier-Motzkin (FM) elimination~\cite{fordan1999projection,DantzigEaves}. This refers to the fact that one starts with the system $\bm{b}= \bm{V}\bm{x}$, $\bm{x}\geq \bm{0}$ and ${{\sum_i}{x_i}}=1$, which is the half-space representation of a convex polytope (a simplex), and then one needs to project onto $\bm{b}$-space by \emph{eliminating} the variables $\bm{x}$ to which the existential \emph{quantifier} $\exists \bm{x}$ refers. The Fourier-Motzkin algorithm is a particular method for performing this quantifier elimination one variable at a time; when applied to~\cref{projsimplex}, it is equivalent to the \emph{double description method}~\cite{DantzigEaves,Fukuda1996}. Linear quantifier elimination routines are available in many software tools\footnote{For example \textit{MATLAB$^{_{\textit{\tiny\texttrademark}}}$}'s \href[pdfnewwindow]{http://people.ee.ethz.ch/~mpt/2/docs/refguide/mpt/@polytope/projection.html}{\texttt{MPT2}}/\href[pdfnewwindow]{http://ellipsoids.googlecode.com/svn-history/r2740/branches/issue_119_vrozova/tbxmanager/toolboxes/mpt/3.0.14/all/mpt3-3_0_14/mpt/modules/geometry/sets/@Polyhedron/projection.m}{\texttt{MPT3}}, \textit{Maxima}'s \href[pdfnewwindow]{http://maxima.sourceforge.net/docs/manual/de/maxima_75.html}{\texttt{fourier\_elim}}, \textit{lrs}'s \href[pdfnewwindow]{http://cgm.cs.mcgill.ca/~avis/C/lrslib/USERGUIDE.html\#fourier}{\texttt{fourier}}, or \textit{Maple$^{_{\textit{\tiny\texttrademark}}}$}'s (v17+) \href[pdfnewwindow]{http://www.maplesoft.com/support/help/maple/view.aspx?path=RegularChains/SemiAlgebraicSetTools/LinearSolve}{\texttt{LinearSolve}} and \href[pdfnewwindow]{http://www.maplesoft.com/support/help/Maple/view.aspx?path=RegularChains/SemiAlgebraicSetTools/Projection}{\texttt{Projection}}. The efficiency of most of these software tools, however, drops off markedly when the dimension of the final projection is much smaller than the initial space of the inequalities. Fast facet enumeration aided by Chernikov rules \cite{Shapot2012,Bastrakov2015} is implemented in \href[pdfnewwindow]{https://www.inf.ethz.ch/personal/fukudak/cdd_home/}{\textit{cdd}},
\href[pdfnewwindow]{http://comopt.ifi.uni-heidelberg.de/software/PORTA/}{\textit{PORTA}}, \href[pdfnewwindow]{http://sbastrakov.github.io/qskeleton/}{\textit{qskeleton}}%~\cite{qskeleton}
, and \href[pdfnewwindow]{http://www.uic.unn.ru/~zny/skeleton/}{\textit{skeleton}}. In the authors experience \href[pdfnewwindow]{http://www.uic.unn.ru/~zny/skeleton/}{\textit{skeleton}} seemed to be the most efficient. Additionally, the package \href[pdfnewwindow]{https://polymake.org/doku.php/researchdata/polymakeilp}{\textit{polymake}} offers multiple algorithms as options for computing convex hulls.}. The authors found it convenient to custom-code a linear quantifier elimination routine in \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}.
% Other possible algorithms for facet enumeration come in two kinds: first, algorithms that are---like Fourier-Motzkin---also based on linear quantifier elimination, or equivalently on computing the half-space representation of a polytope given in half-space representation; second, algorithms that solve the facet enumeration problem in a different manner. Other projection methods than FM include 

Other algorithms for facet enumeration that are not based on linear quantifier elimination include the following. \emph{Lexicographic reverse search} (LRS)~\cite{Avis2000lrs} explores the entire polytope by repeatedly pivoting from one facet to an adjacent one, and is implemented in~\href[pdfnewwindow]{http://cgm.cs.mcgill.ca/~avis/C/lrslib/USERGUIDE.html#Installation\%20Section}{\texttt{lrs}}. Equality Set Projection (ESP)~\cite{jones2004equality,JonesThesis2005} is also based on pivoting from facet to facet, though its implementation is less stable\footnote{ESP  \cite{jones2004equality,JonesThesis2005,Jones2008} is supported by \href[pdfnewwindow]{http://people.ee.ethz.ch/~mpt/2/docs/refguide/mpt/@polytope/projection.html}{\texttt{MPT2}} but not \href[pdfnewwindow]{http://people.ee.ethz.ch/~mpt/3/}{\texttt{MPT3}}, and by the (undocumented) option of \href[pdfnewwindow]{https://github.com/tulip-control/polytope/blob/master/polytope/polytope.py\#L1412}{projection} in the \href[pdfnewwindow]{https://pypi.python.org/pypi/polytope}{\textit{polytope}} (v0.1.2 2016-07-13) python module.}. These algorithms could be interesting to use in practice, since each pivoting step churns out a new facet; by contrast, Fourier-Motzkin type algorithms only generate the entire list of facets at once, after all the quantifiers have been eliminated one by one.

It may also be possible to exploit special features of marginal polytopes in order to facilitate their facet enumeration, such as their high degree of symmetry: permuting the outcomes of each variable maps the polytope to itself, which already generates a sizeable symmetry group, and oftentimes there are additional symmetries given by permuting some of the variables. This simplifies the problem of facet enumeration~\cite{bremner_symmetries_2009,Schurmann2013}, and it may be interesting to apply dedicated software\footnote{Such as \href[pdfnewwindow]{http://comopt.ifi.uni-heidelberg.de/software/PANDA/}{\textit{PANDA}}, \href[pdfnewwindow]{http://mathieudutour.altervista.org/Polyhedral/}{\textit{Polyhedral}}, or \href[pdfnewwindow]{http://www.math.uni-rostock.de/~rehn/software/sympol.html}{\textit{SymPol}}. The authors found \textit{SymPol} to be rather effective for some small test problems, using the options ``\texttt{./sympol -a --cdd}".} to the facet enumeration problem of marginal polytopes~\cite{Kaibel2010,rehn_tools_2012,panda_2015}.

%\footnote{FM elimination algorithms make intermittent calls to a linear-programming subroutine for eliminating redundant inequalities. The authors found an efficient implementation of this subroutine in \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}, see \cref{sec:redundancy} for further details.}.
%Fourier-Motzkin elimination appreciable suboptimal, however, when the dimension of the final projection is much smaller than the initial space of the inequalities, i.e. when there are many gedankenprobabilities. See Refs. \cite{jones2004equality,JonesThesis2005,Jones2008} and \cref{sec:projalgorithms} for further detail.

% The generic task of polytope projection assumes that the initial polytope is given \emph{only} in halfspace representation. If, however, a \tblue{dual description} of the initial polytope is available, i.e. we are also given its extremal vertices, then the projection problem can be significantly optimized \cite{projectiondual,Avis2000lrs}. Such dual-description algorithms are used, for example, by modern convex hull solvers. The marginal problem can be explicitly recast as a a special convex hull problem, which can be seen as follows.

%The marginal problem is included among such special cases: the extremal vertices of the initial polytope are just the various distinct possible deterministic joint distributions! Indeed, the initial polytope of the marginal problem is a \tblue{probability simplex}, such that every non-negativity inequality is saturated by all one point.

%Here we present an explicit algorithm for polytope projection when a dual description in available. Without loss of generality we assume that the halfspace representation consists of only inequalities. This is generic, as any equality can either be solved-for as a preliminary step (substituting the solution into the system of inequalities) or converted to two inequalities (of the form $\vec{a}.\vec{x}\geq 0$ and $-\vec{a}\vec{x} \geq 0$). In this notation $\vec{x}$ represents a list of variables \emph{appended by 1}, and $\vec{a}$ indicate the coefficients of the variables, appended by some constant.

%A halfspace representation of a polytope is therefore $\brackets{\vec{x}|\hat{A}.\vec{x}\geq 0}$. The matrix element $A_{j,k}$ corresponds to the coefficient of variable $x_k$ in the $j$'th inequality.

%Consider a list of extreme points $\hat{V}$, such that the row $\vec{V_m}$ corresponds to extremal vertex $\#m$ of the polytope, with the vertex coordinates \emph{appended by 1}. Appending 1 to each vertex is useful, as inequality $\vec{A_j}$ is saturated by $\vec{V_m}$ iff $\vec{V_m}.\vec{A_j}=0$. 
%Let's introduce a binary matrix $\hat{Q}$ so that the matrix element $Q_{j,m}$ is $0$ whenever $\vec{V_m}.\vec{A_j}=0$ and $1$ whenever $\vec{V_m}.\vec{A_j}>0$. 

%Elimination of the variable $x_k$ is now performed as follows. Let $\bm{j}^+$ be a list of those $j$ for which $A_{j,k}>0$, let $\bm{j}^-$ be a list of those $j$ for which $A_{j,k}<0$, and let $\bm{j}^0$ be a list of those $j$ for which $A_{j,k}=0$. 

%Let $\hat{A}^+\coloneqq \hat{A}_{\bm{j}^+}$, i.e. the rows of $\hat{A}^+$ are precisely rows $\bm{j}^+$ extracted from $\hat{A}$. In the same manner, construct $\hat{A}^-$, $\hat{A}^0$, $\hat{Q}^+$, $\hat{Q}^-$, and $\hat{Q}^0$. Next, we construct the matrix $\hat{A}^{\pm}$, possessing $|\bm{j}^+|\times|\bm{j}^-|$ rows which we index by $i=|\bm{j}^-|^{j^+}+j^-$. 
%Let row ${\vec{A^{\pm}_i}\coloneqq \left(-A^{-}_{j^-,k}\right)\vec{A^{+}_{j^+}}+\left(A^{-}_{j^-,k}\right)\vec{A^{+}_{j^+}}}$, such that the $k$'th column of $\hat{A}^{\pm}$ is uniformly zero. 
%The minus sign in front of $A^{-}_{j^-,k}$ is important, as by itself $A^{-}_{j^-,k}<0$. Update the matrix of inequalities $\hat{A}$ to be equal to $\hat{A}^{\pm}$ joined with $\hat{A}^0$. At this point the inequities  (rows) of $\hat{A}$ may be redundant, and so we prepare for redundancy elimination as follows.

%We construct the matrix $\hat{Q}^{\pm}$, which like $\hat{A}^{\pm}$ possesses $|\bm{j}^+|\times|\bm{j}^-|$ rows indexed by $i=|\bm{j}^-|^{j^+}+j^-$. Let row ${\vec{Q^{\pm}_i}\coloneqq \vec{Q^{+}_{j^+}}\oplus\vec{A^{+}_{j^+}}}$, which the binary vector addition is taken to be such that $0\oplus0=0$ but $0\oplus1=1\oplus0=1\oplus1=1$. Update the binary matrix $\hat{Q}$ to be equal to $\hat{Q}^{\pm}$ joined with $\hat{Q}^0$. The form of binary addition is chosen in order to preserve the property $Q_{j,m}=\begin{cases} 0 & \text{if } \vec{V_m}.\vec{A_j}=0 \\ 1 & \text{otherwise} \end{cases}$. The key idea is that any extremal point which does not saturate $\vec{A^{+}_{j^+}}$ or which does not saturate $\vec{A^{-}_{j^-}}$ will, either way, surely not saturate $\vec{A^{\pm}_i}$. 

%Redundancy elimination is now rapidly accomplished by identifying indices of redundant rows in $\hat{Q}$ and then deleting those rows from both $\hat{Q}$ and $\hat{A}$. If (and only if) the set of extremal points which do not saturate $\vec{A_j}$ comprise a superset of the points which do not saturate $\vec{A_{j'}}$ then $\vec{A_j}$ is redundant. An equivalent but far more efficient criterion is that if $\vec{Q_{j'}}-\vec{Q_j}$ is entirely nonnegative then  $\vec{A_j}$ is redundant. This can be used to rapidly filter \emph{all} redundant inequalities.

%This algorithm can be thought of as an improvement to Fouerir-Chernikov elimination \cite{Shapot2012,Bastrakov2015}, which uses a similar $\hat{Q}$ to partially filter redundant inequalities.



% We find the strategy of employing linear programming in concert with the second Chernikov rule to be extremely efficient.

%There are plenty of other algorithms for computing the facets of a polytope from its vertices. The Equality Set Projection (ESP) algorithm~\cite{jones2004equality,JonesThesis2005} could be an interesting algorithm to use in practice, as it starts churning out facets one by one from the very beginning, whereas Fourier-Motzkin only has the ability to generate the entire list of facets all in one, which quickly becomes computationally intractable. So ESP may provide a useful tool for deriving an incomplete list of inequalities on inflated DAGs that are too large for the Fourier-Motzkin elimination to work.
% ideal for handling inflated DAGs, because its computational complexity scales only according to the facet count of the final projection. Our use of larger-and-larger inflated DAGs to obtain causal infeasibility criteria on the same underlying original DAG means that while the complexity of the starting polytope is unbounded, the complexity of the projection is finite. Practically, this suggests that the ESP algorithm could parse the implications due to very large inflated DAGs efficiently. Formally, ESP should require minimal computational overhead to consider a larger inflated DAG relative to considering a much smaller inflated DAG, when the \emph{implications} of the small and large inflations are similar. By contrast, the computation complexity of Fourier-Motzkin (FM) elimination algorithm scales with the number of quantifiers being eliminated. The number of gedankenprobabilities requiring elimination is exponentially related to the number of variables in the inflated DAG. The FM algorithm, therefore, is utterly impractical very for large inflated DAGs.

% Another positive feature of the ESP algorithm is that it commences outputting quantifier-free inequalities immediately, and terminates upon deriving the complete set of inequalities. By contrast, FM works by eliminating one quantifier at a time. Terminating the ESP algorithm before it reaches completion would result in an incomplete list of inequalities. Even an incomplete list is valuable, though, since the causal infeasibility criteria we are deriving are anyways necessary but not sufficient.

% Vertex projection (VP) algorithms are another computational tool which may be used to assist in linear quantifier elimination \cite{Avis2000lrs}. VP works by first enumerating the vertices of the initial polytope (H-rep to V-rep), projecting the vertices, and then converting back to inequalities (V-rep to H-rep). For generic high-dimensional polytopes, the operation of converting from a representation in terms of halfspaces to one in terms of extremal-vertices representations can be computationally costly (high-$d$ H-rep to V-rep). Starting from a vertex representation in a high dimensional space, however, one can immediately determine the vertex representation of the polytope's projection in a lower dimensional space. The projection is along the coordinate axes, so one just ``discards" the coordinate of the eliminated quantifier. To obtain the inequalities which characterize the projected polytope one then applies a convex hull algorithm to the projected vertices (low-$d$ V-rep to H-rep).

% For probability distributions, however, the extremal vertices are precisely the deterministic possibilities. Since the extremal vertices of the initial polytope are easily enumerated, it is possible to avoid the high-$d$ V-rep to H-rep step entirely. There is a one-to-one correspondence between the inflation-DAG's initial generating inequalities and its initial extreme observable probability distributions. 
% We used this V-rep to H-rep technique to project the initial marginals-problem polytope implied by \cref{fig:Tri222} to an intermediate 23-dimensional polytope, where the 23 remaining dimensions correspond to the probabilities pertainining to  pre-injectable sets.  Only then did we apply translate those probabilities into probabilities pertaining to the original DAG, and in so doing we convert linear inflation-DAG inequalities to polynomial inequalities pertaining to the original DAG. We found that the V-rep to H-rep technique, using \textit{lrs} [\href[pdfnewwindow]{http://cgm.cs.mcgill.ca/~avis/C/lrslib/USERGUIDE.html#Installation\%20Section}{\texttt{lrs}}], was orders-of-magnitude faster than FM elimination at obtaining the same result.

% Yet another technique is also possible. Suppose the initial polytope is given by $\brackets{\vec{x},\vec{y}\,|\hat{A}.\vec{x}+\hat{B}.\vec{y}\geq\bm{c}}$, where $y$ are the quantifiers. If we can find any completely nonnegative vector $\bm{w}$ such that $\bm{w}.\hat{B}=\vec{0}$ then we automatically establish the quantifier-free inequality $\bm{w}.\hat{A}.\vec{x}\geq\bm{w}.\bm{c}$. Solving for ``random" nonnegative vectors $\bm{w}$ is easy; solving for all possible solutions is rather more difficult. \citet{BalasProjectionCone} refined this method so that each extremal construction of $\bm{w}$ corresponds to an irredundant inequality in the H-rep description of the projected polytope. Nevertheless, even without utilizing the full projection cone, this technique can be used to rapidly obtain a few quantifier-free inequalities. 

%\section{Optimized Algorithm for Recognizing Redundant Inequalities}\label{sec:redundancy}

% When performing Fourier-Motzkin linear quantifier elimination one must periodically filter out redundant inequalities from the set of linear inequalities. Equivalently, the means identifying redundant halfspace constraints in the description of the polytope. An individual constraint in a set is redundant if it is implied by the other constraints. 

% An individual linear inequality is redundant if and only if it is a \emph{positive} linear combination of the others [Thm. 5.8 in \citealp{fordan1999projection}]\footnote{The ``if" is obvious. The ``only if" is a consequence of Farka's lemma \cite{fordan1999projection}.}. This is related to the V-rep characterization of polyhedral cones: If a cone is defined such that $W_{\hat{M}}\coloneqq\brackets{\vec{x}\,|\exists_{\bm{v}\geq\bm{0}}:\, \hat{M}.\bm{v}=\vec{x}}$ then $\vec{b}\in W_{\hat{M}}$ if and only if the linear system of equations $\hat{M}.\bm{v}=\vec{b}$ has a solution such that all the elements of $\bm{v}$ are nonnegative.  Thus, the computational tool required is one which accepts as input the matrix $\hat{M}$ and the column vector $\vec{b}$ and returns $\vec{b}\in W_{\hat{M}}$ as True or False. 


%It turns out that we can optimize the detection of redundant halfspaces when considering polyhedral cones as opposed to polytopes. Happily, the inequalities that pertain to the nonnegativity of probability describe a polytope which is identically the intersection of a cone with a hyperplane. The cone is given by the usual nonnegativity inequalities, just without defining $\p{}=1$. The hyperplane, then, is exactly $\p{}=1$. As the hyperplane-intersection constraint has no bearing on the quantifiers, we can set it aside, perform the projection, and then re-incorporate the $\p{}=1$ normalization condition after the Fourier-Motzkin procedure has completed.


%Thus, the computational tool required is one which accepts as input the matrix $\hat{M}$ and the column vector $\vec{b}$, and which determines if the linear system of equations $\hat{M}.\bm{v}=\vec{b}$ has any solutions such that all the elements of $\bm{v}$ are nonnegative.

%For our purposes, $\hat{M}$ is the set of all rays \emph{other} than $\vec{b}$, where the columns of $\hat{M}$ are the other rays. 

% Below, we present two possible \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$} implementations which assess if a given column $\vec{b}$ can be expressed as a positive linear combination of the columns of $\hat{M}$. The former function is easy to understand, but the latter utilizes efficient low-level code and \textit{Mathematica$^{_{\textit{\tiny\texttrademark}}}$}'s internal error-handling to rapidly recognize infeasible linear programs.











\section{Constraints on marginal distributions from copy-index equivalence relations}\label{sec:coincidingdetails}


In \cref{Sec:copyindexequivalence}, we noted that every copy of a variable in an inflation model has the same probabilistic dependence on its parents as every other copy (see~\cref{copyindexequivalence}), and that it follows that for certain pairs of marginal contexts the marginal distributions are necessarily equal.  In this section, we describe how to identify such pairs of contexts. 

%Whenever one considers some inflated DAG, the inflation of any causal model on the original DAG includes the constraint that every copy of a variable in the inflated DAG has the same functional dependence on its parents as every other copy, as noted in Eq.~\eqref{copyindexequivalence} of Sec.~\ref{Sec:copyindexequivalence}. This implies that for any pair of single-variable contexts corresponding to variables that differ only in their copy-index, such as $A_i$ and $A_j$, the marginal distributions are equal, $ \pfunc{A_i}=\pfunc{A_j}$. Such equality of marginal distributions sometimes can also apply to pairs of contexts each of which contains a set of variables.  An example was given in Sec.~\ref{Sec:copyindexequivalence}. In this section, we describe how to identify such equalities.

Given sets of nodes $\bm{U},\bm{V}\subseteq\nodes{G'}$ in an inflation DAG $G'$, let us say that a map $\varphi:\bm{U}\to\bm{V}$ is a \tblue{copy isomorphism} if it is a graph isomorphism\footnote{A graph isomorphism is a bijective map between the nodes of one graph and the nodes of another, such that both the map and its inverse take edges to edges.} between $\subgraph{\bm{U}}$ and $\subgraph{\bm{V}}$ such that $\varphi(X)\sim X$ for all $X\in\bm{U}$, meaning that $\varphi$ maps every node $X\in\bm{U}$ to a node $\varphi(X)\in\bm{V}$ that is equivalent to $X$ under dropping the copy-index. %We have been using the notion of a copy isomorphism previously by writing $\bm{U}\sim\bm{V}$ whenever there exists a copy isomorphism $\varphi:\bm{U}\to\bm{V}$.

Furthermore, we say that a copy isomorphism $\varphi : \bm{U}\to\bm{V}$ is an \tblue{inflationary isomorphism} whenever it can be extended to a copy isomorphism on the ancestral subgraphs, $\Phi : \An{\bm{U}}\to\An{\bm{V}}$. %\color{purple}
Any copy isomorphism $\Phi: \An{\bm{U}}\to\An{\bm{V}}$ defines an inflationary isomorphism $\varphi:\bm{U}\to\bm{V}$ if and only if $\Phi(\bm{U}) = \bm{V}$.
%If one starts with such a $\Phi$, then one can reconstruct $\varphi$ by restricting the domain of $\Phi$ to $\subgraph{\bm{U}}$. If the image of this restriction is $\subgraph{\bm{V}}$, then one obtains an inflationary isomorphism; that this restriction is indeed a copy isomorphism follows automatically. 
% [R: I don't understand what purpose is served by the following statement.]
So in practice, one can either start with $\varphi : \bm{U}\to\bm{V}$ and try to extend it to $\Phi : \An{\bm{U}}\to\An{\bm{V}}$, or start with such a $\Phi$ and see whether it maps $\bm{U}$ to $\bm{V}$ and thereby restricts to a $\varphi$.
%\color{black}

%By the very definition of inflated model, the inflation hypothesis implies an equation between marginal distributions:
For given $\bm{U}$ and $\bm{V}$, a sufficient condition for equality of their marginal distributions in the inflation is that there exists an inflationary isomorphism between them.  Because $\bm{U}$ and $\bm{V}$ might themselves contain several variables that are copy-index equivalent (recall the examples of \cref{Sec:copyindexequivalence}), equating the distribution $P_{\bm{U}}$ with the distribution $P_{\bm{V}}$ in an unambiguous fashion requires one to specify a correspondence between the variables that make up $\bm{U}$ and those that make up $\bm{V}$. This is exactly the data provided by the inflationary isomorphism $\varphi$.  This result is summarized in the following lemma.


\begin{lemma}
Let $G'$ be an inflation of $G$, and let $\bm{U},\bm{V}\subseteq\nodes{G'}$. Then every inflationary isomorphism $\varphi:\bm{U}\to\bm{V}$ induces an equality $P_{\bm{U}} = P_{\bm{V}}$ for every inflation model, where the variables in $\bm{U}$ are identified with those in $\bm{V}$ according to $\varphi$.
%\color{purple} [R: note that I've substituted $P_{\varphi (\bm{U})}$ for $P_{\bm{V}}$.] \color{black}
%$P_{\bm{U}} = P_{\bm{V}}$ in every inflated causal model,  where the variables in $\bm{U}$ and $\bm{V}$ are matched up according to $\varphi$.
%if $\varphi:\subgraph{\bm{U}}\to\subgraph{\bm{V}}$ is an inflationary isomorphism, then $P_{\bm{U}} = P_{\bm{V}}$ in any inflated model, where the variables in $\bm{U}$ and $\bm{V}$ are matched up according to $\varphi$.
	\label[lemma]{lem:coincide}
\end{lemma}

This applies in particular when $\bm{V} = \bm{U}$, in which case the statement is that the distribution $P_{\bm{U}}$ is invariant under permuting the variables according to $\varphi$.

\cref{lem:coincide} is best illustrated by returning to our example from \cref{Sec:copyindexequivalence} 
which considered the Spiral inflation of~\cref{fig:Tri222} and the pair of contexts $\bm{U} = \{ A_1 A_2 B_1\}$ and $\bm{V} =\{ A_1 A_2 B_2\}$. The map 
%We illustrate Lemma~\ref{lem:coincide} with an example. For the inflation of~\cref{fig:Tri222}, the map
\begin{align}\label{copyisomorph}
	\varphi \: : \: A_1 \mapsto A_1,\qquad A_2\mapsto A_2,\qquad B_1\mapsto B_2
\end{align}
is a copy isomorphism between $\bm{U}$ and $\bm{V}$
%the non-ancestral subgraphs of $\bm{U}=\{A_1 A_2 B_1\}$ and $\bm{V}=\{A_1 A_2 B_2\}$, 
because it trivially implements a graph isomorphism (both subgraphs are edgeless), and it maps each variable in $\bm{U}$ to a variable in $\bm{V}$ that is copy-index equivalent. There is a unique choice to extend $\varphi$ to a copy isomorphism $\Phi:\An{\bm{U}}\to\An{\bm{V}}$, namely, by extending~\cref{copyisomorph} to the ancestors via
\begin{align}
\Phi \: : \: X_1\mapsto X_1,\qquad Y_1\mapsto Y_1, \qquad Y_2 \mapsto Y_2, \qquad Z_1 \mapsto Z_2,
\end{align}
which is again a copy isomorphism. 
%each of $Y_2$, $X_1$, and $Y_1$ mapping to itself, as well as $Z_1\mapsto Z_2$. 
Therefore $\varphi$ is indeed an inflationary isomorphism. From \cref{lem:coincide}, we then conclude that any inflation model satisfies $P_{A_1 A_2 B_1} = P_{A_1 A_2 B_2}$.

Similarly, the map 
%We illustrate Lemma~\ref{lem:coincide} with an example. For the inflation of~\cref{fig:Tri222}, the map
\begin{align}\label{copyisomorph2}
	\varphi' \: : \: A_1 \mapsto A_2,\qquad A_2\mapsto A_1,\qquad B_1\mapsto B_2
\end{align}
is easily verified to be a copy isomorphism between $\subgraph{\bm{U}}$ and $\subgraph{\bm{V}}$, and there is again a unique choice to extend $\varphi'$ to a copy isomorphism $\Phi':\ansubgraph{\bm{U}}\to\ansubgraph{\bm{V}}$, by extending~\cref{copyisomorph2} with
\begin{align}
\Phi' \: : \: X_1\mapsto X_1,\qquad Y_1\mapsto Y_2, \qquad Y_2 \mapsto Y_1, \qquad Z_1 \mapsto Z_2,
\end{align}
%each of $Y_2$, $X_1$, and $Y_1$ mapping to itself, as well as $Z_1\mapsto Z_2$. 
so that $\varphi'$ is verified to be an inflationary isomorphism. From \cref{lem:coincide}, we then conclude that any inflated model also satisfies $P_{A_1 A_2 B_1} = P_{A_2 A_1 B_2}$.  (And this in turn implies that for the context $\{A_1 A_2\}$, the marginal distribution satisfies $P_{A_1 A_2} = P_{A_2 A_1}$.)


\begin{figure}[b]
    \centering
    \begin{minipage}[t]{0.2\linewidth}      \centering
    \includegraphics[scale=1]{ISorigDAG.pdf}
    \caption{The instrumental scenario of \citet{pearl1995instrumental}.}
    \label{fig:ISorigDAG}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.3\linewidth}      \centering
    \includegraphics[scale=1]{IScopyDAG.pdf}
    \caption{An inflated DAG of the instrumental scenario which illustrates why coinciding ancestral subgraphs doesn't necessarily imply coinciding marginal distributions.}
    \label{fig:IScopyDAG}
    \end{minipage}\hfill    
    \begin{minipage}[t]{0.3\linewidth}      \centering
    \includegraphics[scale=1]{ISancestorDAG.pdf}
    \caption{The ancestral subgraph of \cref{fig:IScopyDAG} for either $\{X_1 Y_2 Z_1\}$ or $\{X_1 Y_2 Z_2\}$.}
    \label{fig:ancestralsubgraphnotenough}
    \end{minipage}
\end{figure}

In order to avoid any possibility of confusion, we emphasize that it is not a plain copy isomorphism between the subgraphs of $\bm{U}$ and $\bm{V}$ themselves which results in coinciding marginal distributions, nor a copy isomorphism between the ancestral subgraphs of $\bm{U}$ and $\bm{V}$. It is rather an inflationary isomorphism between the subgraphs, i.e., a copy isomorphism between the ancestral subgraphs that restricts to a copy isomorphism between the subgraphs. To see why a copy isomorphism between ancestral subgraphs {\em by itself} may not be sufficient for deriving equality of marginal distributions, we offer the following example.
%The following example illustrates why the existence of a copy isomorphism between ancestral subgraphs is not, by itself, a sufficient criterion for deriving constraints on the marginal distributions. 

Take as the original DAG the instrumental scenario of \citet{pearl1995instrumental}, and consider the inflation depicted in \cref{fig:IScopyDAG}.  Consider the pair of contexts $\bm{U} = \{ X_1 Y_2 Z_1\}$ and $\bm{V}= \{ X_1 Y_2 Z_2\}$ on the inflated DAG. Since $\subgraph{\bm{U}}$ and $\subgraph{\bm{V}}$ are not isomorphic, there is no copy isomorphism between the two. On the other hand, 
%Because each context has no two variables that are copy-index equivalent, there is a unique copy isomorphism between them, namely,
the ancestral subgraphs are both given by the DAG of~\cref{fig:ancestralsubgraphnotenough}, so that the identity map is a copy isomorphism between $\ansubgraph{X_1 Y_2 Z_1}$ and $\ansubgraph{X_1 Y_2 Z_2}$.

One can try to make use of \cref{lem:coincide} when deriving polynomial inequalities with inflation via solving the marginal problem, by imposing the resulting equation $P_{\bm{U}} = P_{\bm{V}}$ as an additional constraint for every inflationary isomorphism $\varphi : \bm{U}\to\bm{V}$ between sets of observable nodes. This is advantageous to speed up to the linear quantifier elimination, since one can solve each of the resulting equations for one of the unknown joint probabilities and thereby eliminate that probability directly without Fourier-Motzkin elimination. Moreover, one could hope that these additional equations also result in tighter constraints on the marginal problem, which would in turn yielder tighter causal compatibility inequalities. Our computations have so far not revealed any example of such a tightening.

In some cases, this lack of impact can be explained as follows.
% We define two ordered sets of observable nodes $\bm{X}$ and $\bm{Y}$ in some inflated DAG $G'$ to be \tblue{irrelevant to the marginal problem} if there exists a copy bijection $\varphi:\nodes{G'}\to\nodes{G'}$ which satisfies two conditions:
%\begin{enumerate}
%	\item $\varphi$ is a graph isomorphism,
%	\item $\varphi$ maps $\bm{X}$ onto $\bm{Y}$.
%\end{enumerate}
Suppose that $\varphi:\bm{U}\to\bm{V}$ is an inflationary isomorphism 
%where the copy isomorphism between the ancestral subgraphs of which it is a restriction is an {\em automorphism} 
which is not just the restriction of a copy isomorphism between the ancestral subgraphs, but even the restriction of a copy automorphism 
$\Phi':G'\to G'$ of the entire inflation DAG onto itself; in particular, this assumption implies that $\Phi'$ also restricts to a copy isomorphism $\Phi:\An{\bm{U}}\to\An{\bm{V}}$ between the ancestral subgraphs. In this case, the irrelevance of the additional constraint $P_{\bm{U}} = P_{\bm{V}}$ to the marginal problem for inflated models can be explained by the following argument. 

Suppose that some joint distribution $P_{\SmallNamedFunction{ObservedNodes}{G'}}$ solves the unconstrained marginal problem, i.e.,~without requiring $P_{\bm{U}} = P_{\bm{V}}$. Now apply $\Phi'$ to the variables in $P_{\SmallNamedFunction{ObservedNodes}{G'}}$, switching the variables around, to generate a new distribution $P':=P_{\Phi'(\SmallNamedFunction{ObservedNodes}{G'})}$. Because the set of marginal distributions that arise from inflation models is invariant under this switching of variables, we conclude that $P'$ is also a solution to the unconstrained marginal problem. Taking the uniform mixture of $P$ and $P'$ is therefore still a solution of the unconstrained marginal problem. But this uniform mixture also satisfies the supplementary constraint $P_{\bm{U}} = P_{\bm{V}}$. Hence the supplementary constraint is satisfiable whenever the unconstrained marginal problem is solvable, which makes adding the constraint irrelevant.

This argument does not tell us anything when the inflationary isomorphism $\varphi:\bm{U}\to\bm{V}$ cannot be extended to a copy automorphism of the entire inflated DAG. It also does not apply if one uses $d$-separation conditions beyond ancestral independence  on the inflated DAG as additional constraints, because in this case the set of compatible distributions is not necessarily convex.  In either of these cases, it is unclear whether or not constraints arising from copy-index equivalence could yield tighter inequalities. 



\section{Using the Inflation Technqiue to Certify a DAG as ``Interesting"\label{sec:interestingproof}}

By considering all possible $d$-separation conditions implied by a given DAG, one can infer the set of all conditional independence (CI) relations that must hold in any joint distribution over the observed variables that is compatible with the given DAG. In the presence of latent nodes, satisfying the CI relations among observed variables 
%\sout{is a strict subset of the set of all CI relations} 
is generally not sufficient for compatibility with the DAG. \citet{pusey2014gdag} were concerned with identifying the \tblue{interesting} DAGs, by which they mean precisely those DAGs that exhibit a discrepancy between the set of observable distributions genuinely compatible with it and the set of observable distributions that merely satisfy its observable CI relations.

\citet{pusey2014gdag} derived necessary criteria on the structure of a DAG in order for it to be interesting, and they conjectured that their criteria may also be sufficient. As evidence in favour of this conjecture, they enumerated all possible DAGs with no more than six nodes satisfying their criteria, resulting in 
%for further testing. 
only 21 equivalence classes of potentially interesting DAGs.
%after accounting for symmetry \color{purple} [R: I think that the classes contain more than just DAGs that are related by symmetry.] \color{black} 
Of those 21, they further proved that 18 were unambiguously interesting by writing down explicit distributions which are incompatible despite satisfying the observable CI relations. Incompatibility was certified by means of entropic inequalities. 

That left three classes of DAGs  as \emph{potentially} interesting. For each of these, \citet{pusey2014gdag} derived all Shannon-type entropic inequalities in two different ways, once by accounting for non-observable CI relations (that is, CI relations that do not refer exclusively to observed variables) and once without. The existence of \emph{novel} Shannon-type inequalities upon accounting for non-observable CI relations is evidence for the DAG being interesting. The only loophole is that perhaps those novel Shannon-type inequalities are actually non-novel non-Shannon-type inequalities implied by the observable CI relations alone \cite{pusey2014gdag}. %\color{purple} [R: why is this a loophole?] \color{black}

One way to close this loophole would be to show that the novel Shannon-type inequalities imply constraints beyond some inner approximation to the genuine entropy cone absent non-observable CI relations, perhaps along the lines of~\cite{weilenmann2016entropic}. Another is to use causal compatibility inequalities beyond entropic inequalities to identify some CI-respecting but incompatible distributions. \citet{pianaar2016interesting} accomplished precisely this, and should be credited with the original insight to explicitly consider the different values that an observable root variable may take. In the following, we demonstrate how the inflation technique can be used for this purpose. So far, we have only considered one of the three enigmatic causal structures, namely,~\cref{fig:GDAG15}.

\begin{figure}[b]
\centering
\begin{minipage}[t]{0.4\linewidth}
\centering
\includegraphics[scale=1]{scen15DAGV2.pdf}
\caption{DAG \#15 in Ref. \cite{pusey2014gdag}.}\label{fig:GDAG15}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[scale=1]{scen15InflationDAGV2.pdf}
\caption{A useful inflation of \cref{fig:GDAG15}.}\label{fig:Inflated15}
\end{minipage}
\end{figure}

The following representative causal compatibility inequalities for the DAG of~\cref{fig:GDAG15} follow from the inflation technique applied to causal compatibility inequalities for the inflation DAG of \cref{fig:Inflated15}, where the latter are obtained from Hardy-type tautologies as described in \cref{sec:TSEM}:
\begin{align}
\p[A]{0} \p[A D E]{0 0 0} \leq {\p[A E]{0 0} \p[A F]{0 0}  + \p[A]{0} \p[A D F]{0 0 1}}, \\
\p[A]{0}\p[A D E]{1 0 0} \leq {\p[A E]{1 0} \p[A F]{0 0} + \p[A]{1} \p[A D F]{0 0 1}}.
\label{eq:DAG15ineqs}
\end{align}
%\color{purple} [R: Why do we bother to provide the first of these two inequalities given that we do not use it to reject Pienaar's distribution?  Just as something else we can say about this DAG?]\color{black}
For example, the second inequality may be explicitly derived as follows. A Hardy-type tautology on the variables of the inflation DAG implies the following constraint on marginals:
%One Hardy-type probabilistic inequality required for consistency of marginal distributions is
\begin{align}\label{eq:hardyforpienaar}
     \p[A_1 A_2 D E_2]{0100} \leq \p[A_1 A_2 E_2 F_1]{0100} + \p[A_1 A_2 D F_1]{0101} .
\end{align}
Applying factorization as per the ancestral independence relations of the inflated DAG, we obtain 
%the precursor to \cref{eq:DAG15ineqs}, namely
\begin{align}
 \p[A_1]{0} \p[A_2 D E_2]{100} \leq \p[A_2 E_2]{10} \p[A_1 F_1]{00} + \p[A_2]{1} \p[A_1 D F_1]{001},   
\end{align}
and finally translating this into a causal compatibility inequality on the original DAG using \cref{maincorollary}, we obtain \cref{eq:DAG15ineqs}. 
 
%which is equivalent to \cref{eq:DAG15ineqs}.
%A distribution incompatible with \cref{fig:GDAG15} discovered by \citet{pianaar2016interesting} is given by
In \citet{pianaar2016interesting}, it was shown that the following distribution, which is easily verified to satisfy the CI relations among the observed variables of \cref{fig:GDAG15}, namely, $A\indep D$ and $E\indep F | A$~\cite{pusey2014gdag}, is nonetheless incompatible with \cref{fig:GDAG15}:
\begin{align}\label{eq:pienaardistro}
	P^{\text{Pien}}_{A D E F}:=\frac{[0000]+[0101]+[1000]+[1110]}{4},\quad\text{i.e.}\quad P^{\text{Pien}}_{A D E F}(a d e f):=\begin{cases}\tfrac{1}{4}&\text{if }  a\cdot d = e \text{ and }  (a \oplus 1)\cdot d = f, \\ 0&\text{otherwise}.\end{cases}
\end{align}
%which can be easily verified to satisfy the CI relations among the observed variables of the DAG, namely, $A\indep D$ and $E\indep F | A$~\cite{pusey2014gdag}. 

It is easily verified that this distribution violates the causal compatibility inequality of~\cref{eq:DAG15ineqs}.  It is in this sense that the inflation technique can show that the DAG of \cref{fig:GDAG15} is interesting. 
%demonstrate this incompatibility 
%rules out this distribution because it violates the causal incompatibility inequality~\cref{eq:DAG15ineqs}.

There is another way to see that this distribution is not compatible with~\cref{eq:DAG15ineqs} using the inflation technique.  First, one notes that any marginal distribution on $DEF$ that is compatible with the DAG of \cref{fig:GDAG15} is necessarily also compatible the triangle scenario (with $D$, $E$ and $F$ as observed variables).
% because making a latent variable observable does not alter serves only to restrict the cardinality of that variable.
Second, one notes that the marginal distribution $P^{\text{Pien}}_{D E F}$ is incompatible with the triangle scenario, since it violates inequality \#8 of~\cref{sec:CCineqs}.  This is the same inequality which rejects the W-distribution of~\cref{eq:wdistribution1}.
Like the W-distribution, the distribution $P^{\text{Pien}}$
 %Yet another interesting point is that $P^{\text{Pien}}$ 
 not only satisfies all Shannon-type entropic inequalities pertinent to~\cref{fig:GDAG15}, but lies within an inner approximation to the genuine entropy cone for that scenario\footnote{This is due to Weilenmann and Colbeck (personal communication).}. In other words, there exists a distribution with the same joint and marginal entropies as  $P^{\text{Pien}}$ which \emph{is} compatible with \cref{fig:GDAG15}.

Finally, it may be worth noting that the inflation of~\cref{fig:Inflated15} is precisely the ``bilocality scenario'' investigated by~\citet{BilocalCorrelations}.  Therefore, the inflation technique permits us to translate every causal compatibility inequality for the bilocality scenario into a causal compatibility inequality for the DAG of~\cref{fig:GDAG15}.

%Interesting, the distribution $P^{\text{Pien}}$ can also be certified incompatible with \cref{fig:GDAG15} using only our results from the Triangle scenario. By marginalizing over the random variable $A$ in \cref{eq:pienaardistro} we obtain tripartite distribution which is rejected by inequality $\#8$ in \cref{tab:machinereadable} and in the table of inequalities on \cpageref{page:nontrivlist}. This is the same inequality which rejects the W-distribution defined in \cref{eq:wdistribution1}.





\section{The Copy Lemma and Non-Shannon type Entropic Inequalities}\label{sec:NonShannon}

As it turns out, the inflation technique is also useful outside of the problem of causal inference. As we argue in the following, inflation is secretly what underlies the \tblue{Copy Lemma} in the derivation of non-Shannon type entropic inequalities~\cite[Chapter~15]{yeung_network_2008}. The following formulation of the Copy Lemma is the one of \citet{kaced_equivalence_2013}.

\begin{lemma}
	Let $A$, $B$ and $C$ be random variables with distribution $P_{ABC}$. Then there exists a fourth random variable $A'$ and joint distribution $P_{AA'BC}$ such that:
	\begin{enumerate}
		\item $P_{AB} = P_{A'B}$,
		\item $A' \indep AC \:|\: B$.
	\label{copylemma}
	\end{enumerate}
\end{lemma}

The proof via inflation is as follows.
\begin{proof}
	We begin by noting that every possible joint distribution $P_{ABC}$ is compatible with a DAG of the form of~\cref{fig:beforecopy}.  This follows from the fact that one may take $X$ to be any \tblue{sufficient statistic} for the joint variable $(A,C)$ given $B$, such as $X := (A,B,C)$.  Next, we consider the inflation of \cref{fig:beforecopy} depicted in~\cref{fig:aftercopy}. The maximal injectable sets are $\{ A_1 B_1 C_1\}$ and $\{A_2 B_1\}$.  By \cref{mainlemma}, because $P_{ABC}$ is assumed to be compatible with~\cref{fig:beforecopy}, it follows that the family of marginals $\{ P_{A_1 B_1 C_1}, P_{A_2 B_1}\}$, where $P_{A_1 B_1 C_1}:= P_{A B C}$ and $P_{A_2 B_1} := P_{AB}$, is compatible with the inflation of~\cref{fig:aftercopy}. The resulting joint distribution $P_{A_1 A_2 B_1 C_1}$ has marginals $P_{A_1 B_1}= P_{A_2 B_1} =P_{AB}$ and satisfies the conditional independence relation $A_2 \indep A_1 C_1 \:|\: B_1$, since $A_2$ is $d$-separated from $A_1 C_1$ by $B_1$ in \cref{fig:aftercopy}.
%If the original distribution $P_{ABC}$ is compatible with~\cref{fig:beforecopy}, then the associated inflated model marginalizes to a distribution $P_{A_1 A_2 B_1 C_1}$ which has the required properties.
%Consider the original DAG of~\cref{fig:beforecopy} and the associated inflated DAG of~\cref{fig:aftercopy}. If the original distribution $P_{ABC}$ is compatible with~\cref{fig:beforecopy}, then the associated inflated model marginalizes to a distribution $P_{A_1 A_2 B C}$ which has the required properties. To see that every $P_{ABC}$ is compatible with~\cref{fig:beforecopy} one may take $X$ to be any \tblue{sufficient statistic} for the joint variable $(A,C)$ given $B$, such as $X := (A,B,C)$.
\end{proof}

While it is also not hard to write down the distribution constructed in the proof explicitly as $P_{A_1 A_2 B_1 C_1} := P_{A_1 B_1 C_1} P_{A_2 B_1} P_{B_1}^{-1}$~\cite[Lemma~15.8]{yeung_network_2008}, the fact that one can rederive it using the inflation technique is significant.  For one, all the non-Shannon type inequalities derived by \citet{zeger_2011_nonshannon} are obtained by applying some Shannon type inequality to the distribution that is implied to exist by the Copy Lemma.  Our result shows, therefore, that one can understand these non-Shannon type inequalities for a DAG as arising from Shannon-type inequalities applied to an inflation DAG.  Indeed, it may be that the inflation technique may be a more general-purpose tool for deriving non-Shannon-type entropic inequalities.  A natural direction for future research is to explore whether more sophisticated applications of the inflation technique might result  in \emph{new} examples of such inequalities. 
%our purpose in rederiving the lemma via inflation is our hope that more sophisticated applications of the inflation technique will result in \emph{new} non-Shannon type entropic inequalities. 
%For example, all the non-Shannon type inequalities derived by \citet{zeger_2011_nonshannon} are applications of the Copy Lemma, and each proof therein can be recast in terms of some Shannon type inequalities appied to a suitable inflation.

%Note that this inflation is non-broadcasting. The Copy Lemma is therefore valid even in the paradigm of quantum mechanics or any generalized probability theory, as we would expect. \color{purple} [R:Why do we expect this?  Elie's answer: I was thinking that the Copy Lemma should hold regardless of the classical/quantum paradigm, because it is just a way of obtaining non-Shannon type inequalities. The set of jointly-observable variables may differ in classical and quantum theories, but the validity of all Shannon and non-Shannon type inequalities regarding any jointly-observable set is never in question.]\color{black}

\begin{figure}[H]
\centering
\begin{minipage}[t]{0.4\linewidth}
\centering
\includegraphics[scale=1]{shannonNOcopyV1.pdf}
\caption{A causal structure that is compatible with any distribution $P_{ABC}$.}\label{fig:beforecopy}
\end{minipage}
\hfill
\begin{minipage}[t]{0.4\linewidth}
\centering
\includegraphics[scale=1]{shannonYEScopyV1.pdf}
\caption{An inflation of \cref{fig:beforecopy}.}\label{fig:aftercopy}
\end{minipage}
%\hfill
%\begin{minipage}[t]{0.3\linewidth}
%\centering
%\includegraphics[scale=1]{shannonYEScopyKacedV1.pdf}
%\caption{An equivalent representation of inflation of \cref{fig:aftercopy} so as to match the terminology of \citet{kaced_equivalence_2013}.}
%\end{minipage}
\end{figure}

%\section{Classifying polynomial inequalities for the Triangle scenario}
\section{Causal compatibility inequalities for the Triangle scenario in machine-readable format}
\label{sec:38ineqs}

The following polynomial inequalities for the Triangle scenario with binary observed variables have been derived via the linear quantifier elimination method of~\cref{sec:ineqs} using the inflation DAG of~\cref{fig:Tri222}. Initially this has resulted in 64 symmetry classes of inequalities, where the symmetries are given by permuting the variables and inverting the outcomes. For the resulting 64 inequalities, numerical checks have found violations of only 37 of them: although they are all facets of the marginal polytope over the distributions on pre-injectable sets, there is no guarantee that they are also nontrivial inequalities at the level of the original DAG, and this has indeed turned out not to be the case for 26 of these symmetry classes of inequalities. Moreover, it is still likely to be the case that some of these inequalities are redundant; we have not checked whether for every inequality there is a distribution which violates the inequality but satisfies all others.

In the following table, the inequalities are listed in expectation-value form, where we assume the two possible outcomes of each variables to be $\{-1,+1\}$. Each row in the table gives the coefficients of one inequality, which is then $\geq 0$. Inequalities \#1, \#3--4, \#8--17 and \#19--24 in the table are also implied by the hypergraph transversals technique per \cref{sec:TSEM}.

\begin{table*}[ht]\centering\caption{List of inequalities as table of coefficients. This is a machine-readable version of the table in \cref{sec:CCineqs}.\medskip}\label{tab:machinereadable}
\resizebox{\textwidth}{!}{
\begin{tabular}{lc@{\hspace{1em}}ccc@{\hspace{1em}}ccc@{\hspace{1em}}c@{\hspace{1em}}ccc@{\hspace{1em}}ccc@{\hspace{1em}}c} 
%\begin{array}{rrrrrrrrrrrrrrrr}
  & constant & \(\expec{A}\) & \(\expec{B}\) & \(\expec{C}\) & \(\expec{A B}\) & \(\expec{A C}\) & \(\expec{B C}\) & \(\expec{A B C}\) & \(\expec{A}\expec{B}\) & \(\expec{A}\expec{C}\) & \(\expec{B}\expec{C}\) & \(\expec{C}\expec{A B}\) & \(\expec{B}\expec{A C}\) &
   {\(\expec{A}\expec{B C}\)} & {\(\expec{A}\expec{B}\expec{C}\)}   \\\bottomrule
\text{($\#$1):} & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
 \text{($\#$2):} & 2 & 0 & 0 & 0 & 0 & -2 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & 0 & 1 \\
 \text{($\#$3):} & 3 & 1 & -1 & 1 & 1 & 3 & 0 & 0 & 0 & 0 & 1 & -1 & -1 & 0 & 1 \\
 \text{($\#$4):} & 3 & 1 & -1 & 1 & 1 & 3 & 0 & 0 & 0 & 0 & 1 & 1 & -1 & 0 & -1 \\
 \text{($\#$5):} & 3 & 0 & 1 & 0 & 1 & 0 & -2 & 0 & -1 & 1 & 0 & 1 & -1 & 0 & 1 \\
 \text{($\#$6):} & 3 & 0 & 1 & 0 & 0 & -2 & -2 & 0 & 0 & 1 & 0 & -1 & -1 & 0 & 1 \\
 \text{($\#$7):} & 3 & 0 & 1 & 0 & 1 & 0 & -2 & 0 & 1 & -1 & 0 & 1 & 1 & 0 & -1 \\
 \text{($\#$8):} & 3 & 1 & 1 & 1 & 2 & 2 & 2 & -1 & 1 & 1 & 1 & 1 & 1 & 1 & -1 \\
 \text{($\#$9):} & 3 & 1 & 1 & 1 & 0 & 2 & -2 & 1 & -1 & 1 & 1 & 1 & 1 & -1 & -1 \\
 \text{($\#$10):} & 4 & 0 & 0 & 2 & -2 & -2 & 0 & -1 & 2 & 0 & 2 & 1 & 1 & 1 & 0 \\
 \text{($\#$11):} & 4 & 0 & -2 & 0 & -2 & 0 & -3 & 1 & 0 & 0 & 1 & 1 & -1 & 0 & 1 \\
 \text{($\#$12):} & 4 & 0 & -2 & 0 & -2 & -2 & -3 & 1 & 0 & 2 & 1 & 1 & 1 & 0 & -1 \\
 \text{($\#$13):} & 4 & 0 & 0 & 0 & 2 & -2 & 1 & 1 & -2 & -2 & -1 & -1 & 1 & 0 & -1 \\
 \text{($\#$14):} & 4 & 0 & 0 & 0 & 2 & -2 & 1 & 1 & -2 & 2 & -1 & 1 & 1 & 0 & 1 \\
 \text{($\#$15):} & 4 & 0 & 0 & 0 & 0 & -2 & 3 & 1 & 0 & 2 & 1 & -1 & -1 & 0 & 1 \\
 \text{($\#$16):} & 4 & 0 & -2 & 0 & -2 & -2 & -2 & 1 & 0 & 2 & 0 & 1 & 1 & -1 & 0 \\
 \text{($\#$17):} & 4 & 0 & 0 & 0 & -2 & -2 & -2 & 1 & 2 & 2 & 2 & 1 & 1 & 1 & 0 \\
 \text{($\#$18):} & 5 & 1 & 1 & 1 & 3 & 1 & -4 & 0 & -2 & 0 & 1 & 1 & -1 & 0 & 1 \\
 \text{($\#$19):} & 5 & 1 & 1 & 1 & 3 & -1 & -4 & 0 & 2 & -2 & 1 & 1 & 1 & 0 & -1 \\
 \text{($\#$20):} & 5 & 1 & -1 & 1 & 1 & 2 & -2 & -2 & -2 & -1 & 1 & 1 & -2 & -2 & 0 \\
 \text{($\#$21):} & 5 & 1 & 1 & 1 & 1 & 2 & -2 & -1 & 0 & -1 & -1 & 2 & 1 & 1 & -2 \\
 \text{($\#$22):} & 5 & -1 & 1 & 1 & 1 & 1 & -1 & 1 & -2 & -2 & 2 & -2 & -2 & -2 & 0 \\
 \text{($\#$23):} & 5 & 1 & 1 & 1 & 2 & 1 & -1 & 1 & -1 & 0 & 2 & -1 & -2 & -2 & 1 \\
 \text{($\#$24):} & 5 & 1 & 1 & 1 & -1 & 2 & 2 & 1 & -2 & -1 & -1 & 2 & 1 & -1 & -2 \\
 \text{($\#$25):} & 6 & 0 & 0 & 0 & -4 & -3 & 0 & 0 & 2 & 1 & 2 & -2 & -1 & -2 & 1 \\
 \text{($\#$26):} & 6 & -2 & 0 & 2 & -5 & -3 & 0 & 0 & 1 & 1 & 0 & -1 & 1 & -2 & 2 \\
 \text{($\#$27):} & 6 & 0 & 0 & 2 & -4 & 3 & 0 & 0 & 2 & 1 & 0 & -2 & 1 & -2 & 1 \\
 \text{($\#$28):} & 6 & 0 & 0 & 0 & 1 & -3 & 2 & 0 & 1 & 1 & -4 & 1 & -1 & -2 & -2 \\
 \text{($\#$29):} & 6 & 0 & 2 & 0 & 3 & 0 & -5 & 0 & 1 & -2 & 1 & 1 & 2 & 1 & -2 \\
 \text{($\#$30):} & 6 & 0 & 2 & 0 & 2 & -2 & 1 & 0 & -2 & 4 & -1 & 2 & 2 & 1 & 1 \\
 \text{($\#$31):} & 6 & 0 & 0 & 0 & -2 & -3 & -2 & -2 & 0 & 1 & 4 & -2 & -1 & 0 & 1 \\
 \text{($\#$32):} & 7 & 1 & 1 & 1 & 2 & 1 & -3 & 3 & 1 & -2 & 2 & 3 & 2 & -2 & -1 \\
 \text{($\#$33):} & 8 & 0 & 0 & 0 & -2 & -4 & -2 & -3 & 2 & 4 & -2 & -1 & 1 & -3 & 2 \\
 \text{($\#$34):} & 8 & 2 & 0 & -2 & -6 & 1 & 0 & 1 & 0 & -1 & 2 & 1 & 2 & -3 & 3 \\
 \text{($\#$35):} & 8 & 2 & 0 & 0 & 6 & 1 & -2 & 1 & 0 & 1 & 2 & -1 & -2 & -3 & 3 \\
 \text{($\#$36):} & 8 & 0 & -2 & -2 & 0 & -6 & 1 & 1 & 2 & 0 & -1 & 3 & 1 & -2 & -3 \\
 \text{($\#$37):} & 8 & 0 & 2 & 0 & 1 & 2 & -6 & 1 & 1 & -2 & 0 & 2 & 3 & -1 & -3 
\end{tabular}}
\end{table*}


\section{Recovering the Bell inequalities from the inflation technique}
\label{sec:Bellscenarios}


To further illustrate the power of our inflation DAG approach, we now demonstrate how to recover all Bell inequalities~\cite{Brunner2013Bell,bell1966lhvm,CHSHOriginal} via our method. To keep things simple we only discuss the case of a bipartite Bell scenario with two values for both ``settings'' and ``outcome'' variables here, but the case of more parties and/or more values per variable is totally analogous.
%It is critical that our method should be able to derive these seminal criteria, as Bell inequalities have been a foundational component of quantum information theory for the last half century \cite{scarani2012device,BancalDIApproach}.

The causal structure associated to the Bell \cite{bell1964einstein,Brunner2013Bell,bell1966lhvm,CHSHOriginal} experiment [\citealp{pusey2014gdag}~(Fig.~E\#2), \citealp{WoodSpekkens}~(Fig.~19), \citealp{chaves2014novel}~(Fig.~1), \citealp{BeyondBellII}~(Fig.~1), \citealp{wolfe2015nonconvexity}~(Fig.~2b), \citealp{steeg2011relaxation}~(Fig.~2)] is depicted in \cref{fig:NewBellDAG1}. The observable variables are $A,B,X,Y$, and $\Lambda$ is the latent common cause of $A$ and $B$. In a Bell scenario, one traditionally works with the conditional distribution $P_{AB|XY}$, to be understood as an array of distributions indexed by the possible values of $X$ and $Y$, instead of with the original distribution $P_{ABXY}$, which is what we do.

In the inflation DAG of \cref{fig:BellDagCopy1}, the maximal pre-injectable sets are
\begin{align}\begin{split}
	\label{eq:bellcontexts}
&\brackets{A_1 B_1 X_1 X_2 Y_1 Y_2}, \\
&\brackets{A_1 B_2 X_1 X_2 Y_2 Y_2}, \\
&\brackets{A_2 B_1 X_1 X_2 Y_2 Y_2}, \\
&\brackets{A_2 B_2 X_1 X_2 Y_2 Y_2},
\end{split}\end{align}
where notably every maximal pre-injectable set contains all ``settings'' variables $X_1$ to $Y_2$. The marginal distributions on these pre-injectable sets are then specified by the original observable distribution via
\begin{align}\begin{split}&\forall{a b x_1 x_2 y_1 y_2}:\; \begin{cases}
	P_{A_1 B_1 X_1 X_2 Y_1 Y_2}(a b x_1 x_2 y_1 y_2)  = P_{A B X Y}(a b x_1 y_1) P_X(x_2) P_Y(y_2), \\
	P_{A_1 B_2 X_1 X_2 Y_1 Y_2}(a b x_1 x_2 y_1 y_2)  = P_{A B X Y}(a b x_1 y_2) P_X(x_2) P_Y(y_1), \\
	P_{A_2 B_1 X_1 X_2 Y_1 Y_2}(a b x_1 x_2 y_1 y_2)  = P_{A B X Y}(a b x_2 y_1) P_X(x_1) P_Y(y_2), \\
	P_{A_2 B_2 X_1 X_2 Y_1 Y_2}(a b x_1 x_2 y_1 y_2)  = P_{A B X Y}(a b x_2 y_2) P_X(x_1) P_Y(y_1), \\
\hspace{2.5pc}	P_{X_1 X_2 Y_1 Y_2}(x_1 x_2 y_1 y_2)  = P_X(x_1) P_X(x_2) P_Y(y_1) P_Y(y_2).
\end{cases}\end{split}\end{align}
%where it should be understood implicitly that the inequalities hold for all values of $\{a b x_1 x_2 y_1 y_2\}$.
%The last equations follows from each of the others by making use of the Markov condition $P_{XY} = P_X P_Y$ for the original distribution, it nevertheless
By dividing each of the first four equations by the fifth, we obtain
\begin{align}\begin{split}
	\label{eq:bellfactor}
	\forall{a b x_1 x_2 y_1 y_2}:\; \begin{cases}
	P_{A_1 B_1 | X_1 X_2 Y_1 Y_2}(a b | x_1 x_2 y_1 y_2)  = P_{A B | X Y}(a b | x_1 y_1), \\
	P_{A_1 B_2 | X_1 X_2 Y_1 Y_2}(a b | x_1 x_2 y_1 y_2)  = P_{A B | X Y}(a b | x_1 y_2), \\
	P_{A_2 B_1 | X_1 X_2 Y_1 Y_2}(a b | x_1 x_2 y_1 y_2)  = P_{A B | X Y}(a b | x_2 y_1), \\
	P_{A_2 B_2 | X_1 X_2 Y_1 Y_2}(a b | x_1 x_2 y_1 y_2)  = P_{A B | X Y}(a b | x_2 y_2).
\end{cases}\end{split}\end{align}
The existence of a joint distribution over all six variables---i.e.~the existence of a solution to the marginal problem---implies in particular
%If we then impose marginal compatibility according the the marginal problem we find that the (minimal!) consequence of the inflation hypothesis is 
\begin{align}
	\forall{a b x_1 x_2 y_1 y_2}: \quad P_{A_1 B_1 | X_1 X_2 Y_1 Y_2}(a b | x_1 x_2 y_1 y_2)  =  \sum\nolimits_{a',b'} P_{A_1 A_2 B_1 B_2 | X_1 X_2 Y_1 Y_2}(a a' b b'|x_1 x_2 y_1 y_2),
\end{align}
and similarly for the other three conditional distributions under consideration. For consistency with the causal hypothesis, \cref{eq:bellfactor} therefore implies that the original distribution must satisfy in particular
\begin{align}\begin{split}\label{eq:finalBellstep}\forall{a b}:\; \begin{cases}
	P_{A B | X Y}(a b | 0 0)  =  \sum\nolimits_{a',b'} P_{A_1 A_2 B_1 B_2| X_1 X_2 Y_1 Y_2}(a a' b b'|0101) \\
	P_{A B | X Y}(a b | 1 0)  =  \sum\nolimits_{a',b'} P_{A_1 A_2 B_1 B_2| X_1 X_2 Y_1 Y_2}(a' a b b'|0101) \\
	P_{A B | X Y}(a b | 0 1)  =  \sum\nolimits_{a',b'} P_{A_1 A_2 B_1 B_2| X_1 X_2 Y_1 Y_2}(a a' b' b|0101) \\
	P_{A B | X Y}(a b | 1 1)  =  \sum\nolimits_{a',b'} P_{A_1 A_2 B_1 B_2| X_1 X_2 Y_1 Y_2}(a' a b' b|0101)
\end{cases}\end{split}\end{align}
The possibility to write the conditional probabilities in the Bell scenario in this form is equivalent to the existence of a latent variable model, as noted in Fine's theorem~\cite{FineTheorem}. Thus, the existence of a solution to our marginal problem implies the existence of a latent variable model for the original distribution; the converse follows from our \cref{mainlemma}. Hence the inflation DAG of~\cref{fig:BellDagCopy1} provides necessary and sufficient conditions for the compatibility of the original distribution with the Bell scenario causal structure.

Moreover, it is possible to describe the marginal polytope over the pre-injectable sets of~\cref{eq:bellcontexts}, resulting in a concrete correspondence between tight Bell inequalities and the facets of our marginal polytope. This is based on the observation that the ``settings'' variables $X_1$ to $Y_4$ occur in all four contexts. The marginal polytope lives in $\oplus_{i=1}^4 \mathbb{R}^{2^6} = \oplus_{i=1}^4 (\mathbb{R}^2)^{\otimes 6}$, where each tensor factor has basis vectors corresponding to the two possible outcomes of each variable, and the direct summands enumerate the four contexts. It is given by the convex hull of the points
\begin{align*}
	(e_{A_1} & \otimes e_{B_1} \otimes e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}) \\
	\oplus\: (e_{A_1} & \otimes e_{B_2} \otimes e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}) \\
	\oplus\: (e_{A_2} & \otimes e_{B_1} \otimes e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}) \\
	\oplus\: (e_{A_2} & \otimes e_{B_2} \otimes e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}),
\end{align*}
where all six variables range over their possible values. Since the last four tensor factors occur in every direct summand in exactly the same way, the resulting polytope is linearly isomorphic to the convex hull of the points
\[
	\left[ (e_{A_1} \otimes e_{B_1}) \oplus (e_{A_1} \otimes e_{B_2}) \oplus (e_{A_2} \otimes e_{B_1}) \oplus (e_{A_2} \otimes e_{B_2})\right] \otimes \left[ e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}\right]
\]
in $\big(\oplus_{i=1}^4 \mathbb{R}^{2^2}\big)\otimes \mathbb{R}^{2^4}$. Now since the first four variables in the first tensor factor vary completely independently of the latter four variables in the second tensor factor, the resulting polytope will be precisely the tensor product~\cite{namioka_tensor_1969,bogart_hom_2013} of two polytopes: first, the convex hull of all points of the form
\[
	(e_{A_1} \otimes e_{B_1}) \oplus (e_{A_1} \otimes e_{B_2}) \oplus (e_{A_2} \otimes e_{B_1}) \oplus (e_{A_2} \otimes e_{B_2}),
\]
and second the convex hull of all $e_{X_1} \otimes e_{X_2} \otimes e_{Y_1} \otimes e_{Y_2}$. While the latter polytope is just the standard probability simplex in $\mathbb{R}^8$, the former cone is precisely the ``local polytope'' or ``Bell polytope'' that is traditionally used in the context of Bell scenarios~\cite[Sec.~II.B]{Brunner2013Bell}. This implies that the facets of our marginal polytope are precisely the pairs consisting of a facet of the Bell polytope and a facet of the simplex, the latter of which are only the nonnegativity of probability inequalities like $P_{X_1X_2Y_1Y_2}(0101)\geq 0$. For example, in this way we obtain one version of the CHSH inequality as a facet of our marginal polytope,
\[
	\sum_{a,b,x,y} (-1)^{a + b + xy} P_{A_x B_y X_1 X_2 Y_1 Y_2}(a b 0 1 0 1) \leq 2 P_{X_1 X_2 Y_1 Y_2}(0101).
\]
This translates into the standard form of the CHSH inequality as follows. Upon using~\cref{eq:bellfactor}, the inequality becomes
\begin{align*}
	\sum_{a,b} (-1)^{a + b} \big( & P_{A B X Y}(ab00)P_X(1)P_Y(1) + P_{A B X Y}(ab01)P_X(1)P_Y(0) \\[-4pt]
	& + P_{A B X Y}(ab10)P_X(0)P_Y(1) - P_{A B X Y}(ab11)P_X(0)P_Y(0) \big) \leq P_X(0)P_X(1)P_Y(0)P_Y(1),
\end{align*}
so that dividing by the right-hand side results in one of the conventional forms of the CHSH inequality,
\[
	\sum_{a,b} (-1)^{a + b} \left( P_{AB|XY}(ab|00) + P_{AB|XY}(ab|01) + P_{AB|XY}(ab|10) - P_{AB|XY}(ab|11) \right) \leq 2.
\]
In conclusion, the inflation technique is powerful enough to get a precise characterization of all distributions compatible with the Bell causal structure, and our technique for generating polynomial inequalities through solving the marginal problem recovers all Bell inequalities.

Some Bell inequalities may also be derived using the hypergraph transversals technique discussed in \cref{sec:TSEM}. For example, the inequality
\begin{align}\label{eq:preBell}\begin{split}
& \p[A_1 B_1 X_1 Y_1]{0000}\p[X_2]{1} \p[Y_2]{1} \\
&\leq
 \p[A_1 B_2 X_1 Y_2]{0001}\p[X_2]{1} \p[Y_1]{0} +\p[A_2 B_1 X_2 Y_1]{0010}\p[X_1]{0}\p[Y_2]{1}+  \p[A_2 B_2 X_2 Y_2]{1111}\p[X_1]{0} \p[Y_1]{0}
\end{split}\end{align}
is the inflationary precursor of the Bell inequality
\begin{align}\label{eq:aBell}
 \p[A B | X Y]{00|00} &\leq \p[A B | X Y]{00|01} +\p[A B | X Y]{00|10}+  \p[A B | X Y]{11|11},
\end{align}
as \cref{eq:aBell} is obtained from \cref{eq:preBell} by dividing both sides by $\p[X_1 Y_1 X_2 Y_2]{0011}=\p[X_1]{0} \p[Y_2]{0}\p[X_2]{1} \p[Y_2]{1}$ and then dropping copy indices. On the other hand, \cref{eq:preBell} follows directly from factorization relations on pre-injectable sets and the tautology
\begin{align}\begin{split}
	[ \mgreen{A_1 \eql 0}, & \mgreen{B_1 \eql 0}, \mgreen{X_1 \eql 0}, \mgreen{Y_1\eql 0}, \mgreen{X_2 \eql 1}, \mgreen{Y_2 \eql 1}]\\
 \implies 
	[ & \mgreen{A_1 \eql 0}, B_2 \eql 0, \mgreen{X_1 \eql 0}, \mgreen{Y_1\eql 0}, \mgreen{X_2 \eql 1}, \mgreen{Y_2 \eql 1}] \\
	\mathrel{\lor} [ & A_2 \eql 0, \mgreen{B_1 \eql 0}, \mgreen{X_1 \eql 0}, \mgreen{Y_1\eql 0}, \mgreen{X_2 \eql 1}, \mgreen{Y_2 \eql 1}] \\
	\mathrel{\lor} [ & A_2 \eql 1, B_2 \eql 1, \mgreen{X_1 \eql 0}, \mgreen{Y_1\eql 0}, \mgreen{X_2 \eql 1}, \mgreen{Y_2 \eql 1}].
\end{split}\end{align}
which corresponds to the original ``Hardy paradox''~\cite{L.Hardy:PRL:1665} in our notation.




%\section*{References}
%\nocite{*}
%\setlength{\bibsep}{\smallskipamount}
%\clearpage
\renewcommand\section{\stdsection}
\let\cleardoublepage\clearpage
\setlength{\bibsep}{3pt plus 3pt minus 2pt}
\bibliographystyle{apsrev4-1}
\nocite{apsrev41Control}
\bibliography{hardyinference}
\end{document}
